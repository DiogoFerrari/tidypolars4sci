{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"Combining Polars and Tidyverse for Python <p>Note</p> <p>This site is still under construction, but full documentation can be found in package docstrings and API Reference.</p> <p>tidypolars provides functions that match as closely as possible to R\u2019s Tidyverse functions for manipulating data frames and conducting data analysis in Python using the blazingly fast Polars as backend.</p>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Fast: Uses Polars as backend for data manipulation. So it inherits many advantages of Polars: fast, parallel, GPU support, etc.</li> <li>Tidy: Keeps the data in tidy (rectangular table) format (no multi-indexes)</li> <li>Sintax: While Polars is fast, the sintax is not the most intuitive. The package provides frontend methods that matches R\u2019s Tidyverse functions, making it easier for users familiar with that ecosystem to transition to this library.</li> <li>Extended functinalities: Polars is extended to provide many functionalities to facilitate data manipulation and and analysis.</li> <li>Research: The package is design to facilitate academic research data analysis and reporting, making it easy to produce tables whose format are common in academic research. Output formats include LaTex, excel, and text-processing formats.</li> </ul> <p>Due to the additional functionalities provided, in some use cases tidypolars may operate slightly slower than if using Polars directly. Check the section Performance for details.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#tidypolars4sci.tibble_df.tibble","title":"<code>tibble</code>","text":"<p>               Bases: <code>DataFrame</code></p> <p>A data frame object that provides methods familiar to R tidyverse users.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>class tibble(pl.DataFrame):\n    \"\"\"\n    A data frame object that provides methods familiar to R tidyverse users.\n    \"\"\"\n    def __init__(self,  *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    @property\n    def _constructor(self):\n        # '''\n        # This method ensures that the method tibble return an instance\n        # of tibble, instead of a DataFrame\n        # '''\n        return self.__class__\n\n    def _repr_html_(self):\n        # \"\"\"\n        # Printing method for jupyter\n\n        # Output rows and columns can be modified by setting the following ENVIRONMENT variables:\n\n        # * POLARS_FMT_MAX_COLS: set the number of columns\n\n        # * POLARS_FMT_MAX_ROWS: set the number of rows\n        # \"\"\"\n        df = self.to_polars()\n        return df._repr_html_()\n\n    def __copy__(self):\n        # Shallow copy\n        # See: https://stackoverflow.com/a/51043609/13254470\n        obj = type(self).__new__(self.__class__)\n        obj.__dict__.update(self.__dict__)\n        return obj\n\n    def __getattribute__(self, attr):\n        if attr in _polars_methods:\n            raise AttributeError\n        return pl.DataFrame.__getattribute__(self, attr)\n\n    def __dir__(self):\n        _tidypolars_methods = [\n            'arrange', 'bind_cols', 'bind_rows', 'colnames', 'clone', 'count',\n            'crossing',\n            'distinct', 'drop', 'drop_null', 'head', 'fill', 'filter',\n            'group_by', \n            'inner_join', 'left_join', 'mutate', 'names', 'nest',\n            'nrow', 'ncol',\n            'full_join', 'pivot_longer', 'pivot_wider', 'print',\n            'pull', 'relocate', 'rename',\n            'replace',\n            'replace_null', 'select',\n            'separate', 'set_names',\n            'slice', 'slice_head', 'slice_tail', 'summarize', 'tail',\n            'to_pandas', 'to_polars', 'unnest', 'write_csv', 'write_parquet'\n        ]\n        return _tidypolars_methods\n\n    def arrange(self, *args):\n        \"\"\"\n        Arrange/sort rows\n\n        Parameters\n        ----------\n        *args : str\n            Columns to sort by\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n        &gt;&gt;&gt; # Arrange in ascending order\n        &gt;&gt;&gt; df.arrange('x', 'y')\n        &gt;&gt;&gt; # Arrange some columns descending\n        &gt;&gt;&gt; df.arrange(tp.desc('x'), 'y')\n\n        Returns\n        ------- \n        tibble\n            Original tibble orderd by *args\n        \"\"\"\n        exprs = _as_list(args)\n        desc = [True if isinstance(expr, DescCol) else False for expr in exprs]\n        return super()\\\n            .sort(exprs, descending = desc, nulls_last=True)\\\n            .pipe(from_polars)\n\n    def bind_cols(self, *args):\n        \"\"\"\n        Bind data frames by columns\n\n        Parameters\n        ----------\n        *args : tibble\n            Data frame to bind\n\n        Returns\n        ------- \n        tibble\n            The original tibble with added columns \n            from the other tibble specified in *args\n\n        Examples\n        --------\n        &gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n        &gt;&gt;&gt; df2 = tp.tibble({'a': ['c', 'c', 'c'], 'b': range(4, 7)})\n        &gt;&gt;&gt; df1.bind_cols(df2)\n        \"\"\"\n        frames = _as_list(args)\n        out = self.to_polars()\n        for frame in frames:\n            out = out.hstack(frame)\n        return out.pipe(from_polars)\n\n    def bind_rows(self, *args):\n        \"\"\"\n        Bind data frames by row\n\n        Parameters\n        ----------\n        *args : tibble, list\n            Data frames to bind by row\n\n        Returns\n        ------- \n        tibble\n            The original tibble with added rows \n            from the other tibble specified in *args\n\n        Examples\n        --------\n        &gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n        &gt;&gt;&gt; df2 = tp.tibble({'x': ['c', 'c', 'c'], 'y': range(4, 7)})\n        &gt;&gt;&gt; df1.bind_rows(df2)\n        \"\"\"\n        frames = _as_list(args)\n        out = pl.concat([self, *frames], how = \"diagonal\")\n        return out.pipe(from_polars)\n\n    def clone(self):\n        \"\"\"\n        Very cheap deep clone\n        \"\"\"\n        return super().clone().pipe(from_polars)\n\n    def count(self, *args, sort = False, name = 'n'):\n        \"\"\"\n        Returns row counts of the dataset. \n        If bare column names are provided, count() returns counts by group.\n\n        Parameters\n        ----------\n        *args : str, Expr\n            Columns to group by\n        sort : bool\n            Should columns be ordered in descending order by count\n        name : str\n            The name of the new column in the output. If omitted, it will default to \"n\".\n\n        Returns\n        ------- \n        tibble\n            If no agument is provided, just return the nomber of rows.\n            If column names are provided, it will count the unique \n            values across columns\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': [1, 1, 2, 3],\n        ...:                 'b': ['a', 'a', 'b', 'b']})\n        &gt;&gt;&gt; df.count()\n        shape: (1, 1)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   n \u2502\n        \u2502 u32 \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502   4 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2518\n        &gt;&gt;&gt; df.count('a', 'b')\n        shape: (3, 3)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   a   b       n \u2502\n        \u2502 i64   str   u32 \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502   1   a       2 \u2502\n        \u2502   2   b       1 \u2502\n        \u2502   3   b       1 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \"\"\"\n        args = _as_list(args)\n\n        out = self.summarize(pl.len().alias(name), by = args)\n\n        if sort == True:\n            out = out.arrange(desc(name))\n\n        return out\n\n    def distinct(self, *args, keep_all = True):\n        \"\"\"\n        Select distinct/unique rows\n\n        Parameters\n        ----------\n        *args : str, Expr\n            Columns to find distinct/unique rows\n\n        keep_all : boll\n            If True, keep all columns. Otherwise, return\n            only the ones used to select the distinct rows.\n\n        Returns\n        ------- \n        tibble\n            Tibble after removing the repeated rows based on *args\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.distinct()\n        &gt;&gt;&gt; df.distinct('b')\n        \"\"\"\n        args = _as_list(args)\n        # \n        if len(args) == 0:\n            df = super().unique()\n        else:\n            df = super().unique(args)\n        if not keep_all and len(args) &gt; 0:\n            df = df.select(args)\n        return df.pipe(from_polars)\n\n    def drop(self, *args):\n        \"\"\"\n        Drop unwanted columns\n\n        Parameters\n        ----------\n        *args : str\n            Columns to drop\n\n        Returns\n        ------- \n        tibble\n            Tibble with columns in *args dropped\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.drop('x', 'y')\n        \"\"\"\n        args = _as_list(args)\n        drop_cols = self.select(args).names\n        return super().drop(drop_cols).pipe(from_polars)\n\n    def drop_null(self, *args):\n        \"\"\"\n        Drop rows containing missing values\n\n        Parameters\n        ----------\n        *args : str\n            Columns to drop nulls from (defaults to all)\n\n        Returns\n        ------- \n        tibble\n            Tibble with rows in *args with missing values dropped\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble(x = [1, None, 3], y = [None, 'b', 'c'], z = range(3)}\n        &gt;&gt;&gt; df.drop_null()\n        &gt;&gt;&gt; df.drop_null('x', 'y')\n        \"\"\"\n        args = _as_list(args)\n        if len(args) == 0:\n            out = super().drop_nulls()\n        else:\n            out = super().drop_nulls(args)\n        return out.pipe(from_polars)\n\n    def equals(self, other, null_equal = True):\n        \"\"\"\n        Check if two tibbles are equal\n        \"\"\"\n        df = self.to_polars()\n        other = other.to_polars()\n        return df.equals(other, null_equal = null_equal)\n\n    def head(self, n = 5, *, by = None):\n        \"\"\"\n        Alias for `.slice_head()`\n        \"\"\"\n        return self.slice_head(n, by = by)\n\n    def fill(self, *args, direction = 'down', by = None):\n        \"\"\"\n        Fill in missing values with previous or next value\n\n        Parameters\n        ----------\n        *args : str\n            Columns to fill\n        direction : str\n            Direction to fill. One of ['down', 'up', 'downup', 'updown']\n        by : str, list\n            Columns to group by\n\n        Returns\n        ------- \n        tibble\n            Tibble with missing values filled\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': [1, None, 3, 4, 5],\n        ...                 'b': [None, 2, None, None, 5],\n        ...                 'groups': ['a', 'a', 'a', 'b', 'b']})\n        &gt;&gt;&gt; df.fill('a', 'b')\n        &gt;&gt;&gt; df.fill('a', 'b', by = 'groups')\n        &gt;&gt;&gt; df.fill('a', 'b', direction = 'downup')\n        \"\"\"\n        args = _as_list(args)\n        if len(args) == 0: return self\n        args = _col_exprs(args)\n        options = {'down': 'forward', 'up': 'backward'}\n        if direction in ['down', 'up']:\n            direction = options[direction]\n            exprs = [arg.fill_null(strategy = direction) for arg in args]\n        elif direction == 'downup':\n            exprs = [\n                arg.fill_null(strategy = 'forward')\n                .fill_null(strategy = 'backward')\n                for arg in args\n            ]\n        elif direction == 'updown':\n            exprs = [\n                arg.fill_null(strategy = 'backward')\n                .fill_null(strategy = 'forward')\n                for arg in args\n            ]\n        else:\n            raise ValueError(\"direction must be one of down, up, downup, or updown\")\n\n        return self.mutate(*exprs, by = by)\n\n    def filter(self, *args,\n               by = None):\n        \"\"\"\n        Filter rows on one or more conditions\n\n        Parameters\n        ----------\n        *args : Expr\n            Conditions to filter by\n        by : str, list\n            Columns to group by\n\n        Returns\n        ------- \n        tibble\n            A tibble with rows that match condition.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.filter(col('a') &lt; 2, col('b') == 'a')\n        &gt;&gt;&gt; df.filter((col('a') &lt; 2) &amp; (col('b') == 'a'))\n        &gt;&gt;&gt; df.filter(col('a') &lt;= tp.mean(col('a')), by = 'b')\n        \"\"\"\n        args = _as_list(args)\n        exprs = ft.reduce(lambda a, b: a &amp; b, args)\n\n        if _uses_by(by):\n            out = super().group_by(by).map_groups(lambda x: x.filter(exprs))\n        else:\n            out = super().filter(exprs)\n\n        return out.pipe(from_polars)\n\n    def inner_join(self, df, left_on = None, right_on = None, on = None, suffix = '_right'):\n        \"\"\"\n        Perform an inner join\n\n        Parameters\n        ----------\n        df : tibble\n            Lazy DataFrame to join with.\n        left_on : str, list\n            Join column(s) of the left DataFrame.\n        right_on : str, list\n            Join column(s) of the right DataFrame.\n        on: str, list\n            Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n        suffix : str\n            Suffix to append to columns with a duplicate name.\n\n        Returns\n        ------- \n        tibble\n            A tibble with intersection of cases in the original and\n            df tibbles.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df1.inner_join(df2)\n        &gt;&gt;&gt; df1.inner_join(df2, on = 'x')\n        &gt;&gt;&gt; df1.inner_join(df2, left_on = 'left_x', right_on = 'x')\n        \"\"\"\n        if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n            on = list(set(self.names) &amp; set(df.names))\n        return super().join(df, on, 'inner',\n                            left_on = left_on,\n                            right_on= right_on,\n                            suffix= suffix).pipe(from_polars)\n\n    def left_join(self, df, left_on = None, right_on = None, on = None, suffix = '_right'):\n        \"\"\"\n        Perform a left join\n\n        Parameters\n        ----------\n        df : tibble\n            Lazy DataFrame to join with.\n        left_on : str, list\n            Join column(s) of the left DataFrame.\n        right_on : str, list\n            Join column(s) of the right DataFrame.\n        on: str, list\n            Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n        suffix : str\n            Suffix to append to columns with a duplicate name.\n\n        Returns\n        ------- \n        tibble\n             The original tibble with added columns from tibble df if\n             they match columns in the original one. Columns to match\n             on are given in the function parameters.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df1.left_join(df2)\n        &gt;&gt;&gt; df1.left_join(df2, on = 'x')\n        &gt;&gt;&gt; df1.left_join(df2, left_on = 'left_x', right_on = 'x')\n        \"\"\"\n        if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n            on = list(set(self.names) &amp; set(df.names))\n        return super().join(df, on, 'left',  left_on = left_on, right_on= right_on, suffix= suffix).pipe(from_polars)\n\n    def mutate(self, *args, by = None, **kwargs):\n        \"\"\"\n        Add or modify columns\n\n        Parameters\n        ----------\n        *args : Expr\n            Column expressions to add or modify\n        by : str, list\n            Columns to group by\n        **kwargs : Expr\n            Column expressions to add or modify\n\n        Returns\n        ------- \n        tibble\n            Original tibble with new column created.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), c = ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.mutate(double_a = col('a') * 2,\n        ...           a_plus_b = col('a') + col('b'))\n        &gt;&gt;&gt; df.mutate(row_num = row_number(), by = 'c')\n        \"\"\"\n        exprs = _as_list(args) + _kwargs_as_exprs(kwargs)\n\n        out = self.to_polars()\n\n        if _uses_by(by):\n            out = out.group_by(by).map_groups(lambda x: _mutate_cols(x, exprs))\n        else:\n            out = _mutate_cols(out, exprs)\n\n        return out.pipe(from_polars)\n\n    @property\n    def names(self):\n        \"\"\"\n        Get column names\n\n        Returns\n        ------- \n        list\n            Names of the columns\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.names\n        \"\"\"\n        return super().columns\n\n    @property\n    def ncol(self):\n        \"\"\"\n        Get number of columns\n\n        Returns\n        ------- \n        int\n            Number of columns\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.ncol\n        \"\"\"\n        return super().shape[1]\n\n    @property\n    def nrow(self):\n        \"\"\"\n        Get number of rows\n\n        Returns\n        ------- \n        int\n            Number of rows\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.nrow\n        \"\"\"\n        return super().shape[0]\n\n    def full_join(self, df, left_on = None, right_on = None, on = None, suffix: str = '_right'):\n        \"\"\"\n        Perform an full join\n\n        Parameters\n        ----------\n        df : tibble\n            Lazy DataFrame to join with.\n        left_on : str, list\n            Join column(s) of the left DataFrame.\n        right_on : str, list\n            Join column(s) of the right DataFrame.\n        on: str, list\n            Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n        suffix : str\n            Suffix to append to columns with a duplicate name.\n\n        Returns\n        ------- \n        tibble\n            Union between the original and the df tibbles. The\n            rows that don't match in one of the tibbles will be\n            completed with missing values.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df1.full_join(df2)\n        &gt;&gt;&gt; df1.full_join(df2, on = 'x')\n        &gt;&gt;&gt; df1.full_join(df2, left_on = 'left_x', right_on = 'x')\n        \"\"\"\n        if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n            on = list(set(self.names) &amp; set(df.names))\n        return super().join(df, on, 'outer',\n                            left_on = left_on,\n                            right_on= right_on, suffix= suffix).pipe(from_polars)\n\n    def pivot_longer(self,\n                     cols = None,\n                     names_to = \"name\",\n                     values_to = \"value\"):\n        \"\"\"\n        Pivot data from wide to long\n\n        Parameters\n        ----------\n        cols : Expr\n            List of the columns to pivot. Defaults to all columns.\n        names_to : str\n            Name of the new \"names\" column.\n        values_to: str\n            Name of the new \"values\" column\n\n        Returns\n        ------- \n        tibble\n            Original tibble, but in long format.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'id': ['id1', 'id2'], 'a': [1, 2], 'b': [1, 2]})\n        &gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'])\n        &gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'], names_to = 'stuff', values_to = 'things')\n        \"\"\"\n        if cols is None:\n            cols = everything()\n        if isinstance(cols, dict):\n            cols = list(cols.keys())\n\n        df_cols = pl.Series(self.names)\n        value_vars = self.select(cols).names\n        id_vars = df_cols.filter(df_cols.is_in(value_vars).not_()).to_list()\n        out = super().melt(id_vars, value_vars, names_to, values_to)\n        return out.pipe(from_polars)\n\n    def pivot_wider(self,\n                    names_from = 'name',\n                    values_from = 'value',\n                    id_cols = None,\n                    values_fn = 'first', \n                    values_fill = None\n                    ):\n        \"\"\"\n        Pivot data from long to wide\n\n        Parameters\n        ----------\n        names_from : str\n            Column to get the new column names from.\n        values_from : str\n            Column to get the new column values from\n        id_cols : str, list\n            A set of columns that uniquely identifies each observation.\n            Defaults to all columns in the data table except for the columns specified in\n            `names_from` and `values_from`.\n        values_fn : str\n            Function for how multiple entries per group should be dealt with.\n            Any of 'first', 'count', 'sum', 'max', 'min', 'mean', 'median', 'last'\n        values_fill : str\n            If values are missing/null, what value should be filled in.\n            Can use: \"backward\", \"forward\", \"mean\", \"min\", \"max\", \"zero\", \"one\"\n\n        Returns\n        ------- \n        tibble\n            Original tibble, but in wide format.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'id': [1, 1], 'variable': ['a', 'b'], 'value': [1, 2]})\n        &gt;&gt;&gt; df.pivot_wider(names_from = 'variable', values_from = 'value')\n        \"\"\"\n        if id_cols == None:\n            df_cols = pl.Series(self.names)\n            from_cols = pl.Series(self.select(names_from, values_from).names)\n            id_cols = df_cols.filter(df_cols.is_in(from_cols).not_()).to_list()\n\n        no_id = len(id_cols) == 0\n\n        if no_id:\n            id_cols = '___id__'\n            self = self.mutate(___id__ = pl.lit(1))\n\n        out = (\n            super()\n            .pivot(index=id_cols, on=names_from, values=values_from, aggregate_function=values_fn)\n            .pipe(from_polars)\n        )\n\n        if values_fill != None:\n            new_cols = pl.Series(out.names)\n            new_cols = new_cols.filter(~new_cols.is_in(id_cols))\n            fill_exprs = [col(new_col).fill_null(values_fill) for new_col in new_cols]\n            out = out.mutate(*fill_exprs)\n\n        if no_id: out = out.drop('___id__')\n\n        return out\n\n    def pull(self, var = None):\n        \"\"\"\n        Extract a column as a series\n\n        Parameters\n        ----------\n        var : str\n            Name of the column to extract. Defaults to the last column.\n\n        Returns\n        ------- \n        Series\n            The series will contain the values of the column from `var`.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3))\n        &gt;&gt;&gt; df.pull('a')\n        \"\"\"\n        if var == None:\n            var = self.names[-1]\n\n        return super().get_column(var)\n\n    def relevel(self, x, ref):\n        \"\"\"\n        Change the reference level a string or factor and covert to factor\n\n        Inputs\n        ------\n        x : str\n            Variable name\n\n        ref : str\n           Reference level\n\n        Returns\n        ------- \n        tibble\n            The original tibble with the column specified in `x` as\n            an ordered factors, with first category specified in `ref`.\n        \"\"\"\n        levels = self.pull(x).unique().to_list()\n        relevels = [ref] + [l for l in levels if l != ref]\n        self = self.mutate(**{x : as_factor(x, relevels)})\n        return self\n\n    def relocate(self, *args, before = None, after = None):\n        \"\"\"\n        Move a column or columns to a new position\n\n        Parameters\n        ----------\n        *args : str, Expr\n            Columns to move\n\n        Returns\n        ------- \n        tibble\n            Original tibble with columns relocated.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.relocate('a', before = 'c')\n        &gt;&gt;&gt; df.relocate('b', after = 'c')\n        \"\"\"\n        cols_all = pl.Series(self.names)\n        locs_all = pl.Series(range(len(cols_all)))\n        locs_dict = {k:v for k,v in zip(cols_all, locs_all)}\n        locs_df = pl.DataFrame(locs_dict, orient = \"row\")\n\n        cols_relocate = _as_list(args)\n        locs_relocate = pl.Series(locs_df.select(cols_relocate).row(0))\n\n        if (len(locs_relocate) == 0):\n            return self\n\n        uses_before = before != None\n        uses_after = after != None\n\n        if (uses_before &amp; uses_after):\n            raise ValueError(\"Cannot provide both before and after\")\n        elif (not_(uses_before) &amp; not_(uses_after)):\n            before = cols_all[0]\n            uses_before = True\n\n        if uses_before:\n            before = locs_df.select(before).get_column(before)\n            locs_start = locs_all.filter(locs_all &lt; before)\n        else:\n            after = locs_df.select(after).get_column(after)\n            locs_start = locs_all.filter(locs_all &lt;= after)\n\n        locs_start = locs_start.filter(~locs_start.is_in(locs_relocate))\n        final_order = pl.concat([locs_start, locs_relocate, locs_all]).unique(maintain_order = True)\n        final_order = cols_all[final_order].to_list()\n\n        return self.select(final_order)\n\n    def rename(self, columns=None, regex=False, tolower=False, strict=False):\n        \"\"\"\n        Rename columns\n\n        Parameters\n        ----------\n        columns : dict, default None\n            Dictionary mapping of old and new names\n            {&lt;old name&gt;:&lt;new name&gt;, ...}\n\n        regex : bool, default False\n            If True, uses regular expression replacement\n            {&lt;matched from&gt;:&lt;matched to&gt;}\n\n        tolower : bool, default False\n            If True, convert all to lower case\n\n        Returns\n        ------- \n        tibble\n            Original tibble with columns renamed.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'x': range(3), 't': range(3), 'z': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.rename({'x': 'new_x'}) \n        \"\"\"\n        assert isinstance(columns, dict) or columns is None,\\\n            \"'columns' must be a dictionary or None.\"\n\n        if columns is not None:\n            if regex:\n                self = self.__rename_regexp__(columns)\n            else:\n                self = super().rename(columns, strict=False).pipe(from_polars)\n\n        if tolower:\n            self = self.__rename_tolower__()\n        return self\n\n    def __rename_regexp__(self, mapping):\n        pattern = next(iter(mapping))\n        replacement = next(iter(mapping.values()))\n        old = self.names\n        new = [re.sub(pattern, replacement, col) for col in self.names]\n        mapping = {o:n for o, n in zip(old, new)}\n        return self.rename(mapping, regex=False)\n\n    def __rename_tolower__(self):\n        old = self.names\n        new = [col.lower() for col in self.names]\n        mapping = {o:n for o, n in zip(old, new)}\n        return self.rename(mapping, regex=False)\n\n    def replace_null(self, replace = None):\n        \"\"\"\n        Replace null values\n\n        Parameters\n        ----------\n        replace : dict\n            Dictionary of column/replacement pairs\n\n        Returns\n        -------\n        tibble\n            Original tibble with missing/null values replaced.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble(x = [0, None], y = [None, None])\n        &gt;&gt;&gt; df.replace_null(dict(x = 1, y = 2))\n        \"\"\"\n        if replace == None: return self\n        if type(replace) != dict:\n            ValueError(\"replace must be a dictionary of column/replacement pairs\")\n        replace_exprs = [col(key).fill_null(value) for key, value in replace.items()]\n        return self.mutate(*replace_exprs)\n\n    def separate(self, sep_col, into, sep = '_', remove = True):\n        \"\"\"\n        Separate a character column into multiple columns\n\n        Parameters\n        ----------\n        sep_col : str\n            Column to split into multiple columns\n        into : list\n            List of new column names\n        sep : str\n            Separator to split on. Default to '_'\n        remove : bool\n            If True removes the input column from the output data frame\n\n        Returns\n        -------\n        tibble\n            Original tibble with a column splitted based on `sep`.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble(x = ['a_a', 'b_b', 'c_c'])\n        &gt;&gt;&gt; df.separate('x', into = ['left', 'right'])\n        \"\"\"\n        into_len = len(into) - 1\n        sep_df = (\n            self\n            .to_polars()\n            .select(col(sep_col)\n                    .str.split_exact(sep, into_len)\n                    .alias(\"_seps\")\n                    .struct\n                    .rename_fields(into))\n            .unnest(\"_seps\")\n            .pipe(from_polars)\n        )\n        out = self.bind_cols(sep_df)\n        if remove == True:\n            out = out.drop(sep_col)\n        return out\n\n    def set_names(self, nm = None):\n        \"\"\"\n        Change the column names of the data frame\n\n        Parameters\n        ----------\n        nm : list\n            A list of new names for the data frame\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble(x = range(3), y = range(3))\n        &gt;&gt;&gt; df.set_names(['a', 'b'])\n        \"\"\"\n        if nm == None: nm = self.names\n        nm = _as_list(nm)\n        rename_dict = {k:v for k, v in zip(self.names, nm)}\n        return self.rename(rename_dict)\n\n    def select(self, *args):\n        \"\"\"\n        Select or drop columns\n\n        Parameters\n        ----------\n        *args : str, list, dict, of combinations of them\n            Columns to select. It can combine names, list of names,\n            and a dict. If dict, it will rename the columns based\n            on the dict.\n            It also accepts tp.matches(&lt;regex&gt;) and tp.contains(&lt;str&gt;)\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'abcba': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.select('a', 'b')\n        &gt;&gt;&gt; df.select(col('a'), col('b'))\n        &gt;&gt;&gt; df.select({'a': 'new name'}, tp.matches(\"c\"))\n        \"\"\"\n        # convert to list if dict.keys or dict.values are used\n        cols_to_select = []\n        cols_to_rename = {}\n        for arg in args:\n            if isinstance(arg, {}.keys().__class__) or\\\n               isinstance(arg, {}.values().__class__):\n                cols_to_select += list(arg)\n\n            elif isinstance(arg, dict):\n                cols_to_select += [col for col,_ in arg.items()] \n                cols_to_rename |= arg \n\n            elif isinstance(arg, str):\n                cols_to_select += [arg]\n\n            elif isinstance(arg, list):\n                cols_to_select += arg\n\n            elif isinstance(arg, set):\n                cols_to_select += list(arg)\n\n        # # rename columns if dict is used\n        # cols_dict = [d for d in args if isinstance(d, dict)]\n        # if cols_dict:\n        #     cols_dict = cols_dict[0]\n        #     dict_list = list(cols_dict.values())\n        #     self = self.rename(cols_dict)\n        # else:\n        #     dict_list = []\n\n        # # collect str and list elements\n        # cols_list = [c for c in args if isinstance(c, str) or isinstance(c, list)]\n        # # flatten list\n        # cols_list = list(chain.from_iterable((x if isinstance(x, list)\n        #                                       else [x] for x in cols_list ))) \n\n        # # collect dict.keys() or dict.values()\n        # cols_dict_keys   = [k for k in args if isinstance( k, type({}.keys()) )]\n        # cols_dict_values = [k for k in args if isinstance( k, type({}.values()) )]\n\n        # # collect set\n        # cols_set = [s for s in args if isinstance(s, set)]\n        # if cols_set:\n        #     cols_set = list(cols_set[0])\n\n        # cols = cols_list + dict_list + cols_dict_keys +cols_dict_values +cols_set \n\n        # remove non-existing columns\n        cols_to_select = [col for col in cols_to_select \n                          if col in self.names \n                          or (col.startswith(\"^\") and col.endswith(\"$\"))] \n        # cols = [col for col in cols if col in self.names or\n        #         (col.startswith(\"^\") and col.endswith(\"$\"))]\n\n        cols = _col_exprs(cols_to_select)\n        return super().select(cols).pipe(from_polars).rename(cols_to_rename)\n\n    def slice(self, *args, by = None):\n        \"\"\"\n        Grab rows from a data frame\n\n        Parameters\n        ----------\n        *args : int, list\n            Rows to grab\n        by : str, list\n            Columns to group by\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.slice(0, 1)\n        &gt;&gt;&gt; df.slice(0, by = 'c')\n        \"\"\"\n        rows = _as_list(args)\n        if _uses_by(by):\n            df = super(tibble, self).group_by(by).map_groups(lambda x: x.select(pl.all().gather(rows)))\n        else:\n            df = super(tibble, self).select(pl.all().gather(rows))\n        return df.pipe(from_polars)\n\n    def slice_head(self, n = 5, *, by = None):\n        \"\"\"\n        Grab top rows from a data frame\n\n        Parameters\n        ----------\n        n : int\n            Number of rows to grab\n        by : str, list\n            Columns to group by\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.slice_head(2)\n        &gt;&gt;&gt; df.slice_head(1, by = 'c')\n        \"\"\"\n        col_order = self.names\n        if _uses_by(by):\n            df = super(tibble, self).group_by(by).head(n)\n        else:\n            df = super(tibble, self).head(n)\n        df = df.select(col_order)\n        return df.pipe(from_polars)\n\n    def slice_tail(self, n = 5, *, by = None):\n        \"\"\"\n        Grab bottom rows from a data frame\n\n        Parameters\n        ----------\n        n : int\n            Number of rows to grab\n        by : str, list\n            Columns to group by\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.slice_tail(2)\n        &gt;&gt;&gt; df.slice_tail(1, by = 'c')\n        \"\"\"\n        col_order = self.names\n        if _uses_by(by):\n            df = super(tibble, self).group_by(by).tail(n)\n        else:\n            df = super(tibble, self).tail(n)\n        df = df.select(col_order)\n        return df.pipe(from_polars)\n\n    def summarise(self, *args,\n                  by = None,\n                  **kwargs):\n        \"\"\"Alias for `.summarize()`\"\"\"\n        return self.summarize(*args, by = by, **kwargs)\n\n    def summarize(self, *args,\n                  by = None,\n                  **kwargs):\n        \"\"\"\n        Aggregate data with summary statistics\n\n        Parameters\n        ----------\n        *args : Expr\n            Column expressions to add or modify\n        by : str, list\n            Columns to group by\n        **kwargs : Expr\n            Column expressions to add or modify\n\n        Returns\n        -------\n        tibble\n            A tibble with the summaries\n\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')))\n        &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n        ...              by = 'c')\n        &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n        ...              max_b = tp.max(col('b')))\n        \"\"\"\n        exprs = _as_list(args) + _kwargs_as_exprs(kwargs)\n        if _uses_by(by):\n            out = super(tibble, self).group_by(by).agg(exprs)\n        else:\n            out = super(tibble, self).select(exprs)\n        return out.pipe(from_polars)\n\n    def tail(self, n = 5, *, by = None):\n        \"\"\"Alias for `.slice_tail()`\"\"\"\n        return self.slice_tail(n, by = by)\n\n    def to_dict(self, *, as_series = True):\n        \"\"\"\n        Aggregate data with summary statistics\n\n        Parameters\n        ----------\n        as_series : bool\n            If True - returns the dict values as Series\n            If False - returns the dict values as lists\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.to_dict()\n        &gt;&gt;&gt; df.to_dict(as_series = False)\n        \"\"\"\n        return super().to_dict(as_series = as_series)\n\n    def to_pandas(self):\n        \"\"\"\n        Convert to a pandas DataFrame\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.to_pandas()\n        \"\"\"\n        # keep order of factors (pl.Enum)\n        enum_columns = [col for col in self.names if self.pull(col).dtype == pl.Enum]\n        res = self.to_polars().to_pandas()\n        if enum_columns :\n            for col in enum_columns:\n                # Get unique categories in order of appearance\n                categories_in_order = self.pull(col).cat.get_categories().to_list()\n                # Convert the column to Categorical\n                res[col] = pd.Categorical(\n                    res[col],\n                    categories=categories_in_order,\n                    ordered=True\n                )\n        return res\n\n    def to_polars(self):\n        \"\"\"\n        Convert to a polars DataFrame\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.to_polars()\n        \"\"\"\n        self = copy.copy(self)\n        self.__class__ = pl.DataFrame\n        return self\n\n    def unite(self, col = \"_united\", unite_cols = [], sep = \"_\", remove = True):\n        \"\"\"\n        Unite multiple columns by pasting strings together\n\n        Parameters\n        ----------\n        col : str\n            Name of the new column\n        unite_cols : list\n            List of columns to unite\n        sep : str\n            Separator to use between values\n        remove : bool\n            If True removes input columns from the data frame\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble(a = [\"a\", \"a\", \"a\"], b = [\"b\", \"b\", \"b\"], c = range(3))\n        &gt;&gt;&gt; df.unite(\"united_col\", unite_cols = [\"a\", \"b\"])\n        \"\"\"\n        if len(unite_cols) == 0:\n            unite_cols = self.names\n        else: \n            unite_cols = _col_exprs(unite_cols)\n            unite_cols = self.select(unite_cols).names\n        out = self.mutate(str_c(*unite_cols, sep = sep).alias(col))\n        out = out.relocate(col, before = unite_cols[0])\n        if remove == True:\n            out = out.drop(unite_cols)\n        return out\n\n    def write_csv(self,\n                  file = None,\n                  has_headers = True,\n                  sep = ','):\n        \"\"\"Write a data frame to a csv\"\"\"\n        return super().write_csv(file, include_header = has_headers, separator = sep)\n\n    def write_parquet(self,\n                      file = str,\n                      compression = 'snappy',\n                      use_pyarrow = False,\n                      **kwargs):\n        \"\"\"Write a data frame to a parquet\"\"\"\n        return super().write_parquet(file, compression = compression, use_pyarrow = use_pyarrow, **kwargs)\n\n    def group_by(self, group, *args, **kwargs):\n        \"\"\"\n        Takes an existing tibble and converts it into a grouped tibble\n        where operations are performed \"by group\". ungroup() happens\n        automatically after the operation is performed.\n\n        Parameters\n        ---------- \n        group : str, list\n            Variable names to group by.\n\n        Returns\n        -------\n        Grouped tibble\n            A tibble with values grouped by one or more columns.\n        \"\"\"\n        res = TibbleGroupBy(self, group, maintain_order=True)\n        return res\n\n    def nest(self, by, *args, **kwargs):\n        \"\"\"\n        creates a nested tibble\n\n        Parameters\n        ----------\n        by : list, str\n            Columns to nest on\n\n        kwargs :\n            data : list of column names\n               columns to select to include in the nested data\n               If not provided, include all columns except the ones\n               used in 'by'\n\n             key : str\n               name of the resulting nested column. \n\n             names_sep : str\n                If not provided (default), the names in the nested\n                data will come from the former names. If a string,\n                the new inner names in the nested dataframe will use\n                the outer names with names_sep automatically stripped.\n                This makes names_sep roughly\n                symmetric between nesting and unnesting.\n\n        Returns\n        -------\n        tibble\n            The resulting tibble with have a column that contains\n            nested tibbles\n\n        \"\"\"\n        key  = kwargs.get(\"key\", 'data')\n        data = kwargs.get(\"data\", [c for c in self.names if c not in by])\n        names_sep = kwargs.get(\"names_sep\", None)\n\n        out = (self\n               .group_by(by)\n               .agg(**{\n                   key : pl.struct(data).map_elements(\n                       # lambda cols: from_polars( pl.DataFrame(cols.to_list()) ) )\n                       lambda cols: from_polars(pl.DataFrame({'data':cols}).unnest('data')) )\n                       # lambda cols: tibble(cols.to_list()) )\n               })\n               .pipe(from_polars)\n               )\n        # to keep enum order in the nested data\n        # enum_columns = [col for col in self.select(data).names\n        #                 if self.pull(col).dtype == pl.Enum]\n        # if enum_columns:\n        #     for col in enum_columns:\n        #         cats = self.pull(col).cat.get_categories().to_list()\n        #         print(cats)\n        #         out = out.mutate(**{key : map([key], lambda row:\n        #                                       row[0].mutate(col = as_factor(col, cats) )\n        #                                       }\n        # # to keep factors\n        # factors = [col for col in self.select(data).names\n        #                 if self.pull(col).dtype == pl.Categorical]\n        # if factors:\n        #     for col in factors:\n        #         out = out.mutate(**{col : as_factor(col)})\n\n\n        if names_sep is not None:\n            new_names = {col:f\"{col}_{names_sep}\" for col in data}\n            print(new_names)\n            out = out.mutate(**{key:col(key).map_elements(lambda row: row.rename(new_names))})\n        return out\n\n    def unnest(self, col):\n        \"\"\"\n        Unnest a nested tibble\n        Parameters\n        ----------\n        col : str\n            Columns to unnest\n\n        Returns\n        -------\n        tibble\n            The nested tibble will be expanded and become unested\n            rows of the original tibble.\n\n        \"\"\"\n        assert isinstance(col, str), \"'col', must be a string\"\n        # not run: error if nested df has different columns\n        # out = (self\n        #        .mutate(**{\n        #            col : pl.col(col).map_elements(lambda d: d.to_struct())\n        #        })\n        #        .to_polars()\n        #        .explode(col)\n        #        .unnest(col)\n        #        )\n        # return out.pipe(from_polars)\n        out = tibble()\n        for row in self.to_polars().iter_rows(named=True):\n            n = row[col].nrow\n            ids = {c:v for c, v in row.items() if c not in col}\n            cols = list(ids.keys())\n            df_ids = from_polars(pl.DataFrame(ids)\n                                 .with_columns(pl.col(cols) .repeat_by(n))\n                                 .explode(cols))\n            out = out.bind_rows(df_ids.bind_cols(row[col]))\n        return out\n\n    def crossing(self, *args, **kwargs):\n        \"\"\"\n        Expands the existing tibble for each value of the\n        variables used in the `crossing()` argument. See Returns.\n\n        Parameters\n        ----------\n        *args : list\n            One unamed list is accepted. \n\n        *kwargs : list\n            keyword will be the variable name, and the values in the list\n            will be in the expanded tibble\n\n        Returns\n        ------- \n        tibble\n            A tibble with varibles containing all combinations of the\n            values in the arguments passed to `crossing()`. The original\n            tibble will be replicated for each unique combination.\n\n        Examples\n        -------- \n        &gt;&gt;&gt; df = tp.tibble({'a': [1, 2], \"b\": [3, 5]})\n        &gt;&gt;&gt; df\n        shape: (2, 2)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   a     b \u2502\n        \u2502 i64   i64 \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502   1     3 \u2502\n        \u2502   2     5 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        &gt;&gt;&gt; df.crossing(c = ['a', 'b', 'c'])\n        shape: (6, 3)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   a     b   c   \u2502\n        \u2502 i64   i64   str \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502   1     3   a   \u2502\n        \u2502   1     3   b   \u2502\n        \u2502   1     3   c   \u2502\n        \u2502   2     5   a   \u2502\n        \u2502   2     5   b   \u2502\n        \u2502   2     5   c   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \"\"\"\n        out = self.mutate(*args, **kwargs).to_polars()\n        for var,_ in kwargs.items():\n            out = out.explode(var)\n        return out.pipe(from_polars)\n\n    def glimpse(self, regex='.'):\n        \"\"\"\n        Print compact information about the data\n\n        Parameters\n        ----------\n        regex : str, list, dict\n            Return information of the variables that match the regular \n            expression, the list, or the dictionary. If dictionary is \n            used, the variable names must be the dictionary keys.\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        assert isinstance(regex, str) or\\\n            isinstance(regex, list) or\\\n            isinstance(regex, dict), \"regex must be a list, dict, or regular expression\"\n\n        # if isinstance(regex, str):\n        #     df = self.select(regex=regex)\n        # elif isinstance(regex, dict):\n        #     df = self.select(names=list(regex.keys()))\n        # else:\n        #     df = self.select(names=regex)\n        print(f\"Columns matching pattern '{regex}':\")\n        df = self.select(matches(regex)).to_pandas()\n        size_col=80\n        header_var = 'Var'\n        header_type = 'Type'\n        header_uniq = 'Uniq'\n        header_missing = 'Miss'\n        header_missing_perc = '(%)'\n        header_head = 'Head'\n        # \n        length_col  = np.max([len(header_var)] +\n                             [len(col) for col  in df.columns])\n        length_type = np.max([len(header_type)] +\n                             [len(col) for col  in\n                              df.dtypes.astype(str).values]) + 2\n        length_nvalues = np.max([len(header_uniq),\n                                 len(str(np.max(df\n                                                .apply(pd.unique)\n                                                .apply(len))))])\n        length_missing = np.max([len(header_missing)] +\n                                df.isna().sum().astype(str).apply(len).tolist())\n        try:\n            length_missing_perc = np.max([len(header_missing_perc), \n                                            len((100*df.isna().sum()/df.shape[0])\n                                                .max().astype(int)\n                                                .astype(str))+2]\n                                           )\n        except:\n            length_missing_perc = 3\n\n        length_head = size_col - (length_col + length_type + length_nvalues + length_missing )\n        # \n        header = (f\"{header_var:&gt;{length_col}s} \"+\n                  f\"{header_type:{length_type}s}\"+\n                  f\"{header_uniq:&gt;{length_nvalues}s} \"+\n                  f\"{header_missing:&gt;{length_missing}s} \"+\n                  f\"{header_missing_perc:&gt;{length_missing_perc}s} \"+\n                  f\"{header_head:{length_head}s}\")\n        print(header)\n        hline = \"-\"*size_col\n        # print(hline)\n        for col in df.columns:\n            dtype = str(df[col].dtype)\n            nvalues = len(df[col].unique())\n            missings = df[col].isna().sum()\n            missings_perc = str(int(100*missings/self.nrow))+\"%\"\n            # \n            vals = str(df[col].values)\n            vals = vals[:length_head] + (vals[length_head+1:], '...')[len(vals) &gt; length_head]\n            # \n            print(f\"{col:&gt;{length_col}.{length_col}s} \"+\n                  f\"{'&lt;'+dtype+'&gt;':{length_type}.{length_type}s}\"+\n                  f\"{nvalues:&gt;{length_nvalues}d} \"+\n                  f\"{missings:&gt;{length_missing}d}\"+\n                  f\"{missings_perc:&gt;{length_missing_perc}s} \"\n                  f\"{vals:.{length_head+3}s}\")\n        # print(hline)\n        # print(header)\n        print('')\n        print(f\"[Rows: {self.nrow}; Columns {self.ncol}]\")\n        return None\n\n    # Not tidy functions, but useful from pandas/polars \n    # -------------------------------------------------\n    def replace(self, rep, regex=False):\n        \"\"\"\n        Replace method from polars pandas. Replaces values of a column.\n\n        Parameters\n        ----------\n        rep : dict\n            Format to use polars' replace:\n                {&lt;varname&gt;:{&lt;old value&gt;:&lt;new value&gt;, ...}}\n            Format to use pandas' replace:\n                {&lt;old value&gt;:&lt;new value&gt;, ...}\n\n        regex : bool\n            If true, replace using regular expression. It uses pandas\n            replace()\n\n        Returns\n        -------\n        tibble\n            Original tibble with values of columns replaced based on\n            rep`.\n        \"\"\"\n        if regex or not all(isinstance(value, dict) for value in rep.values()):\n            engine = 'pandas'\n        else:\n            engine = 'polars'\n\n        if engine=='polars':\n            out = self.to_polars()\n            for var, rep in rep.items():\n                try:\n                    out = out.with_columns(**{var : pl.col(var).replace(rep)})\n                except :\n                    out = out.with_columns(**{var : pl.col(var).replace_strict(rep)})\n            out = out.pipe(from_polars)\n        else:\n            out = self.to_pandas()\n            out = out.replace(to_replace=rep, regex=regex)\n            out = out.pipe(from_pandas)\n\n        return out\n\n    def print(self, n=1000, ncols=1000, str_length=1000, digits=2):\n        \"\"\"\n        Print the DataFrame\n\n        Parameters\n        ----------\n        n : int, default=1000\n            Number of rows to print\n\n        ncols : int, default=1000\n            Number of columns to print\n\n        str_length : int, default=1000\n            Maximum length of the strings.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        with pl.Config(set_tbl_rows=n,\n                       set_tbl_cols=ncols,\n                       float_precision=digits,\n                       fmt_str_lengths=str_length):\n            print(self)\n\n    # Statistics \n    # ----------\n    def descriptive_statistics(self, vars=None, groups=None,\n                               include_categorical=True,\n                               include_type=False):\n        \"\"\"\n        Compute descriptive statistics for numerical variables and optionally\n        frequency statistics for categorical variables, with support for grouping.\n\n        Parameters\n        ----------\n        vars : str, list, dict, or None, default None\n            The variables for which to compute statistics.\n            - If None, all variables in the dataset (as given by `self.names`) are used.\n            - If a string, it is interpreted as a single variable name.\n            - If a list, each element is treated as a variable name.\n            - If a dict, keys are variable names and values are their labels.\n        groups : str, list, dict, or None, default None\n            Variable(s) to group by when computing statistics.\n            - If None, overall statistics are computed.\n            - If a string, it is interpreted as a single grouping variable.\n            - If a list, each element is treated as a grouping variable.\n            - If a dict, keys are grouping variable names and values are their labels.\n        include_categorical : bool, default True\n            Whether to include frequency statistics for categorical variables in the output.\n        include_type : bool, default False\n            If True, adds a column indicating the variable type (\"Num\" for numerical, \"Cat\" for categorical).\n\n        Returns\n        -------\n        tibble\n            A tibble containing the descriptive statistics.\n            For numerical variables, the statistics include:\n                - N: count of non-missing values\n                - Missing (%): percentage of missing values\n                - Mean: average value\n                - Std.Dev.: standard deviation\n                - Min: minimum value\n                - Max: maximum value\n            If grouping is specified, these statistics are computed for each group.\n            When `include_categorical` is True, frequency statistics for categorical variables are appended\n            to the result.\n        \"\"\"\n        assert isinstance(vars, str) or isinstance(vars, list) or \\\n            isinstance(vars, dict) or vars is None, \\\n            \"'vars' must be a string, dict, or list\"\n        assert isinstance(groups, str) or isinstance(groups, list) or \\\n            isinstance(groups, dict) or groups is None, \\\n            \"'groups' must be a string, dict, or list\"\n\n        if vars is None:\n            vars = {v:v for v in self.names}\n        elif isinstance(vars, str):\n            vars = {vars:vars}\n        elif isinstance(vars, list):\n            vars = {v:v for v in vars}\n\n        if isinstance(groups, str):\n            groups = {groups:groups}\n        elif isinstance(groups, list):\n            groups = {g:g for g in groups}\n\n        # select only numerical\n        vars_num = {var:label for var, label in vars.items() if\n                    self.to_polars().schema[var].is_numeric()}\n        # select only numerical\n        vars_cat = {var:label for var, label in vars.items() if\n                    not self.to_polars().schema[var].is_numeric()}\n\n        # compute statistics for numerical variables\n        if groups is None:\n            res = self.__descriptive_statistics__(self, vars_num)\n        else:\n            res = (self\n                   .select(vars_num | groups)\n                   .nest(list(groups.values()))\n                   .mutate(summary = map(['data'], lambda col:\n                                         self.__descriptive_statistics__(col[0],\n                                                                         vars=vars_num)))\n                   .drop('data')\n                   .unnest('summary')\n                   )\n\n        n = self.nrow\n        res = (res\n               .mutate(null_count = 100*pl.col(\"null_count\")/n,\n                       count = as_integer('count'))\n               .rename({\"count\":'N',\n                        'null_count':'Missing (%)',\n                        \"mean\":\"Mean\",\n                        'std':'Std.Dev.',\n                        'min':\"Min\",\n                        'max':'Max'\n                        })\n               )\n        if include_type:\n            res = res.mutate(Type='Num')\n\n        # compute statistics for categorical variables\n        if vars_cat and include_categorical: \n            res_cat = tibble()\n            for var_cat, label in vars_cat.items():\n                res_cat = res_cat.bind_rows(\n                    self\n                    .freq({var_cat:label}, groups=groups)\n                    .drop('low', 'high')\n                    .rename({'Freq':\"Mean\",\n                             label:'Variable'})\n                    .mutate(Variable = label + \" (\"+pl.col(\"Variable\")+\")\")\n                    .replace_null({'Variable': label + \" (Missing)\"})\n                )\n            if include_type:\n                    res_cat = res_cat.mutate(Type='Cat')\n            res = res.bind_rows(res_cat)\n\n        res = res.arrange('Variable')\n        return res\n\n    def __descriptive_statistics__(self, data, vars=None):\n            res = (data\n                   .select(vars)\n                   .to_polars()\n                   .describe()\n                   .pipe(from_polars)\n                   .pivot_longer(cols=list(vars.values()), names_to='Variable', values_to='value')\n                   .pivot_wider(names_from='statistic', values_from='value')\n                   )\n            return res\n\n    def freq(self, vars=None, groups=None, na_rm=False, na_label=None):\n        \"\"\"\n        Compute frequency table.\n\n        Parameters\n        ----------\n        vars : str, list, or dict\n            Variables to return value frequencies for. \n            If a dict is provided, the key should be the variable name\n            and the values the variable label for the output\n\n        groups : str, list, dict, or None, optional\n            Variable names to condition marginal frequencies on. \n            If a dict is provided, the key should be the variable name\n            and the values the variable label for the output\n            Defaults to None (no grouping).\n\n        na_rm : bool, optional\n            Whether to include NAs in the calculation. Defaults to False.\n\n        na_label : str\n            Label to use for the NA values\n\n        Returns\n        -------\n        tibble\n            A tibble with relative frequencies and counts.\n        \"\"\"\n        assert vars, \"Parameter 'vars' not informed.\"\n        assert isinstance(groups, str) or \\\n            isinstance(groups, list) or\\\n            isinstance(groups, dict) or\\\n            groups is None, \"Incorrect 'groups' argument format. See documentation.\"\n\n        vars_all = []\n\n        if groups is None:\n            groups = {}\n        elif isinstance(groups, str):\n            groups = {groups:groups}\n        elif isinstance(groups, list):\n            groups = {g:g for g in groups}\n        vars_all += list(groups.keys())\n\n        if vars is None:\n            vars = {v:v for v in self.names}\n        elif isinstance(vars, str):\n            vars = {vars:vars}\n        elif isinstance(vars, list):\n            vars = {v:v for v in vars}\n        vars_all += list(vars.keys())\n\n        # labels = False\n        # if isinstance(vars, str):\n        #     vars = [vars]\n        # elif isinstance(vars, dict):\n        #     labels = True\n        #     vars_labels = vars\n        #     vars = list(vars.keys())\n        # elif type(vars) is {}.keys().__class__:\n        #     vars = list(vars)\n\n        # if groups and not isinstance(groups, list):\n        #     groups = [groups]\n        # if groups:\n        #     vars = groups + vars\n\n        res=self.select(vars_all)\n\n        if not na_rm:\n            if na_label is not None:\n                res=res.replace_null({var:na_label for var in vars})\n        else:\n            res=res.drop_null()\n\n        if not groups:\n            res=(res\n                   .group_by(vars_all)\n                 .summarize(n = n())\n                 .mutate(\n                       p     = pl.col(\"n\")/pl.col(\"n\").sum(),\n                       freq  = 100*pl.col(\"p\"),\n                       stdev = 100*np.sqrt((pl.col('p')*(1-pl.col('p')))/pl.col('n'))\n                 )\n            )\n            # for var in vars:\n            #     res = self.__tab_reorder_na__(res, var, na_label)\n        else:\n            res = (res\n                   .group_by(vars_all)\n                   .summarize(n = n())\n                   .group_by(list(groups.keys()))\n                   .mutate(\n                       p     = pl.col(\"n\")/pl.col(\"n\").sum(),\n                       freq  = 100*pl.col(\"p\"),\n                       stdev = 100*np.sqrt((pl.col('p')*(1-pl.col('p')))/pl.col('n'))\n                   )\n            )\n\n        # vars.reverse()\n        res = (\n            res\n            .drop('p')\n            .mutate(n = as_integer('n'),\n                    low  = pl.col('freq')-1.96*pl.col('stdev'),\n                    high = pl.col('freq')+1.96*pl.col('stdev'))\n            .rename({'n':'N',\n                     'stdev':'Std.Dev.',\n                     'freq':'Freq'}, tolower=False)\n            .arrange(list(vars.keys()))\n        )\n\n        res = res.rename(vars | groups)\n        return res\n\n    def tab(self, row, col, groups=None,\n            margins=True, normalize='all',#row/columns\n            margins_name='Total', stat='both',\n            na_rm=True, na_label='NA', digits=2):\n        \"\"\"\n        Create a 2x2 contingency table for two categorical variables, with optional grouping,\n        margins, and normalization.\n\n        Parameters\n        ----------\n        row : str\n            Name of the variable to be used for the rows of the table.\n        col : str\n            Name of the variable to be used for the columns of the table.\n        groups : str or list of str, optional\n            Variable name(s) to use as grouping variables. When provided, a separate 2x2 table\n            is generated for each group.\n        margins : bool, default True\n            If True, include row and column totals (margins) in the table.\n        normalize : {'all', 'row', 'columns'}, default 'all'\n            Specifies how to compute the marginal percentages in each cell:\n              - 'all': percentages computed over the entire table.\n              - 'row': percentages computed across each row.\n              - 'columns': percentages computed down each column.\n        margins_name : str, default 'Total'\n            Name to assign to the row and column totals.\n        stat : {'both', 'perc', 'n'}, default 'both'\n            Determines the statistic to display in each cell:\n              - 'both': returns both percentages and sample size.\n              - 'perc': returns percentages only.\n              - 'n': returns sample size only.\n        na_rm : bool, default True\n            If True, remove rows with missing values in the `row` or `col` variables.\n        na_label : str, default 'NA'\n            Label to use for missing values when `na_rm` is False.\n        digits : int, default 2\n            Number of digits to round the percentages to.\n\n        Returns\n        -------\n        tibble\n            A contingency table as a tibble. The table contains counts and/or percentages as specified\n            by the `stat` parameter, includes margins if requested, and is formatted with group headers\n            when grouping variables are provided.\n        \"\"\"\n        tab = self.select(row, col, groups).mutate(**{row:as_character(row),\n                                                      col:as_character(col)})\n        vars_row = row\n        vars_col = col\n        if na_rm:\n            tab = tab.drop_null()\n        else:\n            repl = {var:na_label for var in [row, col]}\n            tab = tab.replace_null(repl)\n        tab = tab.to_pandas()\n        if groups:\n            groups = [groups] if isinstance(groups, str) else groups\n            ngroups=len(groups)\n            resn = self.__tab_groups__(tab, vars_row, vars_col, normalize=False,\n                                       margins=margins, margins_name=margins_name,\n                                       groups=groups)\n            resp = self.__tab_groups__(tab, vars_row, vars_col, normalize,\n                                       margins, margins_name, groups)\n        else:\n            ngroups=0\n            resn = self.__tab__(tab, vars_row, vars_col, normalize=False,\n                                margins=margins, margins_name=margins_name)\n            resp = self.__tab__(tab, vars_row, vars_col, normalize=normalize,\n                                margins=margins, margins_name=margins_name)\n        colsn=resn.columns[ngroups+1:]\n        colsp=resp.columns[ngroups+1:]\n        res=resp.iloc[:,0:ngroups+1]\n\n        if stat=='both':\n            for coln, colp in zip(colsn, colsp):\n                col = [f\"{round(100*p, digits)} % ({n})\" for p,n\n                       in zip(resp[colp], resn[coln])]\n                res = res.assign(**{coln:col})\n        elif stat=='perc':\n            for colp in colsp:\n                res = res.assign(**{str(colp):100*resp[colp]})\n        else:\n            for coln in colsn:\n                res = res.assign(**{str(coln):100*resp[coln]})\n        # Group columns using varname as label\n        ncat = len(tab[vars_col].unique())\n        ngroups = 0 if not groups else len(groups)\n        col_groups = ['']*(ngroups+1) + [vars_col]*ncat+['']\n        col_ix = pd.MultiIndex.from_arrays([col_groups, res.columns])\n        res.columns = col_ix\n        res.columns.names = ['', '']\n        res.columns.name = ''\n        res.columns = [col[1] for col in res.columns]\n        res = self.__tab_reorder_na__(res, row, na_label)\n        return from_pandas(res)\n\n    def __tab__(self, tab, row, col, normalize='all', margins=True, margins_name='Total'):\n        if normalize=='row':\n            normalize='index'\n        if normalize=='column' or normalize=='col':\n            normalize='columns'\n        res = pd.crosstab(index=[tab[row]],\n                          columns=[tab[col]],\n                          margins=margins, margins_name=margins_name,\n                          normalize=normalize)\n        res = res.reset_index(drop=False)\n        return res\n\n    def __tab_groups__(self, tab, vars_row, vars_col, normalize,\n                       margins, margins_name, groups):\n        res = (tab\n               .groupby(groups)\n               .apply(self.__tab__,\n                      vars_row, vars_col, normalize, margins, margins_name)\n               .reset_index(drop=False)\n        )\n        cols = [col for cidx, col in enumerate(list(res.columns) ) if\n                not bool(re.search(pattern='^level_[0-9]$', string=col))]\n        res=res.filter(cols)\n        return res\n\n    def __tab_reorder_na__(self, tab, row, na_label):\n        tab = from_pandas(tab).to_polars()\n        # Check if \"Total\" column exists and place \"AB\" before it\n        if na_label in tab.columns:\n            if \"Total\" in tab.columns:\n                total_index = tab.columns.index(\"Total\")\n                columns = tab.columns[:total_index] + [na_label] + tab.columns[total_index:]\n                if na_label in tab.columns:\n                    columns.remove(na_label)  # Avoid duplication of \"AB\"\n                tab = tab.select(columns)\n\n        # Check if \"Total\" row exists and move \"ABC\" before it\n        if na_label in tab[row]:\n            na_row = tab.filter(tab[row] == na_label)\n            non_na_rows = tab.filter(tab[row] != na_label)\n            if \"Total\" in tab[row].to_list():\n                total_row_index = non_na_rows[row].to_list().index(\"Total\")\n                before_total_rows = non_na_rows[:total_row_index]\n                after_total_rows = non_na_rows[total_row_index:]\n                tab = pl.concat([before_total_rows, na_row, after_total_rows], how=\"vertical\")\n\n            else:\n                tab = pl.concat([non_na_rows, na_row], how=\"vertical\")\n        return tab.to_pandas()\n\n    # Reporting \n    # ---------\n    def to_latex(self,\n                 header = None,\n                 digits = 4,\n                 caption = None,\n                 label = None,\n                 align = None,\n                 na_rep  =  '',\n                 position = '!htb',\n                 group_rows_by = None,\n                 group_title_align = 'l',\n                 footnotes = None,\n                 index = False,\n                 escape = False,\n                 longtable = False,\n                 longtable_singlespace = True,\n                 rotate = False,\n                 scale = True,\n                 parse_linebreaks=True,\n                 tabular = False\n                 ):\n        \"\"\"\n        Convert the object to a LaTeX tabular representation.\n\n        Parameters\n        ----------\n        header : list of tuples, optional\n            The column headers for the LaTeX table. Each tuple corresponds to a column.\n            Ex: This will create upper level header with grouped columns\n                [(\"\", \"col 1\"),\n                 (\"Group A\", \"col 2\"),\n                 (\"Group A\", \"col 3\"),\n                 (\"Group B\", \"col 4\")\n                 (\"Group B\", \"col 5\"),\n                  ]\n                This will create two upper level header with grouped columns\n                [(\"Group 1\", \"\"       , \"col 1\"),\n                 (\"Group 1\", \"Group A\", \"col 2\"),\n                 (\"Group 1\", \"Group A\", \"col 3\"),\n                 (\"\"       , \"Group B\", \"col 4\")\n                 (\"\"       , \"Group B\", \"col 5\"),\n                  ]\n        digits : int, default=4\n            Number of decimal places to round the numerical values in the table.\n\n        caption : str, optional\n            The caption for the LaTeX table.\n\n        label : str, optional\n            The label for referencing the table in LaTeX.\n\n        align : str, optional\n            Column alignment specifications (e.g., 'lcr').\n\n        na_rep : str, default=''\n            The representation for NaN values in the table.\n\n        position : str, default='!htbp'\n            The placement option for the table in the LaTeX document.\n\n        footnotes : dict, optional\n            A dictionary where keys are column alignments ('c', 'r', or 'l')\n            and values are the respective footnote strings.\n\n        group_rows_by : str, default=None\n            Name of the variable in the data with values to group\n            the rows by.\n\n        group_title_align str, default='l'\n            Alignment of the title of each row group\n\n        index : bool, default=False\n            Whether to include the index in the LaTeX table.\n\n        escape : bool, default=False\n            Whether to escape LaTeX special characters.\n\n        longtable : bool, deafult=False\n            If True, table spans multiple pages\n\n        longtable_singlespace : bool\n            Force single space to longtables\n\n        rotate : bool\n            Whether to use landscape table\n\n        scale : bool, default=True\n            If True, scales the table to fit the linewidth when\n            the table exceeds that size\n            Note: ignored when longtable=True. This is a LaTeX\n                  limitation because longtable does not use\n                  tabular.\n\n        parse_linebreaks : book, default=True\n            If True, parse \\\\n and replace it with \\\\makecel\n            to produce linebreaks\n\n        tabular : bool, default=False\n            Whether to use a tabular format for the output.\n\n        Returns\n        -------\n            str\n                A LaTeX formatted string of the tibble.\n        \"\"\"\n\n        assert footnotes is None or isinstance(footnotes, dict),\\\n            \"'footnote' must be a dictionary\"\n\n        # this must be the first operation\n        if group_rows_by is not None:\n            self = self.arrange(group_rows_by)\n            tabm = self.to_pandas().drop([group_rows_by], axis=1)\n        else:\n            tabm = self.to_pandas()\n        ncols = tabm.shape[1]\n\n        if tabular and not longtable:\n            position=None\n\n        if align is None:\n            align = 'l'*ncols\n\n        if header is not None:\n            tabm.columns = pd.MultiIndex.from_tuples(header)\n\n        tabl = (tabm\n                # .round(digits)\n                # .astype(str)\n                .to_latex(index = index,\n                          escape = escape,\n                          caption = caption,\n                          label = label,\n                          sparsify = True,\n                          multirow = True,\n                          multicolumn = True,\n                          multicolumn_format = 'c',\n                          column_format = align,\n                          bold_rows = True,\n                          na_rep = na_rep,\n                          float_format=f\"%.{digits}f\",\n                          position = position\n                          ))\n\n        # split to add elements\n        rows = tabl.splitlines()\n\n        if group_rows_by is not None:\n            rows = self.__to_latex_group_rows__(group_rows_by, group_title_align, ncols, rows)\n\n        # add centering\n        row = [i for i, txt in enumerate(rows) if\n               bool(re.search(pattern='begin.*tabular', string=txt))][0]\n        rows.insert(row,f\"\\\\centering\")\n\n        footnotes_formated = \"\"\n        if footnotes is not None:\n            for align_note, footnote in footnotes.items():\n                footnote = [footnote] if isinstance(footnote, str) else footnote\n                for fni in footnote:\n                    notes = f\"\\\\multicolumn{{{ncols}}}{{{align_note}}}{{{fni}}}\\\\\\\\\"\n                    footnotes_formated += notes\n                    if not longtable:\n                        row = [idx for idx, s in enumerate(rows) if 'bottomrule' in s ][0]\n                        rows.insert(row + 1, notes)\n\n\n        # rejoin table\n        tabl = \"\\n\".join(rows)\n\n        # add midrules\n        if header is not None:\n            tabl = self.__to_latex_add_midrules_to_table__(tabl)\n\n        if longtable:\n            tabl = self.__to_latex_multipage__(tabl, caption, ncols, align,\n                                               label, position,\n                                               footnotes_formated,\n                                               longtable_singlespace)\n\n        if rotate:\n            tabl = re.sub(pattern=\"^\", repl='\\\\\\\\begin{landscape}', string=tabl)\n            tabl = re.sub(pattern=\"$\", repl='\\\\\\\\end{landscape}', string=tabl)\n\n        if scale and not longtable:\n            box = '\\\\resizebox{\\\\ifdim\\\\width&gt;\\\\linewidth\\\\linewidth\\\\else\\\\width\\\\fi}{!}{'\n            tabl = tabl.replace('\\\\begin{tabular}', f\"{box}\\n\\\\begin{{tabular}}\")\n            tabl = tabl.replace('\\\\end{tabular}', \"\\\\end{tabular}}\")\n\n        # linebreaks:\n        if parse_linebreaks:\n            tabl = self.__to_latex_breaklines__(tabl)    \n\n        return tabl\n\n    def __to_latex_process_header_line_for_cmid__(self, line: str) -&gt; str:\n        # Given a header line (without the trailing newline),\n        # parse for multicolumn commands and generate a line of cmidrule(s)\n        # based on the non-empty group labels.\n\n        # Example:\n        #   Input line: r\"\\\\multicolumn{3}{c}{Combine} &amp; \\\\multicolumn{3}{c}{} \\\\\"\n        #   Output: r\"\\\\cmidrule(lr){1-3} \\\\\"\n\n        # Remove trailing \"\\\\\" if present\n        line_clean = line.strip()\n        if line_clean.endswith(r'\\\\'):\n            line_clean = line_clean[:-2].strip()\n\n        # Split the row into cells (assuming &amp; is the column separator)\n        cells = [cell.strip() for cell in line_clean.split('&amp;')]\n        col_counter = 0\n        midrules = []\n\n        # Regex to capture multicolumn: number of columns and content.\n        # This assumes a simple structure without nested braces.\n        multicolumn_pattern = re.compile(r'\\\\multicolumn\\{(\\d+)\\}\\{[^}]*\\}\\{([^}]*)\\}')\n\n        for cell in cells:\n            m = multicolumn_pattern.search(cell)\n            if m:\n                span = int(m.group(1))\n                content = m.group(2).strip()\n                start = col_counter + 1\n                end = col_counter + span\n                # Only add a midrule if the cell\u2019s content is not empty\n                if content:\n                    midrules.append(r'\\cmidrule(lr){' + f\"{start}-{end}\" + '}')\n                col_counter += span\n            else:\n                # A normal cell occupies one column.\n                col_counter += 1\n\n        if midrules:\n            # Join the midrule commands (separated by a space) and add the trailing \\\\.\n            return \" \".join(midrules) #+ r' \\\\'\n        else:\n            return \"\"\n\n    def __to_latex_add_midrules_to_table__(self, latex_table: str) -&gt; str:\n        # Given a LaTeX table (as a string) that uses booktabs commands,\n        # insert automatically generated cmidrule lines for header rows that\n        # contain multicolumn cells.\n\n        # Assumes that the header is contained between the \\\\toprule and the first \\\\midrule.\n        lines = latex_table.splitlines()\n        new_lines = []\n        in_header = False\n        header_lines = []  # temporarily hold header lines\n\n        for line in lines:\n            # When we hit \\toprule, we start the header section.\n            if r'\\toprule' in line:\n                in_header = True\n                new_lines.append(line)\n            # When we hit the first \\midrule, process any stored header rows.\n            elif in_header and r'\\midrule' in line:\n                # Process each header line: output the line and, if applicable, a cmidrule line.\n                for hline in header_lines:\n                    new_lines.append(hline)\n                    cmid_line = self.__to_latex_process_header_line_for_cmid__(hline)\n                    if cmid_line:\n                        new_lines.append(cmid_line)\n                # Now add the \\midrule line and stop header processing.\n                new_lines.append(line)\n                in_header = False\n                header_lines = []\n            elif in_header:\n                # Collect header rows (these are the lines between \\toprule and \\midrule).\n                header_lines.append(line)\n            else:\n                # Outside the header section, just pass the line along.\n                new_lines.append(line)\n\n        return \"\\n\".join(new_lines)\n\n    def __to_latex_multipage__(self, tabl, caption, ncols, align,\n                               label, position, footnote,\n                               longtable_singlespace):\n        header_old = self.__to_latex_extract_header__(tabl)\n        header_new = f\"\"\"\n          {header_old}\n\n        \\\\endfirsthead\n          \\\\caption[]{{ {caption} }}\\\\\\\\\n\n         \\\\multicolumn{{{ncols}}}{{l}}{{\\\\textit{{(continued)}}}}\\\\\\\\\n        \\\\toprule\n          {header_old}\n        \\\\midrule\n        \\\\endhead\n\n        \\\\bottomrule\n        {footnote}\n        \\\\multicolumn{{{ncols}}}{{r@{{}}}}{{\\\\textit{{(continued \\\\ldots)}}}}\\\\\\\\\n        \\\\endfoot\n        {footnote}\n        \\\\endlastfoot\n        \"\"\"\n\n        longtable_begin = f'\\\\begin{{longtable}}{{{align}}}'\n        longtable_end   = f'\\\\end{{longtable}}'\n        if longtable_singlespace:\n            longtable_begin = '\\\\begin{spacing}{1}\\n' + longtable_begin \n            longtable_end   =  longtable_end + \"\\n\\\\end{spacing}\"\n\n        tabl = (tabl\n                .replace(f\"\\\\begin{{table}}[{position}]\", longtable_begin)\n                .replace(\"\\\\end{table}\", longtable_end)\n\n                .replace(f\"\\\\label{{{label}}}\", f\"\\\\label{{{label}}}\\\\\\\\\")\n\n                .replace(\"\\\\centering\", '')\n                .replace(f\"\\\\begin{{tabular}}{{{align}}}\", '')\n                .replace(\"\\\\end{tabular}\", '')\n\n                .replace(header_old, header_new)\n                )\n        return tabl\n\n    def __to_latex_extract_header__(self, latex_table: str) -&gt; str:\n        # Extract the header section from a LaTeX table.\n\n        # The header is defined as the text between the first occurrence of\n        # '\\\\toprule' and '\\\\midrule'. This function returns that section\n        # as a single string.\n\n        # Parameters:\n        #   latex_table (str): The complete LaTeX table as a string.\n\n        # Returns:\n        #   str: The header lines between '\\\\toprule' and '\\\\midrule', with\n        #        surrounding whitespace removed.\n\n        # Use re.DOTALL so that '.' matches newline characters.\n        pattern = re.compile(r'\\\\toprule\\s*(.*?)\\s*\\\\midrule', re.DOTALL)\n        match = pattern.search(latex_table)\n        if match:\n            return match.group(1).strip()\n        else:\n            return \"\"\n\n    def __to_latex_group_rows__(self, group_rows_by, group_title_align, ncols, rows):\n\n        position_first_row = self.__to_latex_group_rows_starting_positions__(rows)\n        position_last_row = self.__to_latex_group_rows_ending_positions__(rows, position_first_row)\n\n        # get groups locations\n        groups = (self\n                  .pull(group_rows_by)\n                  .to_list())\n        groups_row_locations = {groups[0]: 0}\n        for i in range(1, len(groups)):\n            if groups[i] != groups[i-1]:\n                groups_row_locations[groups[i]] = i\n\n        # insert horizontal space on grouped rows\n        for i in range(position_first_row, position_last_row):\n            rows[i] = '\\\\hspace{1em}' + rows[i] \n\n        # insert groups heading rows\n        for key, pos in sorted(groups_row_locations.items(),\n                               key=lambda item: item[1], reverse=True):\n            group_title = f\"\\\\addlinespace[0.3em]\\n\\\\multicolumn{{{ncols}}}{{{group_title_align}}}{{ \\\\textbf{{{key}}} }}\\\\\\\\\"\n            rows.insert(position_first_row + pos, group_title )\n\n        return rows\n\n    def __to_latex_group_rows_starting_positions__(self, rows):\n        # Given a list of LaTeX table rows, returns the index of the first row\n        # containing '\\\\midrule' after the last occurrence of a row containing '\\\\toprule'.\n        # If either token is not found, the function returns None.\n\n        last_top_index = -1\n        res = None\n\n        # Iterate over rows to find the last index containing '\\toprule'\n        for i, row in enumerate(rows):\n            if r'\\toprule' in row:\n                last_top_index = i\n\n        if last_top_index == -1:\n            res = None\n\n        # Search for the first occurrence of '\\midrule' after the last '\\toprule'\n        for i in range(last_top_index + 1, len(rows)):\n            if r'\\midrule' in rows[i]:\n                res = i+1  # Return the index of the row containing '\\midrule'\n\n        return res\n\n    def __to_latex_group_rows_ending_positions__(self, rows, position_first_row):\n        last_table_row_index = -1\n        for i, row in enumerate(rows[position_first_row:]):\n            if r'\\bottomrule' in row:\n                last_table_row_index = position_first_row + i\n                break\n\n        return last_table_row_index \n\n    def __to_latex_breaklines__(self, table_str):\n        # Given a LaTeX table string containing a tabular environment,\n        # replace internal newline characters within table cells (i.e. those\n        # that occur within the cell content, not the row terminators) by \n        # LaTeX line breaks and wrap the cell text with \\makecell{...}.\n\n        # Table rules such as \\\\toprule, \\midrule, and \\\\bottomrule are left untouched.\n\n        # Parameters:\n        #     table_str (str): A string containing a LaTeX table.\n\n        # Returns:\n        #     str: The modified LaTeX table string.\n\n        def process_tabular(match):\n            # match.group(1): The \\begin{tabular}{...} line\n            # match.group(2): The content inside the tabular environment\n            # match.group(3): The \\end{tabular} line\n            begin_tabular = match.group(1)\n            content = match.group(2)\n            end_tabular = match.group(3)\n\n            # Split the content into parts while preserving the row separator.\n            # We assume each row ends with a double backslash (\\\\) followed by optional whitespace and a newline.\n            parts = re.split(r'(\\\\\\\\\\s*\\n|\\\\toprule\\n|\\\\midrule\\n|\\\\bottomrule\\n)', content)\n\n            # Reassemble rows as tuples: (row_text, row_separator)\n            rows = []\n            for i in range(0, len(parts), 2):\n                row_text = parts[i]\n                separator = parts[i+1] if i+1 &lt; len(parts) else ''\n                rows.append((row_text, separator))\n\n            processed_rows = []\n            for row_text, row_sep in rows:\n                # Skip processing for rows that are table rules.\n                if row_text.strip() in ('\\\\toprule', '\\\\midrule', '\\\\bottomrule'):\n                    processed_rows.append(row_text + row_sep)\n                    continue\n\n                # Split the row into cells using the ampersand (&amp;) as the delimiter.\n                cells = row_text.split('&amp;')\n                new_cells = []\n                for cell in cells:\n                    # Remove only trailing whitespace from the cell.\n                    cell_clean = cell.rstrip()\n                    # Check if the cell contains an internal newline.\n                    if '\\n' in cell_clean:\n                        # Remove any extra whitespace from the beginning and end.\n                        cell_core = cell_clean.strip()\n                        # Split the cell content by newline, strip each line, and join with LaTeX's line-break command.\n                        cell_lines = cell_core.split('\\n')\n                        cell_with_breaks = r'\\\\'.join(line.strip() for line in cell_lines)\n                        # Wrap the content with \\makecell{...}\n                        cell_processed = r'\\makecell{' + cell_with_breaks + '}'\n                    else:\n                        cell_processed = cell\n                    new_cells.append(cell_processed)\n                # Reassemble the row from its cells and append the preserved row separator.\n                new_row = \" &amp; \".join(new_cells)\n                processed_rows.append(new_row + row_sep)\n\n            # Reassemble the entire tabular content.\n            new_content = \"\".join(processed_rows)\n            return begin_tabular + new_content + end_tabular\n\n        # Process only the tabular environment in the table string.\n        new_table_str = re.sub(\n            r'(\\\\begin\\{tabular\\}\\{[^}]*\\})(.*?)(\\\\end\\{tabular\\})',\n            process_tabular,\n            table_str,\n            flags=re.DOTALL\n        )\n        return new_table_str\n\n    # Exporting table \n    # ---------------\n    def to_excel(self, *args, **kws):\n        \"\"\"\n        Save table to excel.\n\n        Details\n        -------\n        See polars `write_excel()` for details.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        self.to_polars().write_excel(*args, **kws)\n\n    def to_csv(self, *args, **kws):\n        \"\"\"\n        Save table to csv.\n\n        Details\n        -------\n        See polars `write_csv()` for details.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self.to_polars().write_csv(*args, **kws)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.names","title":"<code>names</code>  <code>property</code>","text":"<p>Get column names</p> <p>Returns:</p> Type Description <code>list</code> <p>Names of the columns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.names\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.ncol","title":"<code>ncol</code>  <code>property</code>","text":"<p>Get number of columns</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of columns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.ncol\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.nrow","title":"<code>nrow</code>  <code>property</code>","text":"<p>Get number of rows</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of rows</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.nrow\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.arrange","title":"<code>arrange(*args)</code>","text":"<p>Arrange/sort rows</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>Columns to sort by</p> <code>()</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n&gt;&gt;&gt; # Arrange in ascending order\n&gt;&gt;&gt; df.arrange('x', 'y')\n&gt;&gt;&gt; # Arrange some columns descending\n&gt;&gt;&gt; df.arrange(tp.desc('x'), 'y')\n</code></pre> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble orderd by *args</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def arrange(self, *args):\n    \"\"\"\n    Arrange/sort rows\n\n    Parameters\n    ----------\n    *args : str\n        Columns to sort by\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n    &gt;&gt;&gt; # Arrange in ascending order\n    &gt;&gt;&gt; df.arrange('x', 'y')\n    &gt;&gt;&gt; # Arrange some columns descending\n    &gt;&gt;&gt; df.arrange(tp.desc('x'), 'y')\n\n    Returns\n    ------- \n    tibble\n        Original tibble orderd by *args\n    \"\"\"\n    exprs = _as_list(args)\n    desc = [True if isinstance(expr, DescCol) else False for expr in exprs]\n    return super()\\\n        .sort(exprs, descending = desc, nulls_last=True)\\\n        .pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.bind_cols","title":"<code>bind_cols(*args)</code>","text":"<p>Bind data frames by columns</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>tibble</code> <p>Data frame to bind</p> <code>()</code> <p>Returns:</p> Type Description <code>tibble</code> <p>The original tibble with added columns  from the other tibble specified in *args</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n&gt;&gt;&gt; df2 = tp.tibble({'a': ['c', 'c', 'c'], 'b': range(4, 7)})\n&gt;&gt;&gt; df1.bind_cols(df2)\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def bind_cols(self, *args):\n    \"\"\"\n    Bind data frames by columns\n\n    Parameters\n    ----------\n    *args : tibble\n        Data frame to bind\n\n    Returns\n    ------- \n    tibble\n        The original tibble with added columns \n        from the other tibble specified in *args\n\n    Examples\n    --------\n    &gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n    &gt;&gt;&gt; df2 = tp.tibble({'a': ['c', 'c', 'c'], 'b': range(4, 7)})\n    &gt;&gt;&gt; df1.bind_cols(df2)\n    \"\"\"\n    frames = _as_list(args)\n    out = self.to_polars()\n    for frame in frames:\n        out = out.hstack(frame)\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.bind_rows","title":"<code>bind_rows(*args)</code>","text":"<p>Bind data frames by row</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>(tibble, list)</code> <p>Data frames to bind by row</p> <code>()</code> <p>Returns:</p> Type Description <code>tibble</code> <p>The original tibble with added rows  from the other tibble specified in *args</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n&gt;&gt;&gt; df2 = tp.tibble({'x': ['c', 'c', 'c'], 'y': range(4, 7)})\n&gt;&gt;&gt; df1.bind_rows(df2)\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def bind_rows(self, *args):\n    \"\"\"\n    Bind data frames by row\n\n    Parameters\n    ----------\n    *args : tibble, list\n        Data frames to bind by row\n\n    Returns\n    ------- \n    tibble\n        The original tibble with added rows \n        from the other tibble specified in *args\n\n    Examples\n    --------\n    &gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n    &gt;&gt;&gt; df2 = tp.tibble({'x': ['c', 'c', 'c'], 'y': range(4, 7)})\n    &gt;&gt;&gt; df1.bind_rows(df2)\n    \"\"\"\n    frames = _as_list(args)\n    out = pl.concat([self, *frames], how = \"diagonal\")\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.clone","title":"<code>clone()</code>","text":"<p>Very cheap deep clone</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def clone(self):\n    \"\"\"\n    Very cheap deep clone\n    \"\"\"\n    return super().clone().pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.count","title":"<code>count(*args, sort=False, name='n')</code>","text":"<p>Returns row counts of the dataset.  If bare column names are provided, count() returns counts by group.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>(str, Expr)</code> <p>Columns to group by</p> <code>()</code> <code>sort</code> <code>bool</code> <p>Should columns be ordered in descending order by count</p> <code>False</code> <code>name</code> <code>str</code> <p>The name of the new column in the output. If omitted, it will default to \u201cn\u201d.</p> <code>'n'</code> <p>Returns:</p> Type Description <code>tibble</code> <p>If no agument is provided, just return the nomber of rows. If column names are provided, it will count the unique  values across columns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': [1, 1, 2, 3],\n...:                 'b': ['a', 'a', 'b', 'b']})\n&gt;&gt;&gt; df.count()\nshape: (1, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   n \u2502\n\u2502 u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; df.count('a', 'b')\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   a   b       n \u2502\n\u2502 i64   str   u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   1   a       2 \u2502\n\u2502   2   b       1 \u2502\n\u2502   3   b       1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def count(self, *args, sort = False, name = 'n'):\n    \"\"\"\n    Returns row counts of the dataset. \n    If bare column names are provided, count() returns counts by group.\n\n    Parameters\n    ----------\n    *args : str, Expr\n        Columns to group by\n    sort : bool\n        Should columns be ordered in descending order by count\n    name : str\n        The name of the new column in the output. If omitted, it will default to \"n\".\n\n    Returns\n    ------- \n    tibble\n        If no agument is provided, just return the nomber of rows.\n        If column names are provided, it will count the unique \n        values across columns\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': [1, 1, 2, 3],\n    ...:                 'b': ['a', 'a', 'b', 'b']})\n    &gt;&gt;&gt; df.count()\n    shape: (1, 1)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   n \u2502\n    \u2502 u32 \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502   4 \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2518\n    &gt;&gt;&gt; df.count('a', 'b')\n    shape: (3, 3)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   a   b       n \u2502\n    \u2502 i64   str   u32 \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502   1   a       2 \u2502\n    \u2502   2   b       1 \u2502\n    \u2502   3   b       1 \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n    args = _as_list(args)\n\n    out = self.summarize(pl.len().alias(name), by = args)\n\n    if sort == True:\n        out = out.arrange(desc(name))\n\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.crossing","title":"<code>crossing(*args, **kwargs)</code>","text":"<p>Expands the existing tibble for each value of the variables used in the <code>crossing()</code> argument. See Returns.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>list</code> <p>One unamed list is accepted.</p> <code>()</code> <code>*kwargs</code> <code>list</code> <p>keyword will be the variable name, and the values in the list will be in the expanded tibble</p> <code>{}</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble with varibles containing all combinations of the values in the arguments passed to <code>crossing()</code>. The original tibble will be replicated for each unique combination.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': [1, 2], \"b\": [3, 5]})\n&gt;&gt;&gt; df\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   a     b \u2502\n\u2502 i64   i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   1     3 \u2502\n\u2502   2     5 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; df.crossing(c = ['a', 'b', 'c'])\nshape: (6, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   a     b   c   \u2502\n\u2502 i64   i64   str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   1     3   a   \u2502\n\u2502   1     3   b   \u2502\n\u2502   1     3   c   \u2502\n\u2502   2     5   a   \u2502\n\u2502   2     5   b   \u2502\n\u2502   2     5   c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def crossing(self, *args, **kwargs):\n    \"\"\"\n    Expands the existing tibble for each value of the\n    variables used in the `crossing()` argument. See Returns.\n\n    Parameters\n    ----------\n    *args : list\n        One unamed list is accepted. \n\n    *kwargs : list\n        keyword will be the variable name, and the values in the list\n        will be in the expanded tibble\n\n    Returns\n    ------- \n    tibble\n        A tibble with varibles containing all combinations of the\n        values in the arguments passed to `crossing()`. The original\n        tibble will be replicated for each unique combination.\n\n    Examples\n    -------- \n    &gt;&gt;&gt; df = tp.tibble({'a': [1, 2], \"b\": [3, 5]})\n    &gt;&gt;&gt; df\n    shape: (2, 2)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   a     b \u2502\n    \u2502 i64   i64 \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502   1     3 \u2502\n    \u2502   2     5 \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    &gt;&gt;&gt; df.crossing(c = ['a', 'b', 'c'])\n    shape: (6, 3)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   a     b   c   \u2502\n    \u2502 i64   i64   str \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502   1     3   a   \u2502\n    \u2502   1     3   b   \u2502\n    \u2502   1     3   c   \u2502\n    \u2502   2     5   a   \u2502\n    \u2502   2     5   b   \u2502\n    \u2502   2     5   c   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n    out = self.mutate(*args, **kwargs).to_polars()\n    for var,_ in kwargs.items():\n        out = out.explode(var)\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.descriptive_statistics","title":"<code>descriptive_statistics(vars=None, groups=None, include_categorical=True, include_type=False)</code>","text":"<p>Compute descriptive statistics for numerical variables and optionally frequency statistics for categorical variables, with support for grouping.</p> <p>Parameters:</p> Name Type Description Default <code>vars</code> <code>str, list, dict, or None</code> <p>The variables for which to compute statistics. - If None, all variables in the dataset (as given by <code>self.names</code>) are used. - If a string, it is interpreted as a single variable name. - If a list, each element is treated as a variable name. - If a dict, keys are variable names and values are their labels.</p> <code>None</code> <code>groups</code> <code>str, list, dict, or None</code> <p>Variable(s) to group by when computing statistics. - If None, overall statistics are computed. - If a string, it is interpreted as a single grouping variable. - If a list, each element is treated as a grouping variable. - If a dict, keys are grouping variable names and values are their labels.</p> <code>None</code> <code>include_categorical</code> <code>bool</code> <p>Whether to include frequency statistics for categorical variables in the output.</p> <code>True</code> <code>include_type</code> <code>bool</code> <p>If True, adds a column indicating the variable type (\u201cNum\u201d for numerical, \u201cCat\u201d for categorical).</p> <code>False</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble containing the descriptive statistics. For numerical variables, the statistics include:     - N: count of non-missing values     - Missing (%): percentage of missing values     - Mean: average value     - Std.Dev.: standard deviation     - Min: minimum value     - Max: maximum value If grouping is specified, these statistics are computed for each group. When <code>include_categorical</code> is True, frequency statistics for categorical variables are appended to the result.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def descriptive_statistics(self, vars=None, groups=None,\n                           include_categorical=True,\n                           include_type=False):\n    \"\"\"\n    Compute descriptive statistics for numerical variables and optionally\n    frequency statistics for categorical variables, with support for grouping.\n\n    Parameters\n    ----------\n    vars : str, list, dict, or None, default None\n        The variables for which to compute statistics.\n        - If None, all variables in the dataset (as given by `self.names`) are used.\n        - If a string, it is interpreted as a single variable name.\n        - If a list, each element is treated as a variable name.\n        - If a dict, keys are variable names and values are their labels.\n    groups : str, list, dict, or None, default None\n        Variable(s) to group by when computing statistics.\n        - If None, overall statistics are computed.\n        - If a string, it is interpreted as a single grouping variable.\n        - If a list, each element is treated as a grouping variable.\n        - If a dict, keys are grouping variable names and values are their labels.\n    include_categorical : bool, default True\n        Whether to include frequency statistics for categorical variables in the output.\n    include_type : bool, default False\n        If True, adds a column indicating the variable type (\"Num\" for numerical, \"Cat\" for categorical).\n\n    Returns\n    -------\n    tibble\n        A tibble containing the descriptive statistics.\n        For numerical variables, the statistics include:\n            - N: count of non-missing values\n            - Missing (%): percentage of missing values\n            - Mean: average value\n            - Std.Dev.: standard deviation\n            - Min: minimum value\n            - Max: maximum value\n        If grouping is specified, these statistics are computed for each group.\n        When `include_categorical` is True, frequency statistics for categorical variables are appended\n        to the result.\n    \"\"\"\n    assert isinstance(vars, str) or isinstance(vars, list) or \\\n        isinstance(vars, dict) or vars is None, \\\n        \"'vars' must be a string, dict, or list\"\n    assert isinstance(groups, str) or isinstance(groups, list) or \\\n        isinstance(groups, dict) or groups is None, \\\n        \"'groups' must be a string, dict, or list\"\n\n    if vars is None:\n        vars = {v:v for v in self.names}\n    elif isinstance(vars, str):\n        vars = {vars:vars}\n    elif isinstance(vars, list):\n        vars = {v:v for v in vars}\n\n    if isinstance(groups, str):\n        groups = {groups:groups}\n    elif isinstance(groups, list):\n        groups = {g:g for g in groups}\n\n    # select only numerical\n    vars_num = {var:label for var, label in vars.items() if\n                self.to_polars().schema[var].is_numeric()}\n    # select only numerical\n    vars_cat = {var:label for var, label in vars.items() if\n                not self.to_polars().schema[var].is_numeric()}\n\n    # compute statistics for numerical variables\n    if groups is None:\n        res = self.__descriptive_statistics__(self, vars_num)\n    else:\n        res = (self\n               .select(vars_num | groups)\n               .nest(list(groups.values()))\n               .mutate(summary = map(['data'], lambda col:\n                                     self.__descriptive_statistics__(col[0],\n                                                                     vars=vars_num)))\n               .drop('data')\n               .unnest('summary')\n               )\n\n    n = self.nrow\n    res = (res\n           .mutate(null_count = 100*pl.col(\"null_count\")/n,\n                   count = as_integer('count'))\n           .rename({\"count\":'N',\n                    'null_count':'Missing (%)',\n                    \"mean\":\"Mean\",\n                    'std':'Std.Dev.',\n                    'min':\"Min\",\n                    'max':'Max'\n                    })\n           )\n    if include_type:\n        res = res.mutate(Type='Num')\n\n    # compute statistics for categorical variables\n    if vars_cat and include_categorical: \n        res_cat = tibble()\n        for var_cat, label in vars_cat.items():\n            res_cat = res_cat.bind_rows(\n                self\n                .freq({var_cat:label}, groups=groups)\n                .drop('low', 'high')\n                .rename({'Freq':\"Mean\",\n                         label:'Variable'})\n                .mutate(Variable = label + \" (\"+pl.col(\"Variable\")+\")\")\n                .replace_null({'Variable': label + \" (Missing)\"})\n            )\n        if include_type:\n                res_cat = res_cat.mutate(Type='Cat')\n        res = res.bind_rows(res_cat)\n\n    res = res.arrange('Variable')\n    return res\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.distinct","title":"<code>distinct(*args, keep_all=True)</code>","text":"<p>Select distinct/unique rows</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>(str, Expr)</code> <p>Columns to find distinct/unique rows</p> <code>()</code> <code>keep_all</code> <code>boll</code> <p>If True, keep all columns. Otherwise, return only the ones used to select the distinct rows.</p> <code>True</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Tibble after removing the repeated rows based on *args</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.distinct()\n&gt;&gt;&gt; df.distinct('b')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def distinct(self, *args, keep_all = True):\n    \"\"\"\n    Select distinct/unique rows\n\n    Parameters\n    ----------\n    *args : str, Expr\n        Columns to find distinct/unique rows\n\n    keep_all : boll\n        If True, keep all columns. Otherwise, return\n        only the ones used to select the distinct rows.\n\n    Returns\n    ------- \n    tibble\n        Tibble after removing the repeated rows based on *args\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.distinct()\n    &gt;&gt;&gt; df.distinct('b')\n    \"\"\"\n    args = _as_list(args)\n    # \n    if len(args) == 0:\n        df = super().unique()\n    else:\n        df = super().unique(args)\n    if not keep_all and len(args) &gt; 0:\n        df = df.select(args)\n    return df.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.drop","title":"<code>drop(*args)</code>","text":"<p>Drop unwanted columns</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>Columns to drop</p> <code>()</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Tibble with columns in *args dropped</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.drop('x', 'y')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def drop(self, *args):\n    \"\"\"\n    Drop unwanted columns\n\n    Parameters\n    ----------\n    *args : str\n        Columns to drop\n\n    Returns\n    ------- \n    tibble\n        Tibble with columns in *args dropped\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.drop('x', 'y')\n    \"\"\"\n    args = _as_list(args)\n    drop_cols = self.select(args).names\n    return super().drop(drop_cols).pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.drop_null","title":"<code>drop_null(*args)</code>","text":"<p>Drop rows containing missing values</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>Columns to drop nulls from (defaults to all)</p> <code>()</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Tibble with rows in *args with missing values dropped</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble(x = [1, None, 3], y = [None, 'b', 'c'], z = range(3)}\n&gt;&gt;&gt; df.drop_null()\n&gt;&gt;&gt; df.drop_null('x', 'y')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def drop_null(self, *args):\n    \"\"\"\n    Drop rows containing missing values\n\n    Parameters\n    ----------\n    *args : str\n        Columns to drop nulls from (defaults to all)\n\n    Returns\n    ------- \n    tibble\n        Tibble with rows in *args with missing values dropped\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble(x = [1, None, 3], y = [None, 'b', 'c'], z = range(3)}\n    &gt;&gt;&gt; df.drop_null()\n    &gt;&gt;&gt; df.drop_null('x', 'y')\n    \"\"\"\n    args = _as_list(args)\n    if len(args) == 0:\n        out = super().drop_nulls()\n    else:\n        out = super().drop_nulls(args)\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.equals","title":"<code>equals(other, null_equal=True)</code>","text":"<p>Check if two tibbles are equal</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def equals(self, other, null_equal = True):\n    \"\"\"\n    Check if two tibbles are equal\n    \"\"\"\n    df = self.to_polars()\n    other = other.to_polars()\n    return df.equals(other, null_equal = null_equal)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.fill","title":"<code>fill(*args, direction='down', by=None)</code>","text":"<p>Fill in missing values with previous or next value</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>Columns to fill</p> <code>()</code> <code>direction</code> <code>str</code> <p>Direction to fill. One of [\u2018down\u2019, \u2018up\u2019, \u2018downup\u2019, \u2018updown\u2019]</p> <code>'down'</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Tibble with missing values filled</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': [1, None, 3, 4, 5],\n...                 'b': [None, 2, None, None, 5],\n...                 'groups': ['a', 'a', 'a', 'b', 'b']})\n&gt;&gt;&gt; df.fill('a', 'b')\n&gt;&gt;&gt; df.fill('a', 'b', by = 'groups')\n&gt;&gt;&gt; df.fill('a', 'b', direction = 'downup')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def fill(self, *args, direction = 'down', by = None):\n    \"\"\"\n    Fill in missing values with previous or next value\n\n    Parameters\n    ----------\n    *args : str\n        Columns to fill\n    direction : str\n        Direction to fill. One of ['down', 'up', 'downup', 'updown']\n    by : str, list\n        Columns to group by\n\n    Returns\n    ------- \n    tibble\n        Tibble with missing values filled\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': [1, None, 3, 4, 5],\n    ...                 'b': [None, 2, None, None, 5],\n    ...                 'groups': ['a', 'a', 'a', 'b', 'b']})\n    &gt;&gt;&gt; df.fill('a', 'b')\n    &gt;&gt;&gt; df.fill('a', 'b', by = 'groups')\n    &gt;&gt;&gt; df.fill('a', 'b', direction = 'downup')\n    \"\"\"\n    args = _as_list(args)\n    if len(args) == 0: return self\n    args = _col_exprs(args)\n    options = {'down': 'forward', 'up': 'backward'}\n    if direction in ['down', 'up']:\n        direction = options[direction]\n        exprs = [arg.fill_null(strategy = direction) for arg in args]\n    elif direction == 'downup':\n        exprs = [\n            arg.fill_null(strategy = 'forward')\n            .fill_null(strategy = 'backward')\n            for arg in args\n        ]\n    elif direction == 'updown':\n        exprs = [\n            arg.fill_null(strategy = 'backward')\n            .fill_null(strategy = 'forward')\n            for arg in args\n        ]\n    else:\n        raise ValueError(\"direction must be one of down, up, downup, or updown\")\n\n    return self.mutate(*exprs, by = by)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.filter","title":"<code>filter(*args, by=None)</code>","text":"<p>Filter rows on one or more conditions</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Expr</code> <p>Conditions to filter by</p> <code>()</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble with rows that match condition.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.filter(col('a') &lt; 2, col('b') == 'a')\n&gt;&gt;&gt; df.filter((col('a') &lt; 2) &amp; (col('b') == 'a'))\n&gt;&gt;&gt; df.filter(col('a') &lt;= tp.mean(col('a')), by = 'b')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def filter(self, *args,\n           by = None):\n    \"\"\"\n    Filter rows on one or more conditions\n\n    Parameters\n    ----------\n    *args : Expr\n        Conditions to filter by\n    by : str, list\n        Columns to group by\n\n    Returns\n    ------- \n    tibble\n        A tibble with rows that match condition.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.filter(col('a') &lt; 2, col('b') == 'a')\n    &gt;&gt;&gt; df.filter((col('a') &lt; 2) &amp; (col('b') == 'a'))\n    &gt;&gt;&gt; df.filter(col('a') &lt;= tp.mean(col('a')), by = 'b')\n    \"\"\"\n    args = _as_list(args)\n    exprs = ft.reduce(lambda a, b: a &amp; b, args)\n\n    if _uses_by(by):\n        out = super().group_by(by).map_groups(lambda x: x.filter(exprs))\n    else:\n        out = super().filter(exprs)\n\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.freq","title":"<code>freq(vars=None, groups=None, na_rm=False, na_label=None)</code>","text":"<p>Compute frequency table.</p> <p>Parameters:</p> Name Type Description Default <code>vars</code> <code>str, list, or dict</code> <p>Variables to return value frequencies for.  If a dict is provided, the key should be the variable name and the values the variable label for the output</p> <code>None</code> <code>groups</code> <code>str, list, dict, or None</code> <p>Variable names to condition marginal frequencies on.  If a dict is provided, the key should be the variable name and the values the variable label for the output Defaults to None (no grouping).</p> <code>None</code> <code>na_rm</code> <code>bool</code> <p>Whether to include NAs in the calculation. Defaults to False.</p> <code>False</code> <code>na_label</code> <code>str</code> <p>Label to use for the NA values</p> <code>None</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble with relative frequencies and counts.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def freq(self, vars=None, groups=None, na_rm=False, na_label=None):\n    \"\"\"\n    Compute frequency table.\n\n    Parameters\n    ----------\n    vars : str, list, or dict\n        Variables to return value frequencies for. \n        If a dict is provided, the key should be the variable name\n        and the values the variable label for the output\n\n    groups : str, list, dict, or None, optional\n        Variable names to condition marginal frequencies on. \n        If a dict is provided, the key should be the variable name\n        and the values the variable label for the output\n        Defaults to None (no grouping).\n\n    na_rm : bool, optional\n        Whether to include NAs in the calculation. Defaults to False.\n\n    na_label : str\n        Label to use for the NA values\n\n    Returns\n    -------\n    tibble\n        A tibble with relative frequencies and counts.\n    \"\"\"\n    assert vars, \"Parameter 'vars' not informed.\"\n    assert isinstance(groups, str) or \\\n        isinstance(groups, list) or\\\n        isinstance(groups, dict) or\\\n        groups is None, \"Incorrect 'groups' argument format. See documentation.\"\n\n    vars_all = []\n\n    if groups is None:\n        groups = {}\n    elif isinstance(groups, str):\n        groups = {groups:groups}\n    elif isinstance(groups, list):\n        groups = {g:g for g in groups}\n    vars_all += list(groups.keys())\n\n    if vars is None:\n        vars = {v:v for v in self.names}\n    elif isinstance(vars, str):\n        vars = {vars:vars}\n    elif isinstance(vars, list):\n        vars = {v:v for v in vars}\n    vars_all += list(vars.keys())\n\n    # labels = False\n    # if isinstance(vars, str):\n    #     vars = [vars]\n    # elif isinstance(vars, dict):\n    #     labels = True\n    #     vars_labels = vars\n    #     vars = list(vars.keys())\n    # elif type(vars) is {}.keys().__class__:\n    #     vars = list(vars)\n\n    # if groups and not isinstance(groups, list):\n    #     groups = [groups]\n    # if groups:\n    #     vars = groups + vars\n\n    res=self.select(vars_all)\n\n    if not na_rm:\n        if na_label is not None:\n            res=res.replace_null({var:na_label for var in vars})\n    else:\n        res=res.drop_null()\n\n    if not groups:\n        res=(res\n               .group_by(vars_all)\n             .summarize(n = n())\n             .mutate(\n                   p     = pl.col(\"n\")/pl.col(\"n\").sum(),\n                   freq  = 100*pl.col(\"p\"),\n                   stdev = 100*np.sqrt((pl.col('p')*(1-pl.col('p')))/pl.col('n'))\n             )\n        )\n        # for var in vars:\n        #     res = self.__tab_reorder_na__(res, var, na_label)\n    else:\n        res = (res\n               .group_by(vars_all)\n               .summarize(n = n())\n               .group_by(list(groups.keys()))\n               .mutate(\n                   p     = pl.col(\"n\")/pl.col(\"n\").sum(),\n                   freq  = 100*pl.col(\"p\"),\n                   stdev = 100*np.sqrt((pl.col('p')*(1-pl.col('p')))/pl.col('n'))\n               )\n        )\n\n    # vars.reverse()\n    res = (\n        res\n        .drop('p')\n        .mutate(n = as_integer('n'),\n                low  = pl.col('freq')-1.96*pl.col('stdev'),\n                high = pl.col('freq')+1.96*pl.col('stdev'))\n        .rename({'n':'N',\n                 'stdev':'Std.Dev.',\n                 'freq':'Freq'}, tolower=False)\n        .arrange(list(vars.keys()))\n    )\n\n    res = res.rename(vars | groups)\n    return res\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.full_join","title":"<code>full_join(df, left_on=None, right_on=None, on=None, suffix='_right')</code>","text":"<p>Perform an full join</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>tibble</code> <p>Lazy DataFrame to join with.</p> required <code>left_on</code> <code>(str, list)</code> <p>Join column(s) of the left DataFrame.</p> <code>None</code> <code>right_on</code> <code>(str, list)</code> <p>Join column(s) of the right DataFrame.</p> <code>None</code> <code>on</code> <p>Join column(s) of both DataFrames. If set, <code>left_on</code> and <code>right_on</code> should be None.</p> <code>None</code> <code>suffix</code> <code>str</code> <p>Suffix to append to columns with a duplicate name.</p> <code>'_right'</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Union between the original and the df tibbles. The rows that don\u2019t match in one of the tibbles will be completed with missing values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df1.full_join(df2)\n&gt;&gt;&gt; df1.full_join(df2, on = 'x')\n&gt;&gt;&gt; df1.full_join(df2, left_on = 'left_x', right_on = 'x')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def full_join(self, df, left_on = None, right_on = None, on = None, suffix: str = '_right'):\n    \"\"\"\n    Perform an full join\n\n    Parameters\n    ----------\n    df : tibble\n        Lazy DataFrame to join with.\n    left_on : str, list\n        Join column(s) of the left DataFrame.\n    right_on : str, list\n        Join column(s) of the right DataFrame.\n    on: str, list\n        Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n    suffix : str\n        Suffix to append to columns with a duplicate name.\n\n    Returns\n    ------- \n    tibble\n        Union between the original and the df tibbles. The\n        rows that don't match in one of the tibbles will be\n        completed with missing values.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df1.full_join(df2)\n    &gt;&gt;&gt; df1.full_join(df2, on = 'x')\n    &gt;&gt;&gt; df1.full_join(df2, left_on = 'left_x', right_on = 'x')\n    \"\"\"\n    if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n        on = list(set(self.names) &amp; set(df.names))\n    return super().join(df, on, 'outer',\n                        left_on = left_on,\n                        right_on= right_on, suffix= suffix).pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.glimpse","title":"<code>glimpse(regex='.')</code>","text":"<p>Print compact information about the data</p> <p>Parameters:</p> Name Type Description Default <code>regex</code> <code>(str, list, dict)</code> <p>Return information of the variables that match the regular  expression, the list, or the dictionary. If dictionary is  used, the variable names must be the dictionary keys.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def glimpse(self, regex='.'):\n    \"\"\"\n    Print compact information about the data\n\n    Parameters\n    ----------\n    regex : str, list, dict\n        Return information of the variables that match the regular \n        expression, the list, or the dictionary. If dictionary is \n        used, the variable names must be the dictionary keys.\n\n    Returns\n    -------\n    None\n\n    \"\"\"\n    assert isinstance(regex, str) or\\\n        isinstance(regex, list) or\\\n        isinstance(regex, dict), \"regex must be a list, dict, or regular expression\"\n\n    # if isinstance(regex, str):\n    #     df = self.select(regex=regex)\n    # elif isinstance(regex, dict):\n    #     df = self.select(names=list(regex.keys()))\n    # else:\n    #     df = self.select(names=regex)\n    print(f\"Columns matching pattern '{regex}':\")\n    df = self.select(matches(regex)).to_pandas()\n    size_col=80\n    header_var = 'Var'\n    header_type = 'Type'\n    header_uniq = 'Uniq'\n    header_missing = 'Miss'\n    header_missing_perc = '(%)'\n    header_head = 'Head'\n    # \n    length_col  = np.max([len(header_var)] +\n                         [len(col) for col  in df.columns])\n    length_type = np.max([len(header_type)] +\n                         [len(col) for col  in\n                          df.dtypes.astype(str).values]) + 2\n    length_nvalues = np.max([len(header_uniq),\n                             len(str(np.max(df\n                                            .apply(pd.unique)\n                                            .apply(len))))])\n    length_missing = np.max([len(header_missing)] +\n                            df.isna().sum().astype(str).apply(len).tolist())\n    try:\n        length_missing_perc = np.max([len(header_missing_perc), \n                                        len((100*df.isna().sum()/df.shape[0])\n                                            .max().astype(int)\n                                            .astype(str))+2]\n                                       )\n    except:\n        length_missing_perc = 3\n\n    length_head = size_col - (length_col + length_type + length_nvalues + length_missing )\n    # \n    header = (f\"{header_var:&gt;{length_col}s} \"+\n              f\"{header_type:{length_type}s}\"+\n              f\"{header_uniq:&gt;{length_nvalues}s} \"+\n              f\"{header_missing:&gt;{length_missing}s} \"+\n              f\"{header_missing_perc:&gt;{length_missing_perc}s} \"+\n              f\"{header_head:{length_head}s}\")\n    print(header)\n    hline = \"-\"*size_col\n    # print(hline)\n    for col in df.columns:\n        dtype = str(df[col].dtype)\n        nvalues = len(df[col].unique())\n        missings = df[col].isna().sum()\n        missings_perc = str(int(100*missings/self.nrow))+\"%\"\n        # \n        vals = str(df[col].values)\n        vals = vals[:length_head] + (vals[length_head+1:], '...')[len(vals) &gt; length_head]\n        # \n        print(f\"{col:&gt;{length_col}.{length_col}s} \"+\n              f\"{'&lt;'+dtype+'&gt;':{length_type}.{length_type}s}\"+\n              f\"{nvalues:&gt;{length_nvalues}d} \"+\n              f\"{missings:&gt;{length_missing}d}\"+\n              f\"{missings_perc:&gt;{length_missing_perc}s} \"\n              f\"{vals:.{length_head+3}s}\")\n    # print(hline)\n    # print(header)\n    print('')\n    print(f\"[Rows: {self.nrow}; Columns {self.ncol}]\")\n    return None\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.group_by","title":"<code>group_by(group, *args, **kwargs)</code>","text":"<p>Takes an existing tibble and converts it into a grouped tibble where operations are performed \u201cby group\u201d. ungroup() happens automatically after the operation is performed.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>(str, list)</code> <p>Variable names to group by.</p> required <p>Returns:</p> Type Description <code>Grouped tibble</code> <p>A tibble with values grouped by one or more columns.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def group_by(self, group, *args, **kwargs):\n    \"\"\"\n    Takes an existing tibble and converts it into a grouped tibble\n    where operations are performed \"by group\". ungroup() happens\n    automatically after the operation is performed.\n\n    Parameters\n    ---------- \n    group : str, list\n        Variable names to group by.\n\n    Returns\n    -------\n    Grouped tibble\n        A tibble with values grouped by one or more columns.\n    \"\"\"\n    res = TibbleGroupBy(self, group, maintain_order=True)\n    return res\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.head","title":"<code>head(n=5, *, by=None)</code>","text":"<p>Alias for <code>.slice_head()</code></p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def head(self, n = 5, *, by = None):\n    \"\"\"\n    Alias for `.slice_head()`\n    \"\"\"\n    return self.slice_head(n, by = by)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.inner_join","title":"<code>inner_join(df, left_on=None, right_on=None, on=None, suffix='_right')</code>","text":"<p>Perform an inner join</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>tibble</code> <p>Lazy DataFrame to join with.</p> required <code>left_on</code> <code>(str, list)</code> <p>Join column(s) of the left DataFrame.</p> <code>None</code> <code>right_on</code> <code>(str, list)</code> <p>Join column(s) of the right DataFrame.</p> <code>None</code> <code>on</code> <p>Join column(s) of both DataFrames. If set, <code>left_on</code> and <code>right_on</code> should be None.</p> <code>None</code> <code>suffix</code> <code>str</code> <p>Suffix to append to columns with a duplicate name.</p> <code>'_right'</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble with intersection of cases in the original and df tibbles.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df1.inner_join(df2)\n&gt;&gt;&gt; df1.inner_join(df2, on = 'x')\n&gt;&gt;&gt; df1.inner_join(df2, left_on = 'left_x', right_on = 'x')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def inner_join(self, df, left_on = None, right_on = None, on = None, suffix = '_right'):\n    \"\"\"\n    Perform an inner join\n\n    Parameters\n    ----------\n    df : tibble\n        Lazy DataFrame to join with.\n    left_on : str, list\n        Join column(s) of the left DataFrame.\n    right_on : str, list\n        Join column(s) of the right DataFrame.\n    on: str, list\n        Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n    suffix : str\n        Suffix to append to columns with a duplicate name.\n\n    Returns\n    ------- \n    tibble\n        A tibble with intersection of cases in the original and\n        df tibbles.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df1.inner_join(df2)\n    &gt;&gt;&gt; df1.inner_join(df2, on = 'x')\n    &gt;&gt;&gt; df1.inner_join(df2, left_on = 'left_x', right_on = 'x')\n    \"\"\"\n    if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n        on = list(set(self.names) &amp; set(df.names))\n    return super().join(df, on, 'inner',\n                        left_on = left_on,\n                        right_on= right_on,\n                        suffix= suffix).pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.left_join","title":"<code>left_join(df, left_on=None, right_on=None, on=None, suffix='_right')</code>","text":"<p>Perform a left join</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>tibble</code> <p>Lazy DataFrame to join with.</p> required <code>left_on</code> <code>(str, list)</code> <p>Join column(s) of the left DataFrame.</p> <code>None</code> <code>right_on</code> <code>(str, list)</code> <p>Join column(s) of the right DataFrame.</p> <code>None</code> <code>on</code> <p>Join column(s) of both DataFrames. If set, <code>left_on</code> and <code>right_on</code> should be None.</p> <code>None</code> <code>suffix</code> <code>str</code> <p>Suffix to append to columns with a duplicate name.</p> <code>'_right'</code> <p>Returns:</p> Type Description <code>tibble</code> <p>The original tibble with added columns from tibble df if they match columns in the original one. Columns to match on are given in the function parameters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df1.left_join(df2)\n&gt;&gt;&gt; df1.left_join(df2, on = 'x')\n&gt;&gt;&gt; df1.left_join(df2, left_on = 'left_x', right_on = 'x')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def left_join(self, df, left_on = None, right_on = None, on = None, suffix = '_right'):\n    \"\"\"\n    Perform a left join\n\n    Parameters\n    ----------\n    df : tibble\n        Lazy DataFrame to join with.\n    left_on : str, list\n        Join column(s) of the left DataFrame.\n    right_on : str, list\n        Join column(s) of the right DataFrame.\n    on: str, list\n        Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n    suffix : str\n        Suffix to append to columns with a duplicate name.\n\n    Returns\n    ------- \n    tibble\n         The original tibble with added columns from tibble df if\n         they match columns in the original one. Columns to match\n         on are given in the function parameters.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df1.left_join(df2)\n    &gt;&gt;&gt; df1.left_join(df2, on = 'x')\n    &gt;&gt;&gt; df1.left_join(df2, left_on = 'left_x', right_on = 'x')\n    \"\"\"\n    if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n        on = list(set(self.names) &amp; set(df.names))\n    return super().join(df, on, 'left',  left_on = left_on, right_on= right_on, suffix= suffix).pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.mutate","title":"<code>mutate(*args, by=None, **kwargs)</code>","text":"<p>Add or modify columns</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Expr</code> <p>Column expressions to add or modify</p> <code>()</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <code>**kwargs</code> <code>Expr</code> <p>Column expressions to add or modify</p> <code>{}</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with new column created.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), c = ['a', 'a', 'b']})\n&gt;&gt;&gt; df.mutate(double_a = col('a') * 2,\n...           a_plus_b = col('a') + col('b'))\n&gt;&gt;&gt; df.mutate(row_num = row_number(), by = 'c')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def mutate(self, *args, by = None, **kwargs):\n    \"\"\"\n    Add or modify columns\n\n    Parameters\n    ----------\n    *args : Expr\n        Column expressions to add or modify\n    by : str, list\n        Columns to group by\n    **kwargs : Expr\n        Column expressions to add or modify\n\n    Returns\n    ------- \n    tibble\n        Original tibble with new column created.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), c = ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.mutate(double_a = col('a') * 2,\n    ...           a_plus_b = col('a') + col('b'))\n    &gt;&gt;&gt; df.mutate(row_num = row_number(), by = 'c')\n    \"\"\"\n    exprs = _as_list(args) + _kwargs_as_exprs(kwargs)\n\n    out = self.to_polars()\n\n    if _uses_by(by):\n        out = out.group_by(by).map_groups(lambda x: _mutate_cols(x, exprs))\n    else:\n        out = _mutate_cols(out, exprs)\n\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.nest","title":"<code>nest(by, *args, **kwargs)</code>","text":"<p>creates a nested tibble</p> <p>Parameters:</p> Name Type Description Default <code>by</code> <code>(list, str)</code> <p>Columns to nest on</p> required <code>kwargs</code> <p>data : list of column names    columns to select to include in the nested data    If not provided, include all columns except the ones    used in \u2018by\u2019</p> <p>key : str    name of the resulting nested column. </p> <p>names_sep : str     If not provided (default), the names in the nested     data will come from the former names. If a string,     the new inner names in the nested dataframe will use     the outer names with names_sep automatically stripped.     This makes names_sep roughly     symmetric between nesting and unnesting.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tibble</code> <p>The resulting tibble with have a column that contains nested tibbles</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def nest(self, by, *args, **kwargs):\n    \"\"\"\n    creates a nested tibble\n\n    Parameters\n    ----------\n    by : list, str\n        Columns to nest on\n\n    kwargs :\n        data : list of column names\n           columns to select to include in the nested data\n           If not provided, include all columns except the ones\n           used in 'by'\n\n         key : str\n           name of the resulting nested column. \n\n         names_sep : str\n            If not provided (default), the names in the nested\n            data will come from the former names. If a string,\n            the new inner names in the nested dataframe will use\n            the outer names with names_sep automatically stripped.\n            This makes names_sep roughly\n            symmetric between nesting and unnesting.\n\n    Returns\n    -------\n    tibble\n        The resulting tibble with have a column that contains\n        nested tibbles\n\n    \"\"\"\n    key  = kwargs.get(\"key\", 'data')\n    data = kwargs.get(\"data\", [c for c in self.names if c not in by])\n    names_sep = kwargs.get(\"names_sep\", None)\n\n    out = (self\n           .group_by(by)\n           .agg(**{\n               key : pl.struct(data).map_elements(\n                   # lambda cols: from_polars( pl.DataFrame(cols.to_list()) ) )\n                   lambda cols: from_polars(pl.DataFrame({'data':cols}).unnest('data')) )\n                   # lambda cols: tibble(cols.to_list()) )\n           })\n           .pipe(from_polars)\n           )\n    # to keep enum order in the nested data\n    # enum_columns = [col for col in self.select(data).names\n    #                 if self.pull(col).dtype == pl.Enum]\n    # if enum_columns:\n    #     for col in enum_columns:\n    #         cats = self.pull(col).cat.get_categories().to_list()\n    #         print(cats)\n    #         out = out.mutate(**{key : map([key], lambda row:\n    #                                       row[0].mutate(col = as_factor(col, cats) )\n    #                                       }\n    # # to keep factors\n    # factors = [col for col in self.select(data).names\n    #                 if self.pull(col).dtype == pl.Categorical]\n    # if factors:\n    #     for col in factors:\n    #         out = out.mutate(**{col : as_factor(col)})\n\n\n    if names_sep is not None:\n        new_names = {col:f\"{col}_{names_sep}\" for col in data}\n        print(new_names)\n        out = out.mutate(**{key:col(key).map_elements(lambda row: row.rename(new_names))})\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.pivot_longer","title":"<code>pivot_longer(cols=None, names_to='name', values_to='value')</code>","text":"<p>Pivot data from wide to long</p> <p>Parameters:</p> Name Type Description Default <code>cols</code> <code>Expr</code> <p>List of the columns to pivot. Defaults to all columns.</p> <code>None</code> <code>names_to</code> <code>str</code> <p>Name of the new \u201cnames\u201d column.</p> <code>'name'</code> <code>values_to</code> <p>Name of the new \u201cvalues\u201d column</p> <code>'value'</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble, but in long format.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'id': ['id1', 'id2'], 'a': [1, 2], 'b': [1, 2]})\n&gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'])\n&gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'], names_to = 'stuff', values_to = 'things')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def pivot_longer(self,\n                 cols = None,\n                 names_to = \"name\",\n                 values_to = \"value\"):\n    \"\"\"\n    Pivot data from wide to long\n\n    Parameters\n    ----------\n    cols : Expr\n        List of the columns to pivot. Defaults to all columns.\n    names_to : str\n        Name of the new \"names\" column.\n    values_to: str\n        Name of the new \"values\" column\n\n    Returns\n    ------- \n    tibble\n        Original tibble, but in long format.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'id': ['id1', 'id2'], 'a': [1, 2], 'b': [1, 2]})\n    &gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'])\n    &gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'], names_to = 'stuff', values_to = 'things')\n    \"\"\"\n    if cols is None:\n        cols = everything()\n    if isinstance(cols, dict):\n        cols = list(cols.keys())\n\n    df_cols = pl.Series(self.names)\n    value_vars = self.select(cols).names\n    id_vars = df_cols.filter(df_cols.is_in(value_vars).not_()).to_list()\n    out = super().melt(id_vars, value_vars, names_to, values_to)\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.pivot_wider","title":"<code>pivot_wider(names_from='name', values_from='value', id_cols=None, values_fn='first', values_fill=None)</code>","text":"<p>Pivot data from long to wide</p> <p>Parameters:</p> Name Type Description Default <code>names_from</code> <code>str</code> <p>Column to get the new column names from.</p> <code>'name'</code> <code>values_from</code> <code>str</code> <p>Column to get the new column values from</p> <code>'value'</code> <code>id_cols</code> <code>(str, list)</code> <p>A set of columns that uniquely identifies each observation. Defaults to all columns in the data table except for the columns specified in <code>names_from</code> and <code>values_from</code>.</p> <code>None</code> <code>values_fn</code> <code>str</code> <p>Function for how multiple entries per group should be dealt with. Any of \u2018first\u2019, \u2018count\u2019, \u2018sum\u2019, \u2018max\u2019, \u2018min\u2019, \u2018mean\u2019, \u2018median\u2019, \u2018last\u2019</p> <code>'first'</code> <code>values_fill</code> <code>str</code> <p>If values are missing/null, what value should be filled in. Can use: \u201cbackward\u201d, \u201cforward\u201d, \u201cmean\u201d, \u201cmin\u201d, \u201cmax\u201d, \u201czero\u201d, \u201cone\u201d</p> <code>None</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble, but in wide format.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'id': [1, 1], 'variable': ['a', 'b'], 'value': [1, 2]})\n&gt;&gt;&gt; df.pivot_wider(names_from = 'variable', values_from = 'value')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def pivot_wider(self,\n                names_from = 'name',\n                values_from = 'value',\n                id_cols = None,\n                values_fn = 'first', \n                values_fill = None\n                ):\n    \"\"\"\n    Pivot data from long to wide\n\n    Parameters\n    ----------\n    names_from : str\n        Column to get the new column names from.\n    values_from : str\n        Column to get the new column values from\n    id_cols : str, list\n        A set of columns that uniquely identifies each observation.\n        Defaults to all columns in the data table except for the columns specified in\n        `names_from` and `values_from`.\n    values_fn : str\n        Function for how multiple entries per group should be dealt with.\n        Any of 'first', 'count', 'sum', 'max', 'min', 'mean', 'median', 'last'\n    values_fill : str\n        If values are missing/null, what value should be filled in.\n        Can use: \"backward\", \"forward\", \"mean\", \"min\", \"max\", \"zero\", \"one\"\n\n    Returns\n    ------- \n    tibble\n        Original tibble, but in wide format.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'id': [1, 1], 'variable': ['a', 'b'], 'value': [1, 2]})\n    &gt;&gt;&gt; df.pivot_wider(names_from = 'variable', values_from = 'value')\n    \"\"\"\n    if id_cols == None:\n        df_cols = pl.Series(self.names)\n        from_cols = pl.Series(self.select(names_from, values_from).names)\n        id_cols = df_cols.filter(df_cols.is_in(from_cols).not_()).to_list()\n\n    no_id = len(id_cols) == 0\n\n    if no_id:\n        id_cols = '___id__'\n        self = self.mutate(___id__ = pl.lit(1))\n\n    out = (\n        super()\n        .pivot(index=id_cols, on=names_from, values=values_from, aggregate_function=values_fn)\n        .pipe(from_polars)\n    )\n\n    if values_fill != None:\n        new_cols = pl.Series(out.names)\n        new_cols = new_cols.filter(~new_cols.is_in(id_cols))\n        fill_exprs = [col(new_col).fill_null(values_fill) for new_col in new_cols]\n        out = out.mutate(*fill_exprs)\n\n    if no_id: out = out.drop('___id__')\n\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.print","title":"<code>print(n=1000, ncols=1000, str_length=1000, digits=2)</code>","text":"<p>Print the DataFrame</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to print</p> <code>1000</code> <code>ncols</code> <code>int</code> <p>Number of columns to print</p> <code>1000</code> <code>str_length</code> <code>int</code> <p>Maximum length of the strings.</p> <code>1000</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def print(self, n=1000, ncols=1000, str_length=1000, digits=2):\n    \"\"\"\n    Print the DataFrame\n\n    Parameters\n    ----------\n    n : int, default=1000\n        Number of rows to print\n\n    ncols : int, default=1000\n        Number of columns to print\n\n    str_length : int, default=1000\n        Maximum length of the strings.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    with pl.Config(set_tbl_rows=n,\n                   set_tbl_cols=ncols,\n                   float_precision=digits,\n                   fmt_str_lengths=str_length):\n        print(self)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.pull","title":"<code>pull(var=None)</code>","text":"<p>Extract a column as a series</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>str</code> <p>Name of the column to extract. Defaults to the last column.</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>The series will contain the values of the column from <code>var</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3))\n&gt;&gt;&gt; df.pull('a')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def pull(self, var = None):\n    \"\"\"\n    Extract a column as a series\n\n    Parameters\n    ----------\n    var : str\n        Name of the column to extract. Defaults to the last column.\n\n    Returns\n    ------- \n    Series\n        The series will contain the values of the column from `var`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3))\n    &gt;&gt;&gt; df.pull('a')\n    \"\"\"\n    if var == None:\n        var = self.names[-1]\n\n    return super().get_column(var)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.relevel","title":"<code>relevel(x, ref)</code>","text":"<p>Change the reference level a string or factor and covert to factor</p> Inputs <p>x : str     Variable name</p> <p>ref : str    Reference level</p> <p>Returns:</p> Type Description <code>tibble</code> <p>The original tibble with the column specified in <code>x</code> as an ordered factors, with first category specified in <code>ref</code>.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def relevel(self, x, ref):\n    \"\"\"\n    Change the reference level a string or factor and covert to factor\n\n    Inputs\n    ------\n    x : str\n        Variable name\n\n    ref : str\n       Reference level\n\n    Returns\n    ------- \n    tibble\n        The original tibble with the column specified in `x` as\n        an ordered factors, with first category specified in `ref`.\n    \"\"\"\n    levels = self.pull(x).unique().to_list()\n    relevels = [ref] + [l for l in levels if l != ref]\n    self = self.mutate(**{x : as_factor(x, relevels)})\n    return self\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.relocate","title":"<code>relocate(*args, before=None, after=None)</code>","text":"<p>Move a column or columns to a new position</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>(str, Expr)</code> <p>Columns to move</p> <code>()</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with columns relocated.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.relocate('a', before = 'c')\n&gt;&gt;&gt; df.relocate('b', after = 'c')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def relocate(self, *args, before = None, after = None):\n    \"\"\"\n    Move a column or columns to a new position\n\n    Parameters\n    ----------\n    *args : str, Expr\n        Columns to move\n\n    Returns\n    ------- \n    tibble\n        Original tibble with columns relocated.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.relocate('a', before = 'c')\n    &gt;&gt;&gt; df.relocate('b', after = 'c')\n    \"\"\"\n    cols_all = pl.Series(self.names)\n    locs_all = pl.Series(range(len(cols_all)))\n    locs_dict = {k:v for k,v in zip(cols_all, locs_all)}\n    locs_df = pl.DataFrame(locs_dict, orient = \"row\")\n\n    cols_relocate = _as_list(args)\n    locs_relocate = pl.Series(locs_df.select(cols_relocate).row(0))\n\n    if (len(locs_relocate) == 0):\n        return self\n\n    uses_before = before != None\n    uses_after = after != None\n\n    if (uses_before &amp; uses_after):\n        raise ValueError(\"Cannot provide both before and after\")\n    elif (not_(uses_before) &amp; not_(uses_after)):\n        before = cols_all[0]\n        uses_before = True\n\n    if uses_before:\n        before = locs_df.select(before).get_column(before)\n        locs_start = locs_all.filter(locs_all &lt; before)\n    else:\n        after = locs_df.select(after).get_column(after)\n        locs_start = locs_all.filter(locs_all &lt;= after)\n\n    locs_start = locs_start.filter(~locs_start.is_in(locs_relocate))\n    final_order = pl.concat([locs_start, locs_relocate, locs_all]).unique(maintain_order = True)\n    final_order = cols_all[final_order].to_list()\n\n    return self.select(final_order)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.rename","title":"<code>rename(columns=None, regex=False, tolower=False, strict=False)</code>","text":"<p>Rename columns</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>dict</code> <p>Dictionary mapping of old and new names</p> <code>None</code> <code>regex</code> <code>bool</code> <p>If True, uses regular expression replacement</p> <code>False</code> <code>tolower</code> <code>bool</code> <p>If True, convert all to lower case</p> <code>False</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with columns renamed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'x': range(3), 't': range(3), 'z': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.rename({'x': 'new_x'})\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def rename(self, columns=None, regex=False, tolower=False, strict=False):\n    \"\"\"\n    Rename columns\n\n    Parameters\n    ----------\n    columns : dict, default None\n        Dictionary mapping of old and new names\n        {&lt;old name&gt;:&lt;new name&gt;, ...}\n\n    regex : bool, default False\n        If True, uses regular expression replacement\n        {&lt;matched from&gt;:&lt;matched to&gt;}\n\n    tolower : bool, default False\n        If True, convert all to lower case\n\n    Returns\n    ------- \n    tibble\n        Original tibble with columns renamed.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'x': range(3), 't': range(3), 'z': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.rename({'x': 'new_x'}) \n    \"\"\"\n    assert isinstance(columns, dict) or columns is None,\\\n        \"'columns' must be a dictionary or None.\"\n\n    if columns is not None:\n        if regex:\n            self = self.__rename_regexp__(columns)\n        else:\n            self = super().rename(columns, strict=False).pipe(from_polars)\n\n    if tolower:\n        self = self.__rename_tolower__()\n    return self\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.replace","title":"<code>replace(rep, regex=False)</code>","text":"<p>Replace method from polars pandas. Replaces values of a column.</p> <p>Parameters:</p> Name Type Description Default <code>rep</code> <code>dict</code> <p>Format to use polars\u2019 replace:     {:{:, \u2026}} Format to use pandas\u2019 replace: required <code>regex</code> <code>bool</code> <p>If true, replace using regular expression. It uses pandas replace()</p> <code>False</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with values of columns replaced based on rep`.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def replace(self, rep, regex=False):\n    \"\"\"\n    Replace method from polars pandas. Replaces values of a column.\n\n    Parameters\n    ----------\n    rep : dict\n        Format to use polars' replace:\n            {&lt;varname&gt;:{&lt;old value&gt;:&lt;new value&gt;, ...}}\n        Format to use pandas' replace:\n            {&lt;old value&gt;:&lt;new value&gt;, ...}\n\n    regex : bool\n        If true, replace using regular expression. It uses pandas\n        replace()\n\n    Returns\n    -------\n    tibble\n        Original tibble with values of columns replaced based on\n        rep`.\n    \"\"\"\n    if regex or not all(isinstance(value, dict) for value in rep.values()):\n        engine = 'pandas'\n    else:\n        engine = 'polars'\n\n    if engine=='polars':\n        out = self.to_polars()\n        for var, rep in rep.items():\n            try:\n                out = out.with_columns(**{var : pl.col(var).replace(rep)})\n            except :\n                out = out.with_columns(**{var : pl.col(var).replace_strict(rep)})\n        out = out.pipe(from_polars)\n    else:\n        out = self.to_pandas()\n        out = out.replace(to_replace=rep, regex=regex)\n        out = out.pipe(from_pandas)\n\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.replace_null","title":"<code>replace_null(replace=None)</code>","text":"<p>Replace null values</p> <p>Parameters:</p> Name Type Description Default <code>replace</code> <code>dict</code> <p>Dictionary of column/replacement pairs</p> <code>None</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with missing/null values replaced.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble(x = [0, None], y = [None, None])\n&gt;&gt;&gt; df.replace_null(dict(x = 1, y = 2))\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def replace_null(self, replace = None):\n    \"\"\"\n    Replace null values\n\n    Parameters\n    ----------\n    replace : dict\n        Dictionary of column/replacement pairs\n\n    Returns\n    -------\n    tibble\n        Original tibble with missing/null values replaced.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble(x = [0, None], y = [None, None])\n    &gt;&gt;&gt; df.replace_null(dict(x = 1, y = 2))\n    \"\"\"\n    if replace == None: return self\n    if type(replace) != dict:\n        ValueError(\"replace must be a dictionary of column/replacement pairs\")\n    replace_exprs = [col(key).fill_null(value) for key, value in replace.items()]\n    return self.mutate(*replace_exprs)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.select","title":"<code>select(*args)</code>","text":"<p>Select or drop columns</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str, list, dict, of combinations of them</code> <p>Columns to select. It can combine names, list of names, and a dict. If dict, it will rename the columns based on the dict. It also accepts tp.matches() and tp.contains() <code>()</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'abcba': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.select('a', 'b')\n&gt;&gt;&gt; df.select(col('a'), col('b'))\n&gt;&gt;&gt; df.select({'a': 'new name'}, tp.matches(\"c\"))\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def select(self, *args):\n    \"\"\"\n    Select or drop columns\n\n    Parameters\n    ----------\n    *args : str, list, dict, of combinations of them\n        Columns to select. It can combine names, list of names,\n        and a dict. If dict, it will rename the columns based\n        on the dict.\n        It also accepts tp.matches(&lt;regex&gt;) and tp.contains(&lt;str&gt;)\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'abcba': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.select('a', 'b')\n    &gt;&gt;&gt; df.select(col('a'), col('b'))\n    &gt;&gt;&gt; df.select({'a': 'new name'}, tp.matches(\"c\"))\n    \"\"\"\n    # convert to list if dict.keys or dict.values are used\n    cols_to_select = []\n    cols_to_rename = {}\n    for arg in args:\n        if isinstance(arg, {}.keys().__class__) or\\\n           isinstance(arg, {}.values().__class__):\n            cols_to_select += list(arg)\n\n        elif isinstance(arg, dict):\n            cols_to_select += [col for col,_ in arg.items()] \n            cols_to_rename |= arg \n\n        elif isinstance(arg, str):\n            cols_to_select += [arg]\n\n        elif isinstance(arg, list):\n            cols_to_select += arg\n\n        elif isinstance(arg, set):\n            cols_to_select += list(arg)\n\n    # # rename columns if dict is used\n    # cols_dict = [d for d in args if isinstance(d, dict)]\n    # if cols_dict:\n    #     cols_dict = cols_dict[0]\n    #     dict_list = list(cols_dict.values())\n    #     self = self.rename(cols_dict)\n    # else:\n    #     dict_list = []\n\n    # # collect str and list elements\n    # cols_list = [c for c in args if isinstance(c, str) or isinstance(c, list)]\n    # # flatten list\n    # cols_list = list(chain.from_iterable((x if isinstance(x, list)\n    #                                       else [x] for x in cols_list ))) \n\n    # # collect dict.keys() or dict.values()\n    # cols_dict_keys   = [k for k in args if isinstance( k, type({}.keys()) )]\n    # cols_dict_values = [k for k in args if isinstance( k, type({}.values()) )]\n\n    # # collect set\n    # cols_set = [s for s in args if isinstance(s, set)]\n    # if cols_set:\n    #     cols_set = list(cols_set[0])\n\n    # cols = cols_list + dict_list + cols_dict_keys +cols_dict_values +cols_set \n\n    # remove non-existing columns\n    cols_to_select = [col for col in cols_to_select \n                      if col in self.names \n                      or (col.startswith(\"^\") and col.endswith(\"$\"))] \n    # cols = [col for col in cols if col in self.names or\n    #         (col.startswith(\"^\") and col.endswith(\"$\"))]\n\n    cols = _col_exprs(cols_to_select)\n    return super().select(cols).pipe(from_polars).rename(cols_to_rename)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.separate","title":"<code>separate(sep_col, into, sep='_', remove=True)</code>","text":"<p>Separate a character column into multiple columns</p> <p>Parameters:</p> Name Type Description Default <code>sep_col</code> <code>str</code> <p>Column to split into multiple columns</p> required <code>into</code> <code>list</code> <p>List of new column names</p> required <code>sep</code> <code>str</code> <p>Separator to split on. Default to \u2018_\u2019</p> <code>'_'</code> <code>remove</code> <code>bool</code> <p>If True removes the input column from the output data frame</p> <code>True</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with a column splitted based on <code>sep</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble(x = ['a_a', 'b_b', 'c_c'])\n&gt;&gt;&gt; df.separate('x', into = ['left', 'right'])\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def separate(self, sep_col, into, sep = '_', remove = True):\n    \"\"\"\n    Separate a character column into multiple columns\n\n    Parameters\n    ----------\n    sep_col : str\n        Column to split into multiple columns\n    into : list\n        List of new column names\n    sep : str\n        Separator to split on. Default to '_'\n    remove : bool\n        If True removes the input column from the output data frame\n\n    Returns\n    -------\n    tibble\n        Original tibble with a column splitted based on `sep`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble(x = ['a_a', 'b_b', 'c_c'])\n    &gt;&gt;&gt; df.separate('x', into = ['left', 'right'])\n    \"\"\"\n    into_len = len(into) - 1\n    sep_df = (\n        self\n        .to_polars()\n        .select(col(sep_col)\n                .str.split_exact(sep, into_len)\n                .alias(\"_seps\")\n                .struct\n                .rename_fields(into))\n        .unnest(\"_seps\")\n        .pipe(from_polars)\n    )\n    out = self.bind_cols(sep_df)\n    if remove == True:\n        out = out.drop(sep_col)\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.set_names","title":"<code>set_names(nm=None)</code>","text":"<p>Change the column names of the data frame</p> <p>Parameters:</p> Name Type Description Default <code>nm</code> <code>list</code> <p>A list of new names for the data frame</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble(x = range(3), y = range(3))\n&gt;&gt;&gt; df.set_names(['a', 'b'])\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def set_names(self, nm = None):\n    \"\"\"\n    Change the column names of the data frame\n\n    Parameters\n    ----------\n    nm : list\n        A list of new names for the data frame\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble(x = range(3), y = range(3))\n    &gt;&gt;&gt; df.set_names(['a', 'b'])\n    \"\"\"\n    if nm == None: nm = self.names\n    nm = _as_list(nm)\n    rename_dict = {k:v for k, v in zip(self.names, nm)}\n    return self.rename(rename_dict)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.slice","title":"<code>slice(*args, by=None)</code>","text":"<p>Grab rows from a data frame</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>(int, list)</code> <p>Rows to grab</p> <code>()</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.slice(0, 1)\n&gt;&gt;&gt; df.slice(0, by = 'c')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def slice(self, *args, by = None):\n    \"\"\"\n    Grab rows from a data frame\n\n    Parameters\n    ----------\n    *args : int, list\n        Rows to grab\n    by : str, list\n        Columns to group by\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.slice(0, 1)\n    &gt;&gt;&gt; df.slice(0, by = 'c')\n    \"\"\"\n    rows = _as_list(args)\n    if _uses_by(by):\n        df = super(tibble, self).group_by(by).map_groups(lambda x: x.select(pl.all().gather(rows)))\n    else:\n        df = super(tibble, self).select(pl.all().gather(rows))\n    return df.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.slice_head","title":"<code>slice_head(n=5, *, by=None)</code>","text":"<p>Grab top rows from a data frame</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to grab</p> <code>5</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.slice_head(2)\n&gt;&gt;&gt; df.slice_head(1, by = 'c')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def slice_head(self, n = 5, *, by = None):\n    \"\"\"\n    Grab top rows from a data frame\n\n    Parameters\n    ----------\n    n : int\n        Number of rows to grab\n    by : str, list\n        Columns to group by\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.slice_head(2)\n    &gt;&gt;&gt; df.slice_head(1, by = 'c')\n    \"\"\"\n    col_order = self.names\n    if _uses_by(by):\n        df = super(tibble, self).group_by(by).head(n)\n    else:\n        df = super(tibble, self).head(n)\n    df = df.select(col_order)\n    return df.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.slice_tail","title":"<code>slice_tail(n=5, *, by=None)</code>","text":"<p>Grab bottom rows from a data frame</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to grab</p> <code>5</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.slice_tail(2)\n&gt;&gt;&gt; df.slice_tail(1, by = 'c')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def slice_tail(self, n = 5, *, by = None):\n    \"\"\"\n    Grab bottom rows from a data frame\n\n    Parameters\n    ----------\n    n : int\n        Number of rows to grab\n    by : str, list\n        Columns to group by\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.slice_tail(2)\n    &gt;&gt;&gt; df.slice_tail(1, by = 'c')\n    \"\"\"\n    col_order = self.names\n    if _uses_by(by):\n        df = super(tibble, self).group_by(by).tail(n)\n    else:\n        df = super(tibble, self).tail(n)\n    df = df.select(col_order)\n    return df.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.summarise","title":"<code>summarise(*args, by=None, **kwargs)</code>","text":"<p>Alias for <code>.summarize()</code></p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def summarise(self, *args,\n              by = None,\n              **kwargs):\n    \"\"\"Alias for `.summarize()`\"\"\"\n    return self.summarize(*args, by = by, **kwargs)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.summarize","title":"<code>summarize(*args, by=None, **kwargs)</code>","text":"<p>Aggregate data with summary statistics</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Expr</code> <p>Column expressions to add or modify</p> <code>()</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <code>**kwargs</code> <code>Expr</code> <p>Column expressions to add or modify</p> <code>{}</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble with the summaries</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')))\n&gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n...              by = 'c')\n&gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n...              max_b = tp.max(col('b')))\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def summarize(self, *args,\n              by = None,\n              **kwargs):\n    \"\"\"\n    Aggregate data with summary statistics\n\n    Parameters\n    ----------\n    *args : Expr\n        Column expressions to add or modify\n    by : str, list\n        Columns to group by\n    **kwargs : Expr\n        Column expressions to add or modify\n\n    Returns\n    -------\n    tibble\n        A tibble with the summaries\n\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')))\n    &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n    ...              by = 'c')\n    &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n    ...              max_b = tp.max(col('b')))\n    \"\"\"\n    exprs = _as_list(args) + _kwargs_as_exprs(kwargs)\n    if _uses_by(by):\n        out = super(tibble, self).group_by(by).agg(exprs)\n    else:\n        out = super(tibble, self).select(exprs)\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.tab","title":"<code>tab(row, col, groups=None, margins=True, normalize='all', margins_name='Total', stat='both', na_rm=True, na_label='NA', digits=2)</code>","text":"<p>Create a 2x2 contingency table for two categorical variables, with optional grouping, margins, and normalization.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>str</code> <p>Name of the variable to be used for the rows of the table.</p> required <code>col</code> <code>str</code> <p>Name of the variable to be used for the columns of the table.</p> required <code>groups</code> <code>str or list of str</code> <p>Variable name(s) to use as grouping variables. When provided, a separate 2x2 table is generated for each group.</p> <code>None</code> <code>margins</code> <code>bool</code> <p>If True, include row and column totals (margins) in the table.</p> <code>True</code> <code>normalize</code> <code>(all, row, columns)</code> <p>Specifies how to compute the marginal percentages in each cell:   - \u2018all\u2019: percentages computed over the entire table.   - \u2018row\u2019: percentages computed across each row.   - \u2018columns\u2019: percentages computed down each column.</p> <code>'all'</code> <code>margins_name</code> <code>str</code> <p>Name to assign to the row and column totals.</p> <code>'Total'</code> <code>stat</code> <code>(both, perc, n)</code> <p>Determines the statistic to display in each cell:   - \u2018both\u2019: returns both percentages and sample size.   - \u2018perc\u2019: returns percentages only.   - \u2018n\u2019: returns sample size only.</p> <code>'both'</code> <code>na_rm</code> <code>bool</code> <p>If True, remove rows with missing values in the <code>row</code> or <code>col</code> variables.</p> <code>True</code> <code>na_label</code> <code>str</code> <p>Label to use for missing values when <code>na_rm</code> is False.</p> <code>'NA'</code> <code>digits</code> <code>int</code> <p>Number of digits to round the percentages to.</p> <code>2</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A contingency table as a tibble. The table contains counts and/or percentages as specified by the <code>stat</code> parameter, includes margins if requested, and is formatted with group headers when grouping variables are provided.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def tab(self, row, col, groups=None,\n        margins=True, normalize='all',#row/columns\n        margins_name='Total', stat='both',\n        na_rm=True, na_label='NA', digits=2):\n    \"\"\"\n    Create a 2x2 contingency table for two categorical variables, with optional grouping,\n    margins, and normalization.\n\n    Parameters\n    ----------\n    row : str\n        Name of the variable to be used for the rows of the table.\n    col : str\n        Name of the variable to be used for the columns of the table.\n    groups : str or list of str, optional\n        Variable name(s) to use as grouping variables. When provided, a separate 2x2 table\n        is generated for each group.\n    margins : bool, default True\n        If True, include row and column totals (margins) in the table.\n    normalize : {'all', 'row', 'columns'}, default 'all'\n        Specifies how to compute the marginal percentages in each cell:\n          - 'all': percentages computed over the entire table.\n          - 'row': percentages computed across each row.\n          - 'columns': percentages computed down each column.\n    margins_name : str, default 'Total'\n        Name to assign to the row and column totals.\n    stat : {'both', 'perc', 'n'}, default 'both'\n        Determines the statistic to display in each cell:\n          - 'both': returns both percentages and sample size.\n          - 'perc': returns percentages only.\n          - 'n': returns sample size only.\n    na_rm : bool, default True\n        If True, remove rows with missing values in the `row` or `col` variables.\n    na_label : str, default 'NA'\n        Label to use for missing values when `na_rm` is False.\n    digits : int, default 2\n        Number of digits to round the percentages to.\n\n    Returns\n    -------\n    tibble\n        A contingency table as a tibble. The table contains counts and/or percentages as specified\n        by the `stat` parameter, includes margins if requested, and is formatted with group headers\n        when grouping variables are provided.\n    \"\"\"\n    tab = self.select(row, col, groups).mutate(**{row:as_character(row),\n                                                  col:as_character(col)})\n    vars_row = row\n    vars_col = col\n    if na_rm:\n        tab = tab.drop_null()\n    else:\n        repl = {var:na_label for var in [row, col]}\n        tab = tab.replace_null(repl)\n    tab = tab.to_pandas()\n    if groups:\n        groups = [groups] if isinstance(groups, str) else groups\n        ngroups=len(groups)\n        resn = self.__tab_groups__(tab, vars_row, vars_col, normalize=False,\n                                   margins=margins, margins_name=margins_name,\n                                   groups=groups)\n        resp = self.__tab_groups__(tab, vars_row, vars_col, normalize,\n                                   margins, margins_name, groups)\n    else:\n        ngroups=0\n        resn = self.__tab__(tab, vars_row, vars_col, normalize=False,\n                            margins=margins, margins_name=margins_name)\n        resp = self.__tab__(tab, vars_row, vars_col, normalize=normalize,\n                            margins=margins, margins_name=margins_name)\n    colsn=resn.columns[ngroups+1:]\n    colsp=resp.columns[ngroups+1:]\n    res=resp.iloc[:,0:ngroups+1]\n\n    if stat=='both':\n        for coln, colp in zip(colsn, colsp):\n            col = [f\"{round(100*p, digits)} % ({n})\" for p,n\n                   in zip(resp[colp], resn[coln])]\n            res = res.assign(**{coln:col})\n    elif stat=='perc':\n        for colp in colsp:\n            res = res.assign(**{str(colp):100*resp[colp]})\n    else:\n        for coln in colsn:\n            res = res.assign(**{str(coln):100*resp[coln]})\n    # Group columns using varname as label\n    ncat = len(tab[vars_col].unique())\n    ngroups = 0 if not groups else len(groups)\n    col_groups = ['']*(ngroups+1) + [vars_col]*ncat+['']\n    col_ix = pd.MultiIndex.from_arrays([col_groups, res.columns])\n    res.columns = col_ix\n    res.columns.names = ['', '']\n    res.columns.name = ''\n    res.columns = [col[1] for col in res.columns]\n    res = self.__tab_reorder_na__(res, row, na_label)\n    return from_pandas(res)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.tail","title":"<code>tail(n=5, *, by=None)</code>","text":"<p>Alias for <code>.slice_tail()</code></p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def tail(self, n = 5, *, by = None):\n    \"\"\"Alias for `.slice_tail()`\"\"\"\n    return self.slice_tail(n, by = by)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_csv","title":"<code>to_csv(*args, **kws)</code>","text":"<p>Save table to csv.</p> Details <p>See polars <code>write_csv()</code> for details.</p> <p>Returns:</p> Type Description <code>None</code> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_csv(self, *args, **kws):\n    \"\"\"\n    Save table to csv.\n\n    Details\n    -------\n    See polars `write_csv()` for details.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    self.to_polars().write_csv(*args, **kws)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_dict","title":"<code>to_dict(*, as_series=True)</code>","text":"<p>Aggregate data with summary statistics</p> <p>Parameters:</p> Name Type Description Default <code>as_series</code> <code>bool</code> <p>If True - returns the dict values as Series If False - returns the dict values as lists</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.to_dict()\n&gt;&gt;&gt; df.to_dict(as_series = False)\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_dict(self, *, as_series = True):\n    \"\"\"\n    Aggregate data with summary statistics\n\n    Parameters\n    ----------\n    as_series : bool\n        If True - returns the dict values as Series\n        If False - returns the dict values as lists\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.to_dict()\n    &gt;&gt;&gt; df.to_dict(as_series = False)\n    \"\"\"\n    return super().to_dict(as_series = as_series)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_excel","title":"<code>to_excel(*args, **kws)</code>","text":"<p>Save table to excel.</p> Details <p>See polars <code>write_excel()</code> for details.</p> <p>Returns:</p> Type Description <code>None</code> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_excel(self, *args, **kws):\n    \"\"\"\n    Save table to excel.\n\n    Details\n    -------\n    See polars `write_excel()` for details.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    self.to_polars().write_excel(*args, **kws)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_latex","title":"<code>to_latex(header=None, digits=4, caption=None, label=None, align=None, na_rep='', position='!htb', group_rows_by=None, group_title_align='l', footnotes=None, index=False, escape=False, longtable=False, longtable_singlespace=True, rotate=False, scale=True, parse_linebreaks=True, tabular=False)</code>","text":"<p>Convert the object to a LaTeX tabular representation.</p> <p>Parameters:</p> Name Type Description Default <code>header</code> <code>list of tuples</code> <p>The column headers for the LaTeX table. Each tuple corresponds to a column. Ex: This will create upper level header with grouped columns     [(\u201c\u201d, \u201ccol 1\u201d),      (\u201cGroup A\u201d, \u201ccol 2\u201d),      (\u201cGroup A\u201d, \u201ccol 3\u201d),      (\u201cGroup B\u201d, \u201ccol 4\u201d)      (\u201cGroup B\u201d, \u201ccol 5\u201d),       ]     This will create two upper level header with grouped columns     [(\u201cGroup 1\u201d, \u201c\u201d       , \u201ccol 1\u201d),      (\u201cGroup 1\u201d, \u201cGroup A\u201d, \u201ccol 2\u201d),      (\u201cGroup 1\u201d, \u201cGroup A\u201d, \u201ccol 3\u201d),      (\u201c\u201d       , \u201cGroup B\u201d, \u201ccol 4\u201d)      (\u201c\u201d       , \u201cGroup B\u201d, \u201ccol 5\u201d),       ]</p> <code>None</code> <code>digits</code> <code>int</code> <p>Number of decimal places to round the numerical values in the table.</p> <code>4</code> <code>caption</code> <code>str</code> <p>The caption for the LaTeX table.</p> <code>None</code> <code>label</code> <code>str</code> <p>The label for referencing the table in LaTeX.</p> <code>None</code> <code>align</code> <code>str</code> <p>Column alignment specifications (e.g., \u2018lcr\u2019).</p> <code>None</code> <code>na_rep</code> <code>str</code> <p>The representation for NaN values in the table.</p> <code>''</code> <code>position</code> <code>str</code> <p>The placement option for the table in the LaTeX document.</p> <code>'!htbp'</code> <code>footnotes</code> <code>dict</code> <p>A dictionary where keys are column alignments (\u2018c\u2019, \u2018r\u2019, or \u2018l\u2019) and values are the respective footnote strings.</p> <code>None</code> <code>group_rows_by</code> <code>str</code> <p>Name of the variable in the data with values to group the rows by.</p> <code>None</code> <code>group_title_align</code> <p>Alignment of the title of each row group</p> <code>'l'</code> <code>index</code> <code>bool</code> <p>Whether to include the index in the LaTeX table.</p> <code>False</code> <code>escape</code> <code>bool</code> <p>Whether to escape LaTeX special characters.</p> <code>False</code> <code>longtable</code> <code>bool, deafult=False</code> <p>If True, table spans multiple pages</p> <code>False</code> <code>longtable_singlespace</code> <code>bool</code> <p>Force single space to longtables</p> <code>True</code> <code>rotate</code> <code>bool</code> <p>Whether to use landscape table</p> <code>False</code> <code>scale</code> <code>bool</code> <p>If True, scales the table to fit the linewidth when the table exceeds that size Note: ignored when longtable=True. This is a LaTeX       limitation because longtable does not use       tabular.</p> <code>True</code> <code>parse_linebreaks</code> <code>book</code> <p>If True, parse \\n and replace it with \\makecel to produce linebreaks</p> <code>True</code> <code>tabular</code> <code>bool</code> <p>Whether to use a tabular format for the output.</p> <code>False</code> <p>Returns:</p> Type Description <code>    str</code> <p>A LaTeX formatted string of the tibble.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_latex(self,\n             header = None,\n             digits = 4,\n             caption = None,\n             label = None,\n             align = None,\n             na_rep  =  '',\n             position = '!htb',\n             group_rows_by = None,\n             group_title_align = 'l',\n             footnotes = None,\n             index = False,\n             escape = False,\n             longtable = False,\n             longtable_singlespace = True,\n             rotate = False,\n             scale = True,\n             parse_linebreaks=True,\n             tabular = False\n             ):\n    \"\"\"\n    Convert the object to a LaTeX tabular representation.\n\n    Parameters\n    ----------\n    header : list of tuples, optional\n        The column headers for the LaTeX table. Each tuple corresponds to a column.\n        Ex: This will create upper level header with grouped columns\n            [(\"\", \"col 1\"),\n             (\"Group A\", \"col 2\"),\n             (\"Group A\", \"col 3\"),\n             (\"Group B\", \"col 4\")\n             (\"Group B\", \"col 5\"),\n              ]\n            This will create two upper level header with grouped columns\n            [(\"Group 1\", \"\"       , \"col 1\"),\n             (\"Group 1\", \"Group A\", \"col 2\"),\n             (\"Group 1\", \"Group A\", \"col 3\"),\n             (\"\"       , \"Group B\", \"col 4\")\n             (\"\"       , \"Group B\", \"col 5\"),\n              ]\n    digits : int, default=4\n        Number of decimal places to round the numerical values in the table.\n\n    caption : str, optional\n        The caption for the LaTeX table.\n\n    label : str, optional\n        The label for referencing the table in LaTeX.\n\n    align : str, optional\n        Column alignment specifications (e.g., 'lcr').\n\n    na_rep : str, default=''\n        The representation for NaN values in the table.\n\n    position : str, default='!htbp'\n        The placement option for the table in the LaTeX document.\n\n    footnotes : dict, optional\n        A dictionary where keys are column alignments ('c', 'r', or 'l')\n        and values are the respective footnote strings.\n\n    group_rows_by : str, default=None\n        Name of the variable in the data with values to group\n        the rows by.\n\n    group_title_align str, default='l'\n        Alignment of the title of each row group\n\n    index : bool, default=False\n        Whether to include the index in the LaTeX table.\n\n    escape : bool, default=False\n        Whether to escape LaTeX special characters.\n\n    longtable : bool, deafult=False\n        If True, table spans multiple pages\n\n    longtable_singlespace : bool\n        Force single space to longtables\n\n    rotate : bool\n        Whether to use landscape table\n\n    scale : bool, default=True\n        If True, scales the table to fit the linewidth when\n        the table exceeds that size\n        Note: ignored when longtable=True. This is a LaTeX\n              limitation because longtable does not use\n              tabular.\n\n    parse_linebreaks : book, default=True\n        If True, parse \\\\n and replace it with \\\\makecel\n        to produce linebreaks\n\n    tabular : bool, default=False\n        Whether to use a tabular format for the output.\n\n    Returns\n    -------\n        str\n            A LaTeX formatted string of the tibble.\n    \"\"\"\n\n    assert footnotes is None or isinstance(footnotes, dict),\\\n        \"'footnote' must be a dictionary\"\n\n    # this must be the first operation\n    if group_rows_by is not None:\n        self = self.arrange(group_rows_by)\n        tabm = self.to_pandas().drop([group_rows_by], axis=1)\n    else:\n        tabm = self.to_pandas()\n    ncols = tabm.shape[1]\n\n    if tabular and not longtable:\n        position=None\n\n    if align is None:\n        align = 'l'*ncols\n\n    if header is not None:\n        tabm.columns = pd.MultiIndex.from_tuples(header)\n\n    tabl = (tabm\n            # .round(digits)\n            # .astype(str)\n            .to_latex(index = index,\n                      escape = escape,\n                      caption = caption,\n                      label = label,\n                      sparsify = True,\n                      multirow = True,\n                      multicolumn = True,\n                      multicolumn_format = 'c',\n                      column_format = align,\n                      bold_rows = True,\n                      na_rep = na_rep,\n                      float_format=f\"%.{digits}f\",\n                      position = position\n                      ))\n\n    # split to add elements\n    rows = tabl.splitlines()\n\n    if group_rows_by is not None:\n        rows = self.__to_latex_group_rows__(group_rows_by, group_title_align, ncols, rows)\n\n    # add centering\n    row = [i for i, txt in enumerate(rows) if\n           bool(re.search(pattern='begin.*tabular', string=txt))][0]\n    rows.insert(row,f\"\\\\centering\")\n\n    footnotes_formated = \"\"\n    if footnotes is not None:\n        for align_note, footnote in footnotes.items():\n            footnote = [footnote] if isinstance(footnote, str) else footnote\n            for fni in footnote:\n                notes = f\"\\\\multicolumn{{{ncols}}}{{{align_note}}}{{{fni}}}\\\\\\\\\"\n                footnotes_formated += notes\n                if not longtable:\n                    row = [idx for idx, s in enumerate(rows) if 'bottomrule' in s ][0]\n                    rows.insert(row + 1, notes)\n\n\n    # rejoin table\n    tabl = \"\\n\".join(rows)\n\n    # add midrules\n    if header is not None:\n        tabl = self.__to_latex_add_midrules_to_table__(tabl)\n\n    if longtable:\n        tabl = self.__to_latex_multipage__(tabl, caption, ncols, align,\n                                           label, position,\n                                           footnotes_formated,\n                                           longtable_singlespace)\n\n    if rotate:\n        tabl = re.sub(pattern=\"^\", repl='\\\\\\\\begin{landscape}', string=tabl)\n        tabl = re.sub(pattern=\"$\", repl='\\\\\\\\end{landscape}', string=tabl)\n\n    if scale and not longtable:\n        box = '\\\\resizebox{\\\\ifdim\\\\width&gt;\\\\linewidth\\\\linewidth\\\\else\\\\width\\\\fi}{!}{'\n        tabl = tabl.replace('\\\\begin{tabular}', f\"{box}\\n\\\\begin{{tabular}}\")\n        tabl = tabl.replace('\\\\end{tabular}', \"\\\\end{tabular}}\")\n\n    # linebreaks:\n    if parse_linebreaks:\n        tabl = self.__to_latex_breaklines__(tabl)    \n\n    return tabl\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert to a pandas DataFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.to_pandas()\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_pandas(self):\n    \"\"\"\n    Convert to a pandas DataFrame\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.to_pandas()\n    \"\"\"\n    # keep order of factors (pl.Enum)\n    enum_columns = [col for col in self.names if self.pull(col).dtype == pl.Enum]\n    res = self.to_polars().to_pandas()\n    if enum_columns :\n        for col in enum_columns:\n            # Get unique categories in order of appearance\n            categories_in_order = self.pull(col).cat.get_categories().to_list()\n            # Convert the column to Categorical\n            res[col] = pd.Categorical(\n                res[col],\n                categories=categories_in_order,\n                ordered=True\n            )\n    return res\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert to a polars DataFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.to_polars()\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_polars(self):\n    \"\"\"\n    Convert to a polars DataFrame\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.to_polars()\n    \"\"\"\n    self = copy.copy(self)\n    self.__class__ = pl.DataFrame\n    return self\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.unite","title":"<code>unite(col='_united', unite_cols=[], sep='_', remove=True)</code>","text":"<p>Unite multiple columns by pasting strings together</p> <p>Parameters:</p> Name Type Description Default <code>col</code> <code>str</code> <p>Name of the new column</p> <code>'_united'</code> <code>unite_cols</code> <code>list</code> <p>List of columns to unite</p> <code>[]</code> <code>sep</code> <code>str</code> <p>Separator to use between values</p> <code>'_'</code> <code>remove</code> <code>bool</code> <p>If True removes input columns from the data frame</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble(a = [\"a\", \"a\", \"a\"], b = [\"b\", \"b\", \"b\"], c = range(3))\n&gt;&gt;&gt; df.unite(\"united_col\", unite_cols = [\"a\", \"b\"])\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def unite(self, col = \"_united\", unite_cols = [], sep = \"_\", remove = True):\n    \"\"\"\n    Unite multiple columns by pasting strings together\n\n    Parameters\n    ----------\n    col : str\n        Name of the new column\n    unite_cols : list\n        List of columns to unite\n    sep : str\n        Separator to use between values\n    remove : bool\n        If True removes input columns from the data frame\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble(a = [\"a\", \"a\", \"a\"], b = [\"b\", \"b\", \"b\"], c = range(3))\n    &gt;&gt;&gt; df.unite(\"united_col\", unite_cols = [\"a\", \"b\"])\n    \"\"\"\n    if len(unite_cols) == 0:\n        unite_cols = self.names\n    else: \n        unite_cols = _col_exprs(unite_cols)\n        unite_cols = self.select(unite_cols).names\n    out = self.mutate(str_c(*unite_cols, sep = sep).alias(col))\n    out = out.relocate(col, before = unite_cols[0])\n    if remove == True:\n        out = out.drop(unite_cols)\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.unnest","title":"<code>unnest(col)</code>","text":"<p>Unnest a nested tibble</p> <p>Parameters:</p> Name Type Description Default <code>col</code> <code>str</code> <p>Columns to unnest</p> required <p>Returns:</p> Type Description <code>tibble</code> <p>The nested tibble will be expanded and become unested rows of the original tibble.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def unnest(self, col):\n    \"\"\"\n    Unnest a nested tibble\n    Parameters\n    ----------\n    col : str\n        Columns to unnest\n\n    Returns\n    -------\n    tibble\n        The nested tibble will be expanded and become unested\n        rows of the original tibble.\n\n    \"\"\"\n    assert isinstance(col, str), \"'col', must be a string\"\n    # not run: error if nested df has different columns\n    # out = (self\n    #        .mutate(**{\n    #            col : pl.col(col).map_elements(lambda d: d.to_struct())\n    #        })\n    #        .to_polars()\n    #        .explode(col)\n    #        .unnest(col)\n    #        )\n    # return out.pipe(from_polars)\n    out = tibble()\n    for row in self.to_polars().iter_rows(named=True):\n        n = row[col].nrow\n        ids = {c:v for c, v in row.items() if c not in col}\n        cols = list(ids.keys())\n        df_ids = from_polars(pl.DataFrame(ids)\n                             .with_columns(pl.col(cols) .repeat_by(n))\n                             .explode(cols))\n        out = out.bind_rows(df_ids.bind_cols(row[col]))\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.write_csv","title":"<code>write_csv(file=None, has_headers=True, sep=',')</code>","text":"<p>Write a data frame to a csv</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def write_csv(self,\n              file = None,\n              has_headers = True,\n              sep = ','):\n    \"\"\"Write a data frame to a csv\"\"\"\n    return super().write_csv(file, include_header = has_headers, separator = sep)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.write_parquet","title":"<code>write_parquet(file=str, compression='snappy', use_pyarrow=False, **kwargs)</code>","text":"<p>Write a data frame to a parquet</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def write_parquet(self,\n                  file = str,\n                  compression = 'snappy',\n                  use_pyarrow = False,\n                  **kwargs):\n    \"\"\"Write a data frame to a parquet\"\"\"\n    return super().write_parquet(file, compression = compression, use_pyarrow = use_pyarrow, **kwargs)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.abs","title":"<code>abs(x)</code>","text":"<p>Absolute value</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(abs_x = tp.abs('x'))\n&gt;&gt;&gt; df.mutate(abs_x = tp.abs(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def abs(x):\n    \"\"\"\n    Absolute value\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(abs_x = tp.abs('x'))\n    &gt;&gt;&gt; df.mutate(abs_x = tp.abs(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.abs()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_boolean","title":"<code>as_boolean(x)</code>","text":"<p>Convert column to string. Alias to as_logical (R naming).</p> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_boolean(x):\n    \"\"\"\n    Convert column to string. Alias to as_logical (R naming).\n    \"\"\"\n    return as_logical(x)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_categorical","title":"<code>as_categorical(*args, **kwargs)</code>","text":"<p>Convert to factor. Alias for as_factor</p> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_categorical(*args, **kwargs):\n    \"Convert to factor. Alias for as_factor\"\n    return as_factor(*args, **kwargs)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_character","title":"<code>as_character(x)</code>","text":"<p>Convert to string. Defaults to Utf8.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Str</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(string_x = tp.as_string('x'))\n# or equivalently\n&gt;&gt;&gt; df.mutate(character_x = tp.as_character('x'))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_character(x):\n    \"\"\"\n    Convert to string. Defaults to Utf8.\n\n    Parameters\n    ----------\n    x : Str \n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(string_x = tp.as_string('x'))\n    # or equivalently\n    &gt;&gt;&gt; df.mutate(character_x = tp.as_character('x'))\n    \"\"\"\n    x = _col_expr(x)\n    return x.cast(pl.Utf8)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_factor","title":"<code>as_factor(x, levels=None)</code>","text":"<p>Convert to factor (R naming), equlivalent to Enum or Categorical (polars), depending on whether \u2018levels\u2019 is provided. </p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Str</code> <p>Column to operate on</p> required <code>levels</code> <code>list of str</code> <p>Categories to use in the factor. The catogories will be ordered as they appear in the list. If None (default), it will create an unordered factor (polars Categorical).</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(factor_x = tp.as_factor('x'))\n# or equivalently\n&gt;&gt;&gt; df.mutate(categorical_x = tp.as_categorical('x'))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_factor(x, levels = None):\n    \"\"\"\n    Convert to factor (R naming), equlivalent to Enum or\n    Categorical (polars), depending on whether 'levels' is provided. \n\n    Parameters\n    ----------\n    x : Str\n        Column to operate on\n\n    levels : list of str\n        Categories to use in the factor. The catogories will be ordered\n        as they appear in the list. If None (default), it will\n        create an unordered factor (polars Categorical).\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(factor_x = tp.as_factor('x'))\n    # or equivalently\n    &gt;&gt;&gt; df.mutate(categorical_x = tp.as_categorical('x'))\n    \"\"\"\n    x = _col_expr(x)\n    x = x.cast(pl.String)\n    if levels is None:\n        x = x.cast(pl.Categorical)\n    else:\n        x = x.cast(pl.Enum(levels))\n    return x\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_float","title":"<code>as_float(x)</code>","text":"<p>Convert to float. Defaults to Float64.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(float_x = tp.as_float(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_float(x):\n    \"\"\"\n    Convert to float. Defaults to Float64.\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(float_x = tp.as_float(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.cast(pl.Float64)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_integer","title":"<code>as_integer(x)</code>","text":"<p>Convert to integer. Defaults to Int64.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Expr</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(int_x = tp.as_integer(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_integer(x):\n    \"\"\"\n    Convert to integer. Defaults to Int64.\n\n    Parameters\n    ----------\n    x : Expr\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(int_x = tp.as_integer(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.cast(pl.Int64)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_logical","title":"<code>as_logical(x)</code>","text":"<p>Convert to a boolean (polars) or \u2018logical\u2019 (R naming)</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Str</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(bool_x = tp.as_boolean(col('x')))\n# or equivalently\n&gt;&gt;&gt; df.mutate(logical_x = tp.as_logical(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_logical(x):\n    \"\"\"\n    Convert to a boolean (polars) or 'logical' (R naming)\n\n    Parameters\n    ----------\n    x : Str\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(bool_x = tp.as_boolean(col('x')))\n    # or equivalently\n    &gt;&gt;&gt; df.mutate(logical_x = tp.as_logical(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.cast(pl.Boolean)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_string","title":"<code>as_string(x)</code>","text":"<p>Convert column to string. Alias to as_character (R naming). Equivalent to Utf8 type (polars)</p> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_string(x):\n    '''\n    Convert column to string. Alias to as_character (R naming).\n    Equivalent to Utf8 type (polars)\n    '''\n    return as_character(x)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.cast","title":"<code>cast(x, dtype)</code>","text":"<p>General type conversion.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <code>dtype</code> <code>DataType</code> <p>Type to convert to</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(abs_x = tp.cast(col('x'), tp.Float64))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def cast(x, dtype):\n    \"\"\"\n    General type conversion.\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n    dtype : DataType\n        Type to convert to\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(abs_x = tp.cast(col('x'), tp.Float64))\n    \"\"\"\n    x = _col_expr(x)\n    return x.cast(dtype)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.cor","title":"<code>cor(x, y, method='pearson')</code>","text":"<p>Find the correlation of two columns</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Expr</code> <p>A column</p> required <code>y</code> <code>Expr</code> <p>A column</p> required <code>method</code> <code>str</code> <p>Type of correlation to find. Either \u2018pearson\u2019 or \u2018spearman\u2019.</p> <code>'pearson'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(cor = tp.cor(col('x'), col('y')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def cor(x, y, method = 'pearson'):\n    \"\"\"\n    Find the correlation of two columns\n\n    Parameters\n    ----------\n    x : Expr\n        A column\n    y : Expr\n        A column\n    method : str\n        Type of correlation to find. Either 'pearson' or 'spearman'.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(cor = tp.cor(col('x'), col('y')))\n    \"\"\"\n    if pl.Series([method]).is_in(['pearson', 'spearman']).not_().item():\n        ValueError(\"`method` must be either 'pearson' or 'spearman'\")\n    return pl.corr(x, y, method = method)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.count","title":"<code>count(x)</code>","text":"<p>Number of observations in each group</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(count = tp.count(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def count(x):\n    \"\"\"\n    Number of observations in each group\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(count = tp.count(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.count()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.cov","title":"<code>cov(x, y)</code>","text":"<p>Find the covariance of two columns</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Expr</code> <p>A column</p> required <code>y</code> <code>Expr</code> <p>A column</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(cor = tp.cov(col('x'), col('y')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def cov(x, y):\n    \"\"\"\n    Find the covariance of two columns\n\n    Parameters\n    ----------\n    x : Expr\n        A column\n    y : Expr\n        A column\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(cor = tp.cov(col('x'), col('y')))\n    \"\"\"\n    return pl.cov(x, y)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.first","title":"<code>first(x)</code>","text":"<p>Get first value</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(first_x = tp.first('x'))\n&gt;&gt;&gt; df.summarize(first_x = tp.first(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def first(x):\n    \"\"\"\n    Get first value\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(first_x = tp.first('x'))\n    &gt;&gt;&gt; df.summarize(first_x = tp.first(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.first()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.floor","title":"<code>floor(x)</code>","text":"<p>Round numbers down to the lower integer</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(floor_x = tp.floor(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def floor(x):\n    \"\"\"\n    Round numbers down to the lower integer\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(floor_x = tp.floor(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.floor()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.from_pandas","title":"<code>from_pandas(df)</code>","text":"<p>Convert from pandas DataFrame to tibble</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pd.DataFrame to convert to a tibble</p> required <p>Returns:</p> Type Description <code>tibble</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tp.from_pandas(df)\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def from_pandas(df):\n    \"\"\"\n    Convert from pandas DataFrame to tibble\n\n    Parameters\n    ----------\n    df : DataFrame\n        pd.DataFrame to convert to a tibble\n\n    Returns\n    -------\n    tibble\n\n    Examples\n    --------\n    &gt;&gt;&gt; tp.from_pandas(df)\n    \"\"\"\n    if isinstance(df, pd.DataFrame):\n        try:\n            # Try to convert directly\n            df = from_polars(pl.from_pandas(df))\n        except Exception as e:\n            print(f\"Error during conversion: {e}\")\n            print(\"Identifying problematic columns...\")\n\n            # Identify problematic columns by attempting individual conversions\n            problematic_columns = []\n            for column in df.columns:\n                try:\n                    pl.from_pandas(df[[column]])\n                except Exception as col_error:\n                    print(f\"Column '{column}' caused an error: {col_error}\")\n                    problematic_columns.append(column)\n\n            # Convert problematic columns to string type\n            for column in problematic_columns:\n                df[column] = df[column].astype(str)\n    elif isinstance(df, tibble):\n        pass\n    elif isinstance(df, pl.DataFrame):\n        df = from_polars(df)\n    else:\n        df = None\n    return df\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.from_polars","title":"<code>from_polars(df)</code>","text":"<p>Convert from polars DataFrame to tibble</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pl.DataFrame to convert to a tibble</p> required <p>Returns:</p> Type Description <code>tibble</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tp.from_polars(df)\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def from_polars(df):\n    \"\"\"\n    Convert from polars DataFrame to tibble\n\n    Parameters\n    ----------\n    df : DataFrame\n        pl.DataFrame to convert to a tibble\n\n    Returns\n    -------\n    tibble\n\n    Examples\n    --------\n    &gt;&gt;&gt; tp.from_polars(df)\n    \"\"\"\n    # df = copy.copy(df)\n    # df.__class__ = tibble\n    df = tibble(df)\n    return df\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.last","title":"<code>last(x)</code>","text":"<p>Get last value</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(last_x = tp.last('x'))\n&gt;&gt;&gt; df.summarize(last_x = tp.last(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def last(x):\n    \"\"\"\n    Get last value\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(last_x = tp.last('x'))\n    &gt;&gt;&gt; df.summarize(last_x = tp.last(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.last()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.length","title":"<code>length(x)</code>","text":"<p>Number of observations in each group</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(length = tp.length(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def length(x):\n    \"\"\"\n    Number of observations in each group\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(length = tp.length(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.count()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.max","title":"<code>max(x)</code>","text":"<p>Get column max</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(max_x = tp.max('x'))\n&gt;&gt;&gt; df.summarize(max_x = tp.max(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def max(x):\n    \"\"\"\n    Get column max\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(max_x = tp.max('x'))\n    &gt;&gt;&gt; df.summarize(max_x = tp.max(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.max()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.mean","title":"<code>mean(x)</code>","text":"<p>Get column mean</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(mean_x = tp.mean('x'))\n&gt;&gt;&gt; df.summarize(mean_x = tp.mean(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def mean(x):\n    \"\"\"\n    Get column mean\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(mean_x = tp.mean('x'))\n    &gt;&gt;&gt; df.summarize(mean_x = tp.mean(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.mean()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.median","title":"<code>median(x)</code>","text":"<p>Get column median</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(median_x = tp.median('x'))\n&gt;&gt;&gt; df.summarize(median_x = tp.median(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def median(x):\n    \"\"\"\n    Get column median\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(median_x = tp.median('x'))\n    &gt;&gt;&gt; df.summarize(median_x = tp.median(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.median()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.min","title":"<code>min(x)</code>","text":"<p>Get column minimum</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(min_x = tp.min('x'))\n&gt;&gt;&gt; df.summarize(min_x = tp.min(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def min(x):\n    \"\"\"\n    Get column minimum\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(min_x = tp.min('x'))\n    &gt;&gt;&gt; df.summarize(min_x = tp.min(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.min()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.min_rank","title":"<code>min_rank(x)</code>","text":"<p>Assigns a minimum rank to each element in the input list, handling ties by assigning the same (lowest) rank to tied values. The next distinct value\u2019s rank is increased by the number of tied values before it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>list</code> <p>A list of values (numeric or otherwise) to be ranked.</p> required <p>Returns:</p> Type Description <code>list of int</code> <p>A list of ranks corresponding to the elements of <code>x</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; min_rank([10, 20, 20, 30])\n[1, 2, 2, 4]\n&gt;&gt;&gt; min_rank([3, 1, 2])\n[3, 1, 2]  # since sorted order is 1,2,3 =&gt; ranks are assigned as per their order\n&gt;&gt;&gt; min_rank([\"b\", \"a\", \"a\", \"c\"])\n[2, 1, 1, 4]\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def min_rank(x):\n    \"\"\"\n    Assigns a minimum rank to each element in the input list, handling ties by\n    assigning the same (lowest) rank to tied values. The next distinct value's rank\n    is increased by the number of tied values before it.\n\n    Parameters\n    ----------\n    x : list\n        A list of values (numeric or otherwise) to be ranked.\n\n    Returns\n    -------\n    list of int\n        A list of ranks corresponding to the elements of `x`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; min_rank([10, 20, 20, 30])\n    [1, 2, 2, 4]\n    &gt;&gt;&gt; min_rank([3, 1, 2])\n    [3, 1, 2]  # since sorted order is 1,2,3 =&gt; ranks are assigned as per their order\n    &gt;&gt;&gt; min_rank([\"b\", \"a\", \"a\", \"c\"])\n    [2, 1, 1, 4]\n    \"\"\"\n    # Get the indices of the x sorted by their corresponding elements\n    indices = sorted(range(len(x)), key=lambda i: x[i])\n    ranks = [None] * len(x)\n\n    current_rank = 1\n    i = 0\n    n = len(x)\n\n    # Iterate through sorted x and assign ranks\n    while i &lt; n:\n        val = x[indices[i]]\n        # Find how many times this value is repeated\n        j = i\n        while j &lt; n and x[indices[j]] == val:\n            j += 1\n\n        # The group from i to j-1 (inclusive) are all the same value\n        count = j - i\n        # Assign the current_rank to all tied elements\n        for k in range(i, j):\n            ranks[indices[k]] = current_rank\n        # Increment the rank by the count of elements in this tie group\n        current_rank += count\n        i = j\n\n    return ranks\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.n","title":"<code>n()</code>","text":"<p>Number of observations in each group</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(count = tp.n())\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def n():\n    \"\"\"\n    Number of observations in each group\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(count = tp.n())\n    \"\"\"\n    return pl.len()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.quantile","title":"<code>quantile(x, quantile=0.5)</code>","text":"<p>Get number of distinct values in a column</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <code>quantile</code> <code>float</code> <p>Quantile to return</p> <code>0.5</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(quantile_x = tp.quantile('x', .25))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def quantile(x, quantile = .5):\n    \"\"\"\n    Get number of distinct values in a column\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    quantile : float\n        Quantile to return\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(quantile_x = tp.quantile('x', .25))\n    \"\"\"\n    x = _col_expr(x)\n    return x.quantile(quantile)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.scale","title":"<code>scale(x)</code>","text":"<p>Standardize the input by scaling it to a mean of 0 and a standard deviation of 1.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Expr</code> <p>Column to operate on</p> required <p>Returns:</p> Type Description <code>array - like</code> <p>The standardized version of the input data.</p> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def scale(x):\n    \"\"\"\n    Standardize the input by scaling it to a mean of 0 and a standard deviation of 1.\n\n    Parameters\n    ----------\n    x : Expr\n        Column to operate on\n\n    Returns\n    -------\n    array-like\n        The standardized version of the input data.\n    \"\"\"\n    x = _col_expr(x)\n    return (x - x.mean()) / x.std()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.sd","title":"<code>sd(x)</code>","text":"<p>Get column standard deviation</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(sd_x = tp.sd('x'))\n&gt;&gt;&gt; df.summarize(sd_x = tp.sd(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def sd(x):\n    \"\"\"\n    Get column standard deviation\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(sd_x = tp.sd('x'))\n    &gt;&gt;&gt; df.summarize(sd_x = tp.sd(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.std()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.sum","title":"<code>sum(x)</code>","text":"<p>Get column sum</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(sum_x = tp.sum('x'))\n&gt;&gt;&gt; df.summarize(sum_x = tp.sum(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def sum(x):\n    \"\"\"\n    Get column sum\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(sum_x = tp.sum('x'))\n    &gt;&gt;&gt; df.summarize(sum_x = tp.sum(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.sum()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.var","title":"<code>var(x)</code>","text":"<p>Get column variance</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Expr</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(sum_x = tp.var('x'))\n&gt;&gt;&gt; df.summarize(sum_x = tp.var(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def var(x):\n    \"\"\"\n    Get column variance\n\n    Parameters\n    ----------\n    x : Expr\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(sum_x = tp.var('x'))\n    &gt;&gt;&gt; df.summarize(sum_x = tp.var(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.var()\n</code></pre>"},{"location":"comparing/","title":"Comparing","text":""},{"location":"comparing/#mutate","title":"Mutate","text":"tidypolars4sciPolarsPandastidyverse <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre>"},{"location":"releases/","title":"Releases","text":"<p>Check the GitHub page for information about releases.</p>"},{"location":"case-studies/pivot-wide/","title":"Pivot wide","text":""},{"location":"case-studies/pivot-wide/#performance","title":"Performance","text":"<p>Let us use the data set <code>mtcars</code> to create a table in wide format using <code>pivot_wide</code>. Here are the variables</p> <pre><code>import tidypolars4sci as tp\nfrom tidypolars4sci.data import mtcars\n\nmtcars.glimpse()\n</code></pre> <pre><code>Columns matching pattern '.':\n Var Type     Uniq Miss (%) Head                                                       \nname &lt;object&gt;   32    0 0% ['Mazda RX4' 'Mazda RX4 Wag' 'Datsun 710' 'Hornet 4 Drive'\n...\n mpg &lt;float64&gt;  25    0 0% [21.  21.  22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16....\n cyl &lt;int64&gt;     3    0 0% [6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 ...\ndisp &lt;float64&gt;  27    0 0% [160.  160.  108.  258.  360.  225.  360.  146.7 140.8 167....\n  hp &lt;int64&gt;    22    0 0% [110 110  93 110 175 105 245  62  95 123 123 180 180 180 20...\ndrat &lt;float64&gt;  22    0 0% [3.9  3.9  3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 3.92 3.0...\n  wt &lt;float64&gt;  29    0 0% [2.62  2.875 2.32  3.215 3.44  3.46  3.57  3.19  3.15  3.44...\nqsec &lt;float64&gt;  30    0 0% [16.46 17.02 18.61 19.44 17.02 20.22 15.84 20.   22.9  18.3...\n  vs &lt;int64&gt;     2    0 0% [0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 ...\n  am &lt;int64&gt;     2    0 0% [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 ...\ngear &lt;int64&gt;     3    0 0% [4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 ...\ncarb &lt;int64&gt;     6    0 0% [4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 ...\n\n[Rows: 32; Columns 12]\n</code></pre> <p>A simple pivot wide operation:</p> <pre><code>from tidypolars4sci.data import mtcars\n\ntab = (mtcars\n       .select('name', 'am')\n       .pivot_wider(values_from='name', names_from='am')\n       )\nprint(tab)\n</code></pre> <pre><code>shape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1        0      \u2502\n\u2502 str      str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Mazda\u2026   Horne\u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Table below shows summary after 1,000 repetitions comparing the same operation in Pandas, Polars, and tidypolars4sci:</p> <pre><code>shape: (3, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Mpdule           Mean (sec)   SD (sec)   Min (sec)   Max (sec)   How much slower than polars? \u2502\n\u2502 str                     f64        f64         f64         f64   str                          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Polars              0.00042    0.00010     0.00026     0.00099   1.0x (baseline)              \u2502\n\u2502 TidyPolars4sci      0.00079    0.00022     0.00049     0.00199   1.9x                         \u2502\n\u2502 Pandas              0.00227    0.00065     0.00147     0.00544   5.4x                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Here is the summary of the performance:</p> <p></p>"},{"location":"case-studies/pivot-wide/#sintax-comparison","title":"Sintax comparison","text":"tidypolars4sciPandasPolars <pre><code>tab = (df\n       .select(col, 'am')\n       .pivot_wider(values_from=col, names_from='am',\n                    values_fn=tp.element().sort().str.concat(\"; \"))\n       )\n</code></pre> <pre><code>tab=(df\n     .filter(['name', \"am\"])\n     .pivot_table(index=None, values=col, columns=\"am\",\n                  aggfunc=lambda col: \"; \".join(sorted(col))\n                  )\n     )\n</code></pre> <pre><code>tab = (df\n       .select([col, \"am\"])\n       .with_columns(idx=0)\n       .pivot(index='idx', on=\"am\", values=col,\n              aggregate_function=pl.element().sort().str.concat(\"; \")\n              )\n       )\n</code></pre>"},{"location":"performance/performance/","title":"Performance","text":""},{"location":"performance/performance/#filter","title":"Filter","text":"<pre><code>import tidypolars4sci as tp\nimport pandas as pd\nimport polars as pl\nimport numpy as np\nimport time\n\nnum_rows = 20_000_000\ndf_tp = tp.tibble({'a':np.random.choice(['apple','banana','carrot',\n                                    'date','eggplant'], num_rows), \n                 'b':np.random.rand(num_rows),\n                 'c':np.random.rand(num_rows),\n                 'd':np.random.rand(num_rows)})\ndf_pandas = df_tp.to_pandas()\ndf_polars = df_tp.to_polars()\n\n\nprocessing_time = {'pandas': [],\n                   'polars': [],\n                   'tidypolars4sci': [],\n                   }\n\n# pandas \n# ------\nstart_time = time.time()\nfor _ in range(10):\n    df_pandas.query(\"a=='apple' | a=='banana'\")\n    processing_time['pandas'] += [time.time() - start_time]\n\n# polars \n# ------\nstart_time = time.time()\nfor _ in range(10):\n    df_polars.filter((pl.col('a')=='apple') | (pl.col('a')=='banana'))\n    processing_time['polars'] += [time.time() - start_time]\n\n# tidypolars4si\n# -------------\nstart_time = time.time()\nfor _ in range(10):\n    df_tp.filter((tp.col('a')=='apple') | (tp.col('a')=='banana'))\n    processing_time['tidypolars4sci'] += [time.time() - start_time]\n\n\n# summary\nsummary=tp.tibble(processing_time)\nsummary.descriptive_statistics().arrange('Mean').print()\n</code></pre> <pre><code>shape: (3, 10)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Variable           N   Missing (%)   Mean   Std.Dev.    Min    25%    50%     75%     Max \u2502\n\u2502 str              i64           f64    f64        f64    f64    f64    f64     f64     f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 tidypolars4sci    10          0.00   1.06       0.59   0.20   0.57   1.15    1.54    1.93 \u2502\n\u2502 polars            10          0.00   1.07       0.59   0.19   0.57   1.16    1.55    1.94 \u2502\n\u2502 pandas            10          0.00   7.25       3.84   1.40   4.09   7.97   10.49   12.76 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"performance/performance/#pivot-wide","title":"Pivot wide","text":"<p>Let us use the data set <code>mtcars</code> to create a table in wide format using <code>pivot_wide</code>. Here are the variables</p> <pre><code>import tidypolars4sci as tp\nfrom tidypolars4sci.data import mtcars\n\nmtcars.glimpse()\n</code></pre> <pre><code>Columns matching pattern '.':\n Var Type     Uniq Miss (%) Head                                                       \nname &lt;object&gt;   32    0 0% ['Mazda RX4' 'Mazda RX4 Wag' 'Datsun 710' 'Hornet 4 Drive'\n...\n mpg &lt;float64&gt;  25    0 0% [21.  21.  22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16....\n cyl &lt;int64&gt;     3    0 0% [6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 ...\ndisp &lt;float64&gt;  27    0 0% [160.  160.  108.  258.  360.  225.  360.  146.7 140.8 167....\n  hp &lt;int64&gt;    22    0 0% [110 110  93 110 175 105 245  62  95 123 123 180 180 180 20...\ndrat &lt;float64&gt;  22    0 0% [3.9  3.9  3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 3.92 3.0...\n  wt &lt;float64&gt;  29    0 0% [2.62  2.875 2.32  3.215 3.44  3.46  3.57  3.19  3.15  3.44...\nqsec &lt;float64&gt;  30    0 0% [16.46 17.02 18.61 19.44 17.02 20.22 15.84 20.   22.9  18.3...\n  vs &lt;int64&gt;     2    0 0% [0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 ...\n  am &lt;int64&gt;     2    0 0% [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 ...\ngear &lt;int64&gt;     3    0 0% [4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 ...\ncarb &lt;int64&gt;     6    0 0% [4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 ...\n\n[Rows: 32; Columns 12]\n</code></pre> <p>A simple pivot wide operation:</p> <pre><code>from tidypolars4sci.data import mtcars\n\ntab = (mtcars\n       .select('name', 'am')\n       .pivot_wider(values_from='name', names_from='am')\n       )\nprint(tab)\n</code></pre> <pre><code>shape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1        0      \u2502\n\u2502 str      str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Mazda\u2026   Horne\u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Table below shows summary after 1,000 repetitions comparing the same operation in Pandas, Polars, and tidypolars4sci:</p> <pre><code>shape: (3, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Mpdule           Mean (sec)   SD (sec)   Min (sec)   Max (sec)   How much slower than polars? \u2502\n\u2502 str                     f64        f64         f64         f64   str                          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Polars              0.00031    0.00005     0.00025     0.00092   1.0x (baseline)              \u2502\n\u2502 TidyPolars4sci      0.00076    0.00007     0.00065     0.00184   2.4x                         \u2502\n\u2502 Pandas              0.00261    0.00018     0.00250     0.00492   8.3x                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Here is the summary of the performance:</p> <p></p>"},{"location":"usage/installation/","title":"Installation","text":"<p>You can install tidypolars4sci with <code>pip</code>:</p> <pre><code>$ pip3 install tidypolars4sci\n</code></pre> <p>Or through <code>conda</code>:</p> <pre><code>$ conda install -c conda-forge tidypolars4sci\n</code></pre>"},{"location":"usage/usage/","title":"Basic usage","text":"<p>tidypolars4sci methods are designed to work like tidyverse functions:</p> <pre><code>import tidypolars4sci as tp\n\n# create tibble data frame\ndf = tp.tibble(x = range(3),\n               y = range(3, 6),\n               z = ['a', 'a', 'b'])\n\n(\n    df\n    .select('x', 'y', 'z')\n    .filter(tp.col('x') &lt; 4, tp.col('y') &gt; 1)\n    .arrange(tp.desc('z'), 'x')\n    .mutate(double_x = tp.col('x') * 2,\n            x_plus_y = tp.col('x') + tp.col('y')\n            )\n)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 x   \u2506 y   \u2506 z   \u2506 double_x \u2506 x_plus_y \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2506 ---      \u2506 ---      \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2506 i64      \u2506 i64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 5   \u2506 b   \u2506 4        \u2506 7        \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 0   \u2506 3   \u2506 a   \u2506 0        \u2506 3        \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 1   \u2506 4   \u2506 a   \u2506 2        \u2506 5        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/usage/#converting-tofrom-pandas-data-frames","title":"Converting to/from pandas data frames","text":"<p>If you need to use a package that requires pandas or polars data frames, you can convert from a tidypolars4sci <code>tibble</code> to either of those <code>DataFrame</code> formats.</p> <pre><code># convert to pandas...\ndf = df.to_pandas()\n# ... or convert to polars\ndf = df.to_polars()\n</code></pre> <p>To convert from a pandas or polars <code>DataFrame</code> to a tidypolars <code>tibble</code>:</p> <pre><code># convert from pandas...\ndf = tp.from_pandas(df)\n# or covert from polars\ndf = tp.from_polars(df)\n</code></pre>"},{"location":"usage/data-manipulation/mutate/","title":"Mutate","text":""},{"location":"usage/data-manipulation/mutate/#basic-examples","title":"Basic examples","text":"<p>To create new variables based transformation of existing ones:</p> <pre><code>import tidypolars4sci as tp\nfrom tidypolars4sci.data import starwars\n\ndf = (starwars\n      .head(5) # &lt;= to select onlye the fist 5 for the example\n      .select('name', 'mass')\n      # create two new variables:\n      .mutate(mass2 = tp.col('mass') * 2,\n              mass2_squared = tp.col('mass2') * tp.col('mass2'),\n              )\n      )\ndf.print()\n</code></pre> <pre><code>shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name               mass    mass2   mass2_squared \u2502\n\u2502 str                 f64      f64             f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker    77.00   154.00       23,716.00 \u2502\n\u2502 C-3PO             75.00   150.00       22,500.00 \u2502\n\u2502 R2-D2             32.00    64.00        4,096.00 \u2502\n\u2502 Darth Vader      136.00   272.00       73,984.00 \u2502\n\u2502 Leia Organa       49.00    98.00        9,604.00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/data-manipulation/mutate/#change-type-of-many-variables-at-once","title":"Change type of many variables at once","text":"<p>We can change the types of many variables that match a name pattern</p> <pre><code># select some rows and varibles\ndf = (starwars\n      .head(5) \n      .select(\"name\", \"homeworld\", \"species\")\n      )\ndf.print()\n</code></pre> <pre><code>shape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name             homeworld   species \u2502\n\u2502 str              str         str     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker   Tatooine    Human   \u2502\n\u2502 C-3PO            Tatooine    Droid   \u2502\n\u2502 R2-D2            Naboo       Droid   \u2502\n\u2502 Darth Vader      Tatooine    Human   \u2502\n\u2502 Leia Organa      Alderaan    Human   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># change to factor (i.e., category) those whose name matches hom|sp\ndf = df.mutate(tp.across(tp.matches(\"hom|sp\"),  tp.as_factor))\ndf.print()\n</code></pre> <pre><code>shape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name             homeworld   species \u2502\n\u2502 str              cat         cat     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker   Tatooine    Human   \u2502\n\u2502 C-3PO            Tatooine    Droid   \u2502\n\u2502 R2-D2            Naboo       Droid   \u2502\n\u2502 Darth Vader      Tatooine    Human   \u2502\n\u2502 Leia Organa      Alderaan    Human   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/data-manipulation/mutate/#using-dynamic-variable-names","title":"Using dynamic variable names","text":"<p>We can use dynamic names to create the new variable:</p> <pre><code>new_var = \"mass2_squared\"\ndf = (starwars\n      .head(5) # &lt;= to select onlye the fist 5 for the example\n      .select('name', 'mass')\n      # create a new variable using dynamic name:\n      .mutate(**{new_var : tp.col('mass') **2 })\n      )\ndf.print()\n</code></pre> <pre><code>shape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name               mass   mass2_squared \u2502\n\u2502 str                 f64             f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker    77.00        5,929.00 \u2502\n\u2502 C-3PO             75.00        5,625.00 \u2502\n\u2502 R2-D2             32.00        1,024.00 \u2502\n\u2502 Darth Vader      136.00       18,496.00 \u2502\n\u2502 Leia Organa       49.00        2,401.00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"}]}