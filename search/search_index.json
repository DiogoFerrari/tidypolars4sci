{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"Combining Polars and Tidyverse for Python <p>Note</p> <p>This site is still under construction, but full documentation can be found in package docstrings and API Reference.</p> <p>tidypolars provides functions that match as closely as possible to R\u2019s Tidyverse functions for manipulating data frames and conducting data analysis in Python using the blazingly fast Polars as backend.</p>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Fast: Uses Polars as a backend for data manipulation. Therefore, it inherits many advantages of that module: fast, parallel, GPU support, etc.</li> <li>Tidy: Keeps the data in a tidy (rectangular table) format (no multi-indexes).</li> <li>Syntax: While Polars is fast, the syntax is not the most intuitive. The package provides frontend methods that match R\u2019s Tidyverse functions, making it easier for users familiar with that ecosystem to transition to this library.</li> <li>Extended functionalities: Polars is extended to facilitate data manipulation and analysis for academic research.</li> <li>Research: The package is designed to facilitate academic research, data analysis, and reporting of results. It provides functions to quickly produce tables using minimal code, and whose output matches the format commonly used in academic publications. Those output formats include LaTeX, Excel, CSV, and others.</li> </ul>"},{"location":"#syntax","title":"Syntax","text":"<p>The main motivation for tidypolars was to provide more readable and elegant syntax in Python for Polars, similar to R\u2019s Tidyverse, while (1) extending Polars functionalities to facilitate data manipulation and (2) keeping the advantages of speed and efficiency in data processing provided by that module. Here are some examples of syntax differences:</p> tidypolars4sciTidyverse (R)PolarsPandas <pre><code>tab = (df\n       .filter(tp.col(\"carb\")&lt;8)\n       .filter(tp.col(\"name\").str.contains(\"Mazda|Toyota|Merc\"))\n       .mutate(cyl_squared = tp.col(\"cyl\")**2,\n               cyl_group = tp.case_when(tp.col(\"cyl\")&lt;tp.col(\"cyl\").mean(), \"Low cyl\",\n                                        tp.col(\"cyl\")&gt;tp.col(\"cyl\").mean(), \"High cyl\",\n                                        True, 'Average cyl'),\n               am = tp.as_factor(\"am\")\n               )\n        .select(\"name\", \"am\")\n        .pivot_wider(values_from=\"name\", names_from=\"am\",\n                     values_fn=tp.element().sort().str.concat(\"; \"))\n        )\n</code></pre> <pre><code>tab = (df\n    %&gt;% filter(carb &lt; 8)\n    %&gt;% filter(str_detect(name, \"Mazda|Toyota|Merc\"))\n    %&gt;% mutate(cyl_squared = cyl^2,\n               cyl_group = case_when(cyl &lt; mean(cyl) ~ \"Low cyl\",\n                                     cyl &gt; mean(cyl) ~ \"High cyl\",\n                                     TRUE ~ \"Average cyl\"),\n               am = as.factor(am)\n               )\n    %&gt;% select(name, am)\n    %&gt;% pivot_wider(names_from = am, values_from = name,\n                    values_fn = list(name = ~ paste(sort(.), collapse = \"; \")))\n)\n</code></pre> <pre><code>tab = (df.to_polars()\n       .filter(pl.col(\"carb\") &lt; 8)\n       .filter(pl.col(\"name\").str.contains(\"Mazda|Toyota|Merc\"))\n       .with_columns([\n           (pl.col(\"cyl\") ** 2).alias(\"cyl_squared\"),\n           (pl\n            .when(pl.col(\"cyl\") &lt; pl.col(\"cyl\").mean()).then(pl.lit(\"Low cyl\"))\n            .when(pl.col(\"cyl\") &gt; pl.col(\"cyl\").mean()).then(pl.lit(\"High cyl\"))\n            .otherwise(pl.lit(\"Average cyl\")).alias(\"cyl_group\")),\n           (pl.col(\"am\").cast(pl.String).cast(pl.Categorical).alias(\"am\"))\n       ])\n       .select([\"name\", \"am\"])\n       .with_columns(idx=0)\n       # pivot-wide\n       .pivot(index='idx', on=\"am\", values=\"name\",\n              aggregate_function=pl.element().sort().str.concat(\"; \")\n              )\n       .drop('idx')\n       )\n</code></pre> <pre><code> tab = (df\n        .query(f\"carb &lt; 8\")\n        .query(f\"name.str.contains('Mazda|Toyota|Merc')\")\n        .assign(cyl_squared = lambda col: col[\"cyl\"]**2,\n                cyl_group = lambda col: pd.cut(col[\"cyl\"], \n                                               bins=[-float(\"inf\"), col[\"cyl\"].mean(),\n                                                      float(\"inf\")],\n                                               labels=[\"Low cyl\", \"High cyl\"]),\n                am = lambda col: col[\"am\"].astype(\"str\"))\n        .filter([\"name\", \"am\"])\n        .pivot_table(columns=\"am\", values=\"name\",\n                     aggfunc = lambda x: \"; \".join(x)))\n</code></pre>"},{"location":"#performance","title":"Performance","text":"<p>In most cases, the performance of tidypolars is comparable to Polars. In some instances, it may operate slightly slower due to the additional functionalities provided by the module. Check the section Performance for details.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#tidypolars4sci.tibble_df.tibble","title":"<code>tibble</code>","text":"<p>               Bases: <code>DataFrame</code></p> <p>A data frame object that provides methods familiar to R tidyverse users.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>class tibble(pl.DataFrame):\n    \"\"\"\n    A data frame object that provides methods familiar to R tidyverse users.\n    \"\"\"\n    def __init__(self,  *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    @property\n    def _constructor(self):\n        # '''\n        # This method ensures that the method tibble return an instance\n        # of tibble, instead of a DataFrame\n        # '''\n        return self.__class__\n\n    def _repr_html_(self):\n        # \"\"\"\n        # Printing method for jupyter\n\n        # Output rows and columns can be modified by setting the following ENVIRONMENT variables:\n\n        # * POLARS_FMT_MAX_COLS: set the number of columns\n\n        # * POLARS_FMT_MAX_ROWS: set the number of rows\n        # \"\"\"\n        df = self.to_polars()\n        return df._repr_html_()\n\n    def __copy__(self):\n        # Shallow copy\n        # See: https://stackoverflow.com/a/51043609/13254470\n        obj = type(self).__new__(self.__class__)\n        obj.__dict__.update(self.__dict__)\n        return obj\n\n    def __getattribute__(self, attr):\n        if attr in _polars_methods:\n            raise AttributeError\n        return pl.DataFrame.__getattribute__(self, attr)\n\n    def __dir__(self):\n        _tidypolars_methods = [\n            'arrange', 'bind_cols', 'bind_rows', 'colnames', 'clone', 'count',\n            'crossing',\n            'distinct', 'drop', 'drop_null', 'head', 'fill', 'filter',\n            'group_by', \n            'inner_join', 'left_join', 'mutate', 'names', 'nest',\n            'nrow', 'ncol',\n            'full_join', 'pivot_longer', 'pivot_wider', 'print',\n            'pull', 'relocate', 'rename',\n            'replace',\n            'replace_null', 'select',\n            'separate', 'set_names',\n            'slice', 'slice_head', 'slice_tail', 'summarize', 'tail',\n            'to_pandas', 'to_polars', 'unnest', 'write_csv', 'write_parquet'\n        ]\n        return _tidypolars_methods\n\n    def arrange(self, *args):\n        \"\"\"\n        Arrange/sort rows\n\n        Parameters\n        ----------\n        *args : str\n            Columns to sort by\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n        &gt;&gt;&gt; # Arrange in ascending order\n        &gt;&gt;&gt; df.arrange('x', 'y')\n        &gt;&gt;&gt; # Arrange some columns descending\n        &gt;&gt;&gt; df.arrange(tp.desc('x'), 'y')\n\n        Returns\n        ------- \n        tibble\n            Original tibble orderd by *args\n        \"\"\"\n        exprs = _as_list(args)\n        desc = [True if isinstance(expr, DescCol) else False for expr in exprs]\n        return super()\\\n            .sort(exprs, descending = desc, nulls_last=True)\\\n            .pipe(from_polars)\n\n    def bind_cols(self, *args):\n        \"\"\"\n        Bind data frames by columns\n\n        Parameters\n        ----------\n        *args : tibble\n            Data frame to bind\n\n        Returns\n        ------- \n        tibble\n            The original tibble with added columns \n            from the other tibble specified in *args\n\n        Examples\n        --------\n        &gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n        &gt;&gt;&gt; df2 = tp.tibble({'a': ['c', 'c', 'c'], 'b': range(4, 7)})\n        &gt;&gt;&gt; df1.bind_cols(df2)\n        \"\"\"\n        frames = _as_list(args)\n        out = self.to_polars()\n        for frame in frames:\n            out = out.hstack(frame)\n        return out.pipe(from_polars)\n\n    def bind_rows(self, *args):\n        \"\"\"\n        Bind data frames by row\n\n        Parameters\n        ----------\n        *args : tibble, list\n            Data frames to bind by row\n\n        Returns\n        ------- \n        tibble\n            The original tibble with added rows \n            from the other tibble specified in *args\n\n        Examples\n        --------\n        &gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n        &gt;&gt;&gt; df2 = tp.tibble({'x': ['c', 'c', 'c'], 'y': range(4, 7)})\n        &gt;&gt;&gt; df1.bind_rows(df2)\n        \"\"\"\n        frames = _as_list(args)\n        out = pl.concat([self, *frames], how = \"diagonal\")\n        return out.pipe(from_polars)\n\n    def clone(self):\n        \"\"\"\n        Very cheap deep clone\n        \"\"\"\n        return super().clone().pipe(from_polars)\n\n    def count(self, *args, sort = False, name = 'n'):\n        \"\"\"\n        Returns row counts of the dataset. \n        If bare column names are provided, count() returns counts by group.\n\n        Parameters\n        ----------\n        *args : str, Expr\n            Columns to group by\n        sort : bool\n            Should columns be ordered in descending order by count\n        name : str\n            The name of the new column in the output. If omitted, it will default to \"n\".\n\n        Returns\n        ------- \n        tibble\n            If no agument is provided, just return the nomber of rows.\n            If column names are provided, it will count the unique \n            values across columns\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': [1, 1, 2, 3],\n        ...:                 'b': ['a', 'a', 'b', 'b']})\n        &gt;&gt;&gt; df.count()\n        shape: (1, 1)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   n \u2502\n        \u2502 u32 \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502   4 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2518\n        &gt;&gt;&gt; df.count('a', 'b')\n        shape: (3, 3)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   a   b       n \u2502\n        \u2502 i64   str   u32 \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502   1   a       2 \u2502\n        \u2502   2   b       1 \u2502\n        \u2502   3   b       1 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \"\"\"\n        args = _as_list(args)\n\n        out = self.summarize(pl.len().alias(name), by = args)\n\n        if sort == True:\n            out = out.arrange(desc(name))\n\n        return out\n\n    def distinct(self, *args, keep_all = True):\n        \"\"\"\n        Select distinct/unique rows\n\n        Parameters\n        ----------\n        *args : str, Expr\n            Columns to find distinct/unique rows\n\n        keep_all : boll\n            If True, keep all columns. Otherwise, return\n            only the ones used to select the distinct rows.\n\n        Returns\n        ------- \n        tibble\n            Tibble after removing the repeated rows based on *args\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.distinct()\n        &gt;&gt;&gt; df.distinct('b')\n        \"\"\"\n        args = _as_list(args)\n        # \n        if len(args) == 0:\n            df = super().unique()\n        else:\n            df = super().unique(args)\n        if not keep_all and len(args) &gt; 0:\n            df = df.select(args)\n        return df.pipe(from_polars)\n\n    def drop(self, *args):\n        \"\"\"\n        Drop unwanted columns\n\n        Parameters\n        ----------\n        *args : str\n            Columns to drop\n\n        Returns\n        ------- \n        tibble\n            Tibble with columns in *args dropped\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.drop('x', 'y')\n        \"\"\"\n        args = _as_list(args)\n        drop_cols = self.select(args).names\n        return super().drop(drop_cols).pipe(from_polars)\n\n    def drop_null(self, *args):\n        \"\"\"\n        Drop rows containing missing values\n\n        Parameters\n        ----------\n        *args : str\n            Columns to drop nulls from (defaults to all)\n\n        Returns\n        ------- \n        tibble\n            Tibble with rows in *args with missing values dropped\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble(x = [1, None, 3], y = [None, 'b', 'c'], z = range(3)}\n        &gt;&gt;&gt; df.drop_null()\n        &gt;&gt;&gt; df.drop_null('x', 'y')\n        \"\"\"\n        args = _as_list(args)\n        if len(args) == 0:\n            out = super().drop_nulls()\n        else:\n            out = super().drop_nulls(args)\n        return out.pipe(from_polars)\n\n    def equals(self, other, null_equal = True):\n        \"\"\"\n        Check if two tibbles are equal\n        \"\"\"\n        df = self.to_polars()\n        other = other.to_polars()\n        return df.equals(other, null_equal = null_equal)\n\n    def head(self, n = 5, *, by = None):\n        \"\"\"\n        Alias for `.slice_head()`\n        \"\"\"\n        return self.slice_head(n, by = by)\n\n    def fill(self, *args, direction = 'down', by = None):\n        \"\"\"\n        Fill in missing values with previous or next value\n\n        Parameters\n        ----------\n        *args : str\n            Columns to fill\n        direction : str\n            Direction to fill. One of ['down', 'up', 'downup', 'updown']\n        by : str, list\n            Columns to group by\n\n        Returns\n        ------- \n        tibble\n            Tibble with missing values filled\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': [1, None, 3, 4, 5],\n        ...                 'b': [None, 2, None, None, 5],\n        ...                 'groups': ['a', 'a', 'a', 'b', 'b']})\n        &gt;&gt;&gt; df.fill('a', 'b')\n        &gt;&gt;&gt; df.fill('a', 'b', by = 'groups')\n        &gt;&gt;&gt; df.fill('a', 'b', direction = 'downup')\n        \"\"\"\n        args = _as_list(args)\n        if len(args) == 0: return self\n        args = _col_exprs(args)\n        options = {'down': 'forward', 'up': 'backward'}\n        if direction in ['down', 'up']:\n            direction = options[direction]\n            exprs = [arg.fill_null(strategy = direction) for arg in args]\n        elif direction == 'downup':\n            exprs = [\n                arg.fill_null(strategy = 'forward')\n                .fill_null(strategy = 'backward')\n                for arg in args\n            ]\n        elif direction == 'updown':\n            exprs = [\n                arg.fill_null(strategy = 'backward')\n                .fill_null(strategy = 'forward')\n                for arg in args\n            ]\n        else:\n            raise ValueError(\"direction must be one of down, up, downup, or updown\")\n\n        return self.mutate(*exprs, by = by)\n\n    def filter(self, *args,\n               by = None):\n        \"\"\"\n        Filter rows on one or more conditions\n\n        Parameters\n        ----------\n        *args : Expr\n            Conditions to filter by\n        by : str, list\n            Columns to group by\n\n        Returns\n        ------- \n        tibble\n            A tibble with rows that match condition.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.filter(col('a') &lt; 2, col('b') == 'a')\n        &gt;&gt;&gt; df.filter((col('a') &lt; 2) &amp; (col('b') == 'a'))\n        &gt;&gt;&gt; df.filter(col('a') &lt;= tp.mean(col('a')), by = 'b')\n        \"\"\"\n        args = _as_list(args)\n        exprs = ft.reduce(lambda a, b: a &amp; b, args)\n\n        if _uses_by(by):\n            out = super().group_by(by).map_groups(lambda x: x.filter(exprs))\n        else:\n            out = super().filter(exprs)\n\n        return out.pipe(from_polars)\n\n    def inner_join(self, df, left_on = None, right_on = None, on = None, suffix = '_right'):\n        \"\"\"\n        Perform an inner join\n\n        Parameters\n        ----------\n        df : tibble\n            Lazy DataFrame to join with.\n        left_on : str, list\n            Join column(s) of the left DataFrame.\n        right_on : str, list\n            Join column(s) of the right DataFrame.\n        on: str, list\n            Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n        suffix : str\n            Suffix to append to columns with a duplicate name.\n\n        Returns\n        ------- \n        tibble\n            A tibble with intersection of cases in the original and\n            df tibbles.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df1.inner_join(df2)\n        &gt;&gt;&gt; df1.inner_join(df2, on = 'x')\n        &gt;&gt;&gt; df1.inner_join(df2, left_on = 'left_x', right_on = 'x')\n        \"\"\"\n        if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n            on = list(set(self.names) &amp; set(df.names))\n        return super().join(df, on, 'inner',\n                            left_on = left_on,\n                            right_on= right_on,\n                            suffix= suffix).pipe(from_polars)\n\n    def left_join(self, df, left_on = None, right_on = None, on = None, suffix = '_right'):\n        \"\"\"\n        Perform a left join\n\n        Parameters\n        ----------\n        df : tibble\n            Lazy DataFrame to join with.\n        left_on : str, list\n            Join column(s) of the left DataFrame.\n        right_on : str, list\n            Join column(s) of the right DataFrame.\n        on: str, list\n            Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n        suffix : str\n            Suffix to append to columns with a duplicate name.\n\n        Returns\n        ------- \n        tibble\n             The original tibble with added columns from tibble df if\n             they match columns in the original one. Columns to match\n             on are given in the function parameters.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df1.left_join(df2)\n        &gt;&gt;&gt; df1.left_join(df2, on = 'x')\n        &gt;&gt;&gt; df1.left_join(df2, left_on = 'left_x', right_on = 'x')\n        \"\"\"\n        if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n            on = list(set(self.names) &amp; set(df.names))\n        return super().join(df, on, 'left',  left_on = left_on, right_on= right_on, suffix= suffix).pipe(from_polars)\n\n    def mutate(self, *args, by = None, **kwargs):\n        \"\"\"\n        Add or modify columns\n\n        Parameters\n        ----------\n        *args : Expr\n            Column expressions to add or modify\n        by : str, list\n            Columns to group by\n        **kwargs : Expr\n            Column expressions to add or modify\n\n        Returns\n        ------- \n        tibble\n            Original tibble with new column created.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), c = ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.mutate(double_a = col('a') * 2,\n        ...           a_plus_b = col('a') + col('b'))\n        &gt;&gt;&gt; df.mutate(row_num = row_number(), by = 'c')\n        \"\"\"\n        exprs = _as_list(args) + _kwargs_as_exprs(kwargs)\n\n        out = self.to_polars()\n\n        if _uses_by(by):\n            out = out.group_by(by).map_groups(lambda x: _mutate_cols(x, exprs))\n        else:\n            out = _mutate_cols(out, exprs)\n\n        return out.pipe(from_polars)\n\n    @property\n    def names(self):\n        \"\"\"\n        Get column names\n\n        Returns\n        ------- \n        list\n            Names of the columns\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.names\n        \"\"\"\n        return super().columns\n\n    @property\n    def ncol(self):\n        \"\"\"\n        Get number of columns\n\n        Returns\n        ------- \n        int\n            Number of columns\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.ncol\n        \"\"\"\n        return super().shape[1]\n\n    @property\n    def nrow(self):\n        \"\"\"\n        Get number of rows\n\n        Returns\n        ------- \n        int\n            Number of rows\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.nrow\n        \"\"\"\n        return super().shape[0]\n\n    def full_join(self, df, left_on = None, right_on = None, on = None, suffix: str = '_right'):\n        \"\"\"\n        Perform an full join\n\n        Parameters\n        ----------\n        df : tibble\n            Lazy DataFrame to join with.\n        left_on : str, list\n            Join column(s) of the left DataFrame.\n        right_on : str, list\n            Join column(s) of the right DataFrame.\n        on: str, list\n            Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n        suffix : str\n            Suffix to append to columns with a duplicate name.\n\n        Returns\n        ------- \n        tibble\n            Union between the original and the df tibbles. The\n            rows that don't match in one of the tibbles will be\n            completed with missing values.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df1.full_join(df2)\n        &gt;&gt;&gt; df1.full_join(df2, on = 'x')\n        &gt;&gt;&gt; df1.full_join(df2, left_on = 'left_x', right_on = 'x')\n        \"\"\"\n        if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n            on = list(set(self.names) &amp; set(df.names))\n        return super().join(df, on, 'outer',\n                            left_on = left_on,\n                            right_on= right_on, suffix= suffix).pipe(from_polars)\n\n    def pivot_longer(self,\n                     cols = None,\n                     names_to = \"name\",\n                     values_to = \"value\"):\n        \"\"\"\n        Pivot data from wide to long\n\n        Parameters\n        ----------\n        cols : Expr\n            List of the columns to pivot. Defaults to all columns.\n        names_to : str\n            Name of the new \"names\" column.\n        values_to: str\n            Name of the new \"values\" column\n\n        Returns\n        ------- \n        tibble\n            Original tibble, but in long format.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'id': ['id1', 'id2'], 'a': [1, 2], 'b': [1, 2]})\n        &gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'])\n        &gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'], names_to = 'stuff', values_to = 'things')\n        \"\"\"\n        if cols is None:\n            cols = everything()\n        if isinstance(cols, dict):\n            cols = list(cols.keys())\n\n        df_cols = pl.Series(self.names)\n        value_vars = self.select(cols).names\n        id_vars = df_cols.filter(df_cols.is_in(value_vars).not_()).to_list()\n        out = super().melt(id_vars, value_vars, names_to, values_to)\n        return out.pipe(from_polars)\n\n    def pivot_wider(self,\n                    names_from = 'name',\n                    values_from = 'value',\n                    id_cols = None,\n                    values_fn = 'first', \n                    values_fill = None\n                    ):\n        \"\"\"\n        Pivot data from long to wide\n\n        Parameters\n        ----------\n        names_from : str\n            Column to get the new column names from.\n        values_from : str\n            Column to get the new column values from\n        id_cols : str, list\n            A set of columns that uniquely identifies each observation.\n            Defaults to all columns in the data table except for the columns specified in\n            `names_from` and `values_from`.\n        values_fn : str\n            Function for how multiple entries per group should be dealt with.\n            Any of 'first', 'count', 'sum', 'max', 'min', 'mean', 'median', 'last'\n        values_fill : str\n            If values are missing/null, what value should be filled in.\n            Can use: \"backward\", \"forward\", \"mean\", \"min\", \"max\", \"zero\", \"one\"\n\n        Returns\n        ------- \n        tibble\n            Original tibble, but in wide format.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'id': [1, 1], 'variable': ['a', 'b'], 'value': [1, 2]})\n        &gt;&gt;&gt; df.pivot_wider(names_from = 'variable', values_from = 'value')\n        \"\"\"\n        if id_cols == None:\n            df_cols = pl.Series(self.names)\n            from_cols = pl.Series(self.select(names_from, values_from).names)\n            id_cols = df_cols.filter(df_cols.is_in(from_cols).not_()).to_list()\n\n        no_id = len(id_cols) == 0\n\n        if no_id:\n            id_cols = '___id__'\n            self = self.mutate(___id__ = pl.lit(1))\n\n        out = (\n            super()\n            .pivot(index=id_cols, on=names_from, values=values_from, aggregate_function=values_fn)\n            .pipe(from_polars)\n        )\n\n        if values_fill != None:\n            new_cols = pl.Series(out.names)\n            new_cols = new_cols.filter(~new_cols.is_in(id_cols))\n            fill_exprs = [col(new_col).fill_null(values_fill) for new_col in new_cols]\n            out = out.mutate(*fill_exprs)\n\n        if no_id: out = out.drop('___id__')\n\n        return out\n\n    def pull(self, var = None):\n        \"\"\"\n        Extract a column as a series\n\n        Parameters\n        ----------\n        var : str\n            Name of the column to extract. Defaults to the last column.\n\n        Returns\n        ------- \n        Series\n            The series will contain the values of the column from `var`.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3))\n        &gt;&gt;&gt; df.pull('a')\n        \"\"\"\n        if var == None:\n            var = self.names[-1]\n\n        return super().get_column(var)\n\n    def relevel(self, x, ref):\n        \"\"\"\n        Change the reference level a string or factor and covert to factor\n\n        Inputs\n        ------\n        x : str\n            Variable name\n\n        ref : str\n           Reference level\n\n        Returns\n        ------- \n        tibble\n            The original tibble with the column specified in `x` as\n            an ordered factors, with first category specified in `ref`.\n        \"\"\"\n        levels = self.pull(x).unique().to_list()\n        relevels = [ref] + [l for l in levels if l != ref]\n        self = self.mutate(**{x : as_factor(x, relevels)})\n        return self\n\n    def relocate(self, *args, before = None, after = None):\n        \"\"\"\n        Move a column or columns to a new position\n\n        Parameters\n        ----------\n        *args : str, Expr\n            Columns to move\n\n        Returns\n        ------- \n        tibble\n            Original tibble with columns relocated.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.relocate('a', before = 'c')\n        &gt;&gt;&gt; df.relocate('b', after = 'c')\n        \"\"\"\n        cols_all = pl.Series(self.names)\n        locs_all = pl.Series(range(len(cols_all)))\n        locs_dict = {k:v for k,v in zip(cols_all, locs_all)}\n        locs_df = pl.DataFrame(locs_dict, orient = \"row\")\n\n        cols_relocate = _as_list(args)\n        locs_relocate = pl.Series(locs_df.select(cols_relocate).row(0))\n\n        if (len(locs_relocate) == 0):\n            return self\n\n        uses_before = before != None\n        uses_after = after != None\n\n        if (uses_before &amp; uses_after):\n            raise ValueError(\"Cannot provide both before and after\")\n        elif (not_(uses_before) &amp; not_(uses_after)):\n            before = cols_all[0]\n            uses_before = True\n\n        if uses_before:\n            before = locs_df.select(before).get_column(before)\n            locs_start = locs_all.filter(locs_all &lt; before)\n        else:\n            after = locs_df.select(after).get_column(after)\n            locs_start = locs_all.filter(locs_all &lt;= after)\n\n        locs_start = locs_start.filter(~locs_start.is_in(locs_relocate))\n        final_order = pl.concat([locs_start, locs_relocate, locs_all]).unique(maintain_order = True)\n        final_order = cols_all[final_order].to_list()\n\n        return self.select(final_order)\n\n    def rename(self, columns=None, regex=False, tolower=False, strict=False):\n        \"\"\"\n        Rename columns\n\n        Parameters\n        ----------\n        columns : dict, default None\n            Dictionary mapping of old and new names\n            {&lt;old name&gt;:&lt;new name&gt;, ...}\n\n        regex : bool, default False\n            If True, uses regular expression replacement\n            {&lt;matched from&gt;:&lt;matched to&gt;}\n\n        tolower : bool, default False\n            If True, convert all to lower case\n\n        Returns\n        ------- \n        tibble\n            Original tibble with columns renamed.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'x': range(3), 't': range(3), 'z': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.rename({'x': 'new_x'}) \n        \"\"\"\n        assert isinstance(columns, dict) or columns is None,\\\n            \"'columns' must be a dictionary or None.\"\n\n        if columns is not None:\n            if regex:\n                self = self.__rename_regexp__(columns)\n            else:\n                self = super().rename(columns, strict=False).pipe(from_polars)\n\n        if tolower:\n            self = self.__rename_tolower__()\n        return self\n\n    def __rename_regexp__(self, mapping):\n        pattern = next(iter(mapping))\n        replacement = next(iter(mapping.values()))\n        old = self.names\n        new = [re.sub(pattern, replacement, col) for col in self.names]\n        mapping = {o:n for o, n in zip(old, new)}\n        return self.rename(mapping, regex=False)\n\n    def __rename_tolower__(self):\n        old = self.names\n        new = [col.lower() for col in self.names]\n        mapping = {o:n for o, n in zip(old, new)}\n        return self.rename(mapping, regex=False)\n\n    def replace_null(self, replace = None):\n        \"\"\"\n        Replace null values\n\n        Parameters\n        ----------\n        replace : dict\n            Dictionary of column/replacement pairs\n\n        Returns\n        -------\n        tibble\n            Original tibble with missing/null values replaced.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble(x = [0, None], y = [None, None])\n        &gt;&gt;&gt; df.replace_null(dict(x = 1, y = 2))\n        \"\"\"\n        if replace == None: return self\n        if type(replace) != dict:\n            ValueError(\"replace must be a dictionary of column/replacement pairs\")\n        replace_exprs = [col(key).fill_null(value) for key, value in replace.items()]\n        return self.mutate(*replace_exprs)\n\n    def separate(self, sep_col, into, sep = '_', remove = True):\n        \"\"\"\n        Separate a character column into multiple columns\n\n        Parameters\n        ----------\n        sep_col : str\n            Column to split into multiple columns\n        into : list\n            List of new column names\n        sep : str\n            Separator to split on. Default to '_'\n        remove : bool\n            If True removes the input column from the output data frame\n\n        Returns\n        -------\n        tibble\n            Original tibble with a column splitted based on `sep`.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble(x = ['a_a', 'b_b', 'c_c'])\n        &gt;&gt;&gt; df.separate('x', into = ['left', 'right'])\n        \"\"\"\n        into_len = len(into) - 1\n        sep_df = (\n            self\n            .to_polars()\n            .select(col(sep_col)\n                    .str.split_exact(sep, into_len)\n                    .alias(\"_seps\")\n                    .struct\n                    .rename_fields(into))\n            .unnest(\"_seps\")\n            .pipe(from_polars)\n        )\n        out = self.bind_cols(sep_df)\n        if remove == True:\n            out = out.drop(sep_col)\n        return out\n\n    def set_names(self, nm = None):\n        \"\"\"\n        Change the column names of the data frame\n\n        Parameters\n        ----------\n        nm : list\n            A list of new names for the data frame\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble(x = range(3), y = range(3))\n        &gt;&gt;&gt; df.set_names(['a', 'b'])\n        \"\"\"\n        if nm == None: nm = self.names\n        nm = _as_list(nm)\n        rename_dict = {k:v for k, v in zip(self.names, nm)}\n        return self.rename(rename_dict)\n\n    def select(self, *args):\n        \"\"\"\n        Select or drop columns\n\n        Parameters\n        ----------\n        *args : str, list, dict, of combinations of them\n            Columns to select. It can combine names, list of names,\n            and a dict. If dict, it will rename the columns based\n            on the dict.\n            It also accepts tp.matches(&lt;regex&gt;) and tp.contains(&lt;str&gt;)\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'abcba': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.select('a', 'b')\n        &gt;&gt;&gt; df.select(col('a'), col('b'))\n        &gt;&gt;&gt; df.select({'a': 'new name'}, tp.matches(\"c\"))\n        \"\"\"\n        # convert to list if dict.keys or dict.values are used\n        cols_to_select = []\n        cols_to_rename = {}\n        for arg in args:\n            if isinstance(arg, {}.keys().__class__) or\\\n               isinstance(arg, {}.values().__class__):\n                cols_to_select += list(arg)\n\n            elif isinstance(arg, dict):\n                cols_to_select += [col for col,_ in arg.items()] \n                cols_to_rename |= arg \n\n            elif isinstance(arg, str):\n                cols_to_select += [arg]\n\n            elif isinstance(arg, list):\n                cols_to_select += arg\n\n            elif isinstance(arg, set):\n                cols_to_select += list(arg)\n\n        # # rename columns if dict is used\n        # cols_dict = [d for d in args if isinstance(d, dict)]\n        # if cols_dict:\n        #     cols_dict = cols_dict[0]\n        #     dict_list = list(cols_dict.values())\n        #     self = self.rename(cols_dict)\n        # else:\n        #     dict_list = []\n\n        # # collect str and list elements\n        # cols_list = [c for c in args if isinstance(c, str) or isinstance(c, list)]\n        # # flatten list\n        # cols_list = list(chain.from_iterable((x if isinstance(x, list)\n        #                                       else [x] for x in cols_list ))) \n\n        # # collect dict.keys() or dict.values()\n        # cols_dict_keys   = [k for k in args if isinstance( k, type({}.keys()) )]\n        # cols_dict_values = [k for k in args if isinstance( k, type({}.values()) )]\n\n        # # collect set\n        # cols_set = [s for s in args if isinstance(s, set)]\n        # if cols_set:\n        #     cols_set = list(cols_set[0])\n\n        # cols = cols_list + dict_list + cols_dict_keys +cols_dict_values +cols_set \n\n        # remove non-existing columns\n        cols_to_select = [col for col in cols_to_select \n                          if col in self.names \n                          or (col.startswith(\"^\") and col.endswith(\"$\"))] \n        # cols = [col for col in cols if col in self.names or\n        #         (col.startswith(\"^\") and col.endswith(\"$\"))]\n\n        cols = _col_exprs(cols_to_select)\n        return super().select(cols).pipe(from_polars).rename(cols_to_rename)\n\n    def slice(self, *args, by = None):\n        \"\"\"\n        Grab rows from a data frame\n\n        Parameters\n        ----------\n        *args : int, list\n            Rows to grab\n        by : str, list\n            Columns to group by\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.slice(0, 1)\n        &gt;&gt;&gt; df.slice(0, by = 'c')\n        \"\"\"\n        rows = _as_list(args)\n        if _uses_by(by):\n            df = super(tibble, self).group_by(by).map_groups(lambda x: x.select(pl.all().gather(rows)))\n        else:\n            df = super(tibble, self).select(pl.all().gather(rows))\n        return df.pipe(from_polars)\n\n    def slice_head(self, n = 5, *, by = None):\n        \"\"\"\n        Grab top rows from a data frame\n\n        Parameters\n        ----------\n        n : int\n            Number of rows to grab\n        by : str, list\n            Columns to group by\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.slice_head(2)\n        &gt;&gt;&gt; df.slice_head(1, by = 'c')\n        \"\"\"\n        col_order = self.names\n        if _uses_by(by):\n            df = super(tibble, self).group_by(by).head(n)\n        else:\n            df = super(tibble, self).head(n)\n        df = df.select(col_order)\n        return df.pipe(from_polars)\n\n    def slice_tail(self, n = 5, *, by = None):\n        \"\"\"\n        Grab bottom rows from a data frame\n\n        Parameters\n        ----------\n        n : int\n            Number of rows to grab\n        by : str, list\n            Columns to group by\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.slice_tail(2)\n        &gt;&gt;&gt; df.slice_tail(1, by = 'c')\n        \"\"\"\n        col_order = self.names\n        if _uses_by(by):\n            df = super(tibble, self).group_by(by).tail(n)\n        else:\n            df = super(tibble, self).tail(n)\n        df = df.select(col_order)\n        return df.pipe(from_polars)\n\n    def summarise(self, *args,\n                  by = None,\n                  **kwargs):\n        \"\"\"Alias for `.summarize()`\"\"\"\n        return self.summarize(*args, by = by, **kwargs)\n\n    def summarize(self, *args,\n                  by = None,\n                  **kwargs):\n        \"\"\"\n        Aggregate data with summary statistics\n\n        Parameters\n        ----------\n        *args : Expr\n            Column expressions to add or modify\n        by : str, list\n            Columns to group by\n        **kwargs : Expr\n            Column expressions to add or modify\n\n        Returns\n        -------\n        tibble\n            A tibble with the summaries\n\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n        &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')))\n        &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n        ...              by = 'c')\n        &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n        ...              max_b = tp.max(col('b')))\n        \"\"\"\n        exprs = _as_list(args) + _kwargs_as_exprs(kwargs)\n        if _uses_by(by):\n            out = super(tibble, self).group_by(by).agg(exprs)\n        else:\n            out = super(tibble, self).select(exprs)\n        return out.pipe(from_polars)\n\n    def tail(self, n = 5, *, by = None):\n        \"\"\"Alias for `.slice_tail()`\"\"\"\n        return self.slice_tail(n, by = by)\n\n    def to_dict(self, *, as_series = True):\n        \"\"\"\n        Aggregate data with summary statistics\n\n        Parameters\n        ----------\n        as_series : bool\n            If True - returns the dict values as Series\n            If False - returns the dict values as lists\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.to_dict()\n        &gt;&gt;&gt; df.to_dict(as_series = False)\n        \"\"\"\n        return super().to_dict(as_series = as_series)\n\n    def to_pandas(self):\n        \"\"\"\n        Convert to a pandas DataFrame\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.to_pandas()\n        \"\"\"\n        # keep order of factors (pl.Enum)\n        enum_columns = [col for col in self.names if self.pull(col).dtype == pl.Enum]\n        res = self.to_polars().to_pandas()\n        if enum_columns :\n            for col in enum_columns:\n                # Get unique categories in order of appearance\n                categories_in_order = self.pull(col).cat.get_categories().to_list()\n                # Convert the column to Categorical\n                res[col] = pd.Categorical(\n                    res[col],\n                    categories=categories_in_order,\n                    ordered=True\n                )\n        return res\n\n    def to_polars(self):\n        \"\"\"\n        Convert to a polars DataFrame\n\n        Examples\n        --------\n        &gt;&gt;&gt; df.to_polars()\n        \"\"\"\n        self = copy.copy(self)\n        self.__class__ = pl.DataFrame\n        return self\n\n    def unite(self, col = \"_united\", unite_cols = [], sep = \"_\", remove = True):\n        \"\"\"\n        Unite multiple columns by pasting strings together\n\n        Parameters\n        ----------\n        col : str\n            Name of the new column\n        unite_cols : list\n            List of columns to unite\n        sep : str\n            Separator to use between values\n        remove : bool\n            If True removes input columns from the data frame\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = tp.tibble(a = [\"a\", \"a\", \"a\"], b = [\"b\", \"b\", \"b\"], c = range(3))\n        &gt;&gt;&gt; df.unite(\"united_col\", unite_cols = [\"a\", \"b\"])\n        \"\"\"\n        if len(unite_cols) == 0:\n            unite_cols = self.names\n        else: \n            unite_cols = _col_exprs(unite_cols)\n            unite_cols = self.select(unite_cols).names\n        out = self.mutate(str_c(*unite_cols, sep = sep).alias(col))\n        out = out.relocate(col, before = unite_cols[0])\n        if remove == True:\n            out = out.drop(unite_cols)\n        return out\n\n    def write_csv(self,\n                  file = None,\n                  has_headers = True,\n                  sep = ','):\n        \"\"\"Write a data frame to a csv\"\"\"\n        return super().write_csv(file, include_header = has_headers, separator = sep)\n\n    def write_parquet(self,\n                      file = str,\n                      compression = 'snappy',\n                      use_pyarrow = False,\n                      **kwargs):\n        \"\"\"Write a data frame to a parquet\"\"\"\n        return super().write_parquet(file, compression = compression, use_pyarrow = use_pyarrow, **kwargs)\n\n    def group_by(self, group, *args, **kwargs):\n        \"\"\"\n        Takes an existing tibble and converts it into a grouped tibble\n        where operations are performed \"by group\". ungroup() happens\n        automatically after the operation is performed.\n\n        Parameters\n        ---------- \n        group : str, list\n            Variable names to group by.\n\n        Returns\n        -------\n        Grouped tibble\n            A tibble with values grouped by one or more columns.\n        \"\"\"\n        res = TibbleGroupBy(self, group, maintain_order=True)\n        return res\n\n    def nest(self, by, *args, **kwargs):\n        \"\"\"\n        creates a nested tibble\n\n        Parameters\n        ----------\n        by : list, str\n            Columns to nest on\n\n        kwargs :\n            data : list of column names\n               columns to select to include in the nested data\n               If not provided, include all columns except the ones\n               used in 'by'\n\n             key : str\n               name of the resulting nested column. \n\n             names_sep : str\n                If not provided (default), the names in the nested\n                data will come from the former names. If a string,\n                the new inner names in the nested dataframe will use\n                the outer names with names_sep automatically stripped.\n                This makes names_sep roughly\n                symmetric between nesting and unnesting.\n\n        Returns\n        -------\n        tibble\n            The resulting tibble with have a column that contains\n            nested tibbles\n\n        \"\"\"\n        key  = kwargs.get(\"key\", 'data')\n        data = kwargs.get(\"data\", [c for c in self.names if c not in by])\n        names_sep = kwargs.get(\"names_sep\", None)\n\n        out = (self\n               .group_by(by)\n               .agg(**{\n                   key : pl.struct(data).map_elements(\n                       # lambda cols: from_polars( pl.DataFrame(cols.to_list()) ) )\n                       lambda cols: from_polars(pl.DataFrame({'data':cols}).unnest('data')) )\n                       # lambda cols: tibble(cols.to_list()) )\n               })\n               .pipe(from_polars)\n               )\n        # to keep enum order in the nested data\n        # enum_columns = [col for col in self.select(data).names\n        #                 if self.pull(col).dtype == pl.Enum]\n        # if enum_columns:\n        #     for col in enum_columns:\n        #         cats = self.pull(col).cat.get_categories().to_list()\n        #         print(cats)\n        #         out = out.mutate(**{key : map([key], lambda row:\n        #                                       row[0].mutate(col = as_factor(col, cats) )\n        #                                       }\n        # # to keep factors\n        # factors = [col for col in self.select(data).names\n        #                 if self.pull(col).dtype == pl.Categorical]\n        # if factors:\n        #     for col in factors:\n        #         out = out.mutate(**{col : as_factor(col)})\n\n\n        if names_sep is not None:\n            new_names = {col:f\"{col}_{names_sep}\" for col in data}\n            print(new_names)\n            out = out.mutate(**{key:col(key).map_elements(lambda row: row.rename(new_names))})\n        return out\n\n    def unnest(self, col):\n        \"\"\"\n        Unnest a nested tibble\n        Parameters\n        ----------\n        col : str\n            Columns to unnest\n\n        Returns\n        -------\n        tibble\n            The nested tibble will be expanded and become unested\n            rows of the original tibble.\n\n        \"\"\"\n        assert isinstance(col, str), \"'col', must be a string\"\n        # not run: error if nested df has different columns\n        # out = (self\n        #        .mutate(**{\n        #            col : pl.col(col).map_elements(lambda d: d.to_struct())\n        #        })\n        #        .to_polars()\n        #        .explode(col)\n        #        .unnest(col)\n        #        )\n        # return out.pipe(from_polars)\n        out = tibble()\n        for row in self.to_polars().iter_rows(named=True):\n            n = row[col].nrow\n            ids = {c:v for c, v in row.items() if c not in col}\n            cols = list(ids.keys())\n            df_ids = from_polars(pl.DataFrame(ids)\n                                 .with_columns(pl.col(cols) .repeat_by(n))\n                                 .explode(cols))\n            out = out.bind_rows(df_ids.bind_cols(row[col]))\n        out = self.__unnest_cast__(self, out)\n        return out\n\n    def __unnest_cast__(self, df_source, df_target):\n        # \"\"\"\n        # Align the types of columns in df_target to match categorical and enum columns from df_source,\n        # preserving the original column order.\n\n        # Parameters:\n        #     df_source: DataFrame containing categorical and enum columns.\n        #     df_target: DataFrame whose column types need to be aligned.\n\n        # Returns:\n        #     A new DataFrame with types aligned to match df_source for categorical and enum columns,\n        #     preserving column order.\n        # \"\"\"\n        df_source = df_source.to_polars()\n        df_target = df_target.to_polars()\n        cat_enum_cols = [\n            col for col, dtype in zip(df_source.columns, df_source.dtypes)\n            if dtype in [pl.Categorical, pl.Enum]\n        ]\n\n        for col in cat_enum_cols:\n            if col in df_target.columns:\n                if df_source.schema[col] == pl.Categorical:\n                    df_target = df_target.with_columns(pl.col(col).cast(pl.Categorical))\n                elif isinstance(df_source.schema[col], pl.Enum):\n                    enum_dtype = df_source.schema[col]\n                    df_target = df_target.with_columns(pl.col(col).cast(enum_dtype))\n\n        return from_polars(df_target.select(df_target.columns))\n\n    def crossing(self, *args, **kwargs):\n        \"\"\"\n        Expands the existing tibble for each value of the\n        variables used in the `crossing()` argument. See Returns.\n\n        Parameters\n        ----------\n        *args : list\n            One unamed list is accepted. \n\n        *kwargs : list\n            keyword will be the variable name, and the values in the list\n            will be in the expanded tibble\n\n        Returns\n        ------- \n        tibble\n            A tibble with varibles containing all combinations of the\n            values in the arguments passed to `crossing()`. The original\n            tibble will be replicated for each unique combination.\n\n        Examples\n        -------- \n        &gt;&gt;&gt; df = tp.tibble({'a': [1, 2], \"b\": [3, 5]})\n        &gt;&gt;&gt; df\n        shape: (2, 2)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   a     b \u2502\n        \u2502 i64   i64 \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502   1     3 \u2502\n        \u2502   2     5 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        &gt;&gt;&gt; df.crossing(c = ['a', 'b', 'c'])\n        shape: (6, 3)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   a     b   c   \u2502\n        \u2502 i64   i64   str \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502   1     3   a   \u2502\n        \u2502   1     3   b   \u2502\n        \u2502   1     3   c   \u2502\n        \u2502   2     5   a   \u2502\n        \u2502   2     5   b   \u2502\n        \u2502   2     5   c   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \"\"\"\n        out = self.mutate(*args, **kwargs).to_polars()\n        for var,_ in kwargs.items():\n            out = out.explode(var)\n        return out.pipe(from_polars)\n\n    def glimpse(self, regex='.'):\n        \"\"\"\n        Print compact information about the data\n\n        Parameters\n        ----------\n        regex : str, list, dict\n            Return information of the variables that match the regular \n            expression, the list, or the dictionary. If dictionary is \n            used, the variable names must be the dictionary keys.\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        assert isinstance(regex, str) or\\\n            isinstance(regex, list) or\\\n            isinstance(regex, dict), \"regex must be a list, dict, or regular expression\"\n\n        # if isinstance(regex, str):\n        #     df = self.select(regex=regex)\n        # elif isinstance(regex, dict):\n        #     df = self.select(names=list(regex.keys()))\n        # else:\n        #     df = self.select(names=regex)\n        print(f\"Columns matching pattern '{regex}':\")\n        df = self.select(matches(regex)).to_pandas()\n        size_col=80\n        header_var = 'Var'\n        header_type = 'Type'\n        header_uniq = 'Uniq'\n        header_missing = 'Miss'\n        header_missing_perc = '(%)'\n        header_head = 'Head'\n        # \n        length_col  = np.max([len(header_var)] +\n                             [len(col) for col  in df.columns])\n        length_type = np.max([len(header_type)] +\n                             [len(col) for col  in\n                              df.dtypes.astype(str).values]) + 2\n        length_nvalues = np.max([len(header_uniq),\n                                 len(str(np.max(df\n                                                .apply(pd.unique)\n                                                .apply(len))))])\n        length_missing = np.max([len(header_missing)] +\n                                df.isna().sum().astype(str).apply(len).tolist())\n        try:\n            length_missing_perc = np.max([len(header_missing_perc), \n                                            len((100*df.isna().sum()/df.shape[0])\n                                                .max().astype(int)\n                                                .astype(str))+2]\n                                           )\n        except:\n            length_missing_perc = 3\n\n        length_head = size_col - (length_col + length_type + length_nvalues + length_missing )\n        # \n        header = (f\"{header_var:&gt;{length_col}s} \"+\n                  f\"{header_type:{length_type}s}\"+\n                  f\"{header_uniq:&gt;{length_nvalues}s} \"+\n                  f\"{header_missing:&gt;{length_missing}s} \"+\n                  f\"{header_missing_perc:&gt;{length_missing_perc}s} \"+\n                  f\"{header_head:{length_head}s}\")\n        print(header)\n        hline = \"-\"*size_col\n        # print(hline)\n        for col in df.columns:\n            dtype = str(df[col].dtype)\n            nvalues = len(df[col].unique())\n            missings = df[col].isna().sum()\n            missings_perc = str(int(100*missings/self.nrow))+\"%\"\n            # \n            vals = str(df[col].values)\n            vals = vals[:length_head] + (vals[length_head+1:], '...')[len(vals) &gt; length_head]\n            # \n            print(f\"{col:&gt;{length_col}.{length_col}s} \"+\n                  f\"{'&lt;'+dtype+'&gt;':{length_type}.{length_type}s}\"+\n                  f\"{nvalues:&gt;{length_nvalues}d} \"+\n                  f\"{missings:&gt;{length_missing}d}\"+\n                  f\"{missings_perc:&gt;{length_missing_perc}s} \"\n                  f\"{vals:.{length_head+3}s}\")\n        # print(hline)\n        # print(header)\n        print('')\n        print(f\"[Rows: {self.nrow}; Columns {self.ncol}]\")\n        return None\n\n    # Not tidy functions, but useful from pandas/polars \n    # -------------------------------------------------\n    def replace(self, rep, regex=False):\n        \"\"\"\n        Replace method from polars pandas. Replaces values of a column.\n\n        Parameters\n        ----------\n        rep : dict\n            Format to use polars' replace:\n                {&lt;varname&gt;:{&lt;old value&gt;:&lt;new value&gt;, ...}}\n            Format to use pandas' replace:\n                {&lt;old value&gt;:&lt;new value&gt;, ...}\n\n        regex : bool\n            If true, replace using regular expression. It uses pandas\n            replace()\n\n        Returns\n        -------\n        tibble\n            Original tibble with values of columns replaced based on\n            rep`.\n        \"\"\"\n        if regex or not all(isinstance(value, dict) for value in rep.values()):\n            engine = 'pandas'\n        else:\n            engine = 'polars'\n\n        if engine=='polars':\n            out = self.to_polars()\n            for var, rep in rep.items():\n                try:\n                    out = out.with_columns(**{var : pl.col(var).replace(rep)})\n                except :\n                    out = out.with_columns(**{var : pl.col(var).replace_strict(rep)})\n            out = out.pipe(from_polars)\n        else:\n            out = self.to_pandas()\n            out = out.replace(to_replace=rep, regex=regex)\n            out = out.pipe(from_pandas)\n\n        return out\n\n    def print(self, n=1000, ncols=1000, str_length=1000, digits=2):\n        \"\"\"\n        Print the DataFrame\n\n        Parameters\n        ----------\n        n : int, default=1000\n            Number of rows to print\n\n        ncols : int, default=1000\n            Number of columns to print\n\n        str_length : int, default=1000\n            Maximum length of the strings.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        with pl.Config(set_tbl_rows=n,\n                       set_tbl_cols=ncols,\n                       float_precision=digits,\n                       fmt_str_lengths=str_length):\n            print(self)\n\n    # Statistics \n    # ----------\n    def descriptive_statistics(self, vars=None, groups=None,\n                               include_categorical=True,\n                               include_type=False):\n        \"\"\"\n        Compute descriptive statistics for numerical variables and optionally\n        frequency statistics for categorical variables, with support for grouping.\n\n        Parameters\n        ----------\n        vars : str, list, dict, or None, default None\n            The variables for which to compute statistics.\n            - If None, all variables in the dataset (as given by `self.names`) are used.\n            - If a string, it is interpreted as a single variable name.\n            - If a list, each element is treated as a variable name.\n            - If a dict, keys are variable names and values are their labels.\n        groups : str, list, dict, or None, default None\n            Variable(s) to group by when computing statistics.\n            - If None, overall statistics are computed.\n            - If a string, it is interpreted as a single grouping variable.\n            - If a list, each element is treated as a grouping variable.\n            - If a dict, keys are grouping variable names and values are their labels.\n        include_categorical : bool, default True\n            Whether to include frequency statistics for categorical variables in the output.\n        include_type : bool, default False\n            If True, adds a column indicating the variable type (\"Num\" for numerical, \"Cat\" for categorical).\n\n        Returns\n        -------\n        tibble\n            A tibble containing the descriptive statistics.\n            For numerical variables, the statistics include:\n                - N: count of non-missing values\n                - Missing (%): percentage of missing values\n                - Mean: average value\n                - Std.Dev.: standard deviation\n                - Min: minimum value\n                - Max: maximum value\n            If grouping is specified, these statistics are computed for each group.\n            When `include_categorical` is True, frequency statistics for categorical variables are appended\n            to the result.\n        \"\"\"\n        assert isinstance(vars, str) or isinstance(vars, list) or \\\n            isinstance(vars, dict) or vars is None, \\\n            \"'vars' must be a string, dict, or list\"\n        assert isinstance(groups, str) or isinstance(groups, list) or \\\n            isinstance(groups, dict) or groups is None, \\\n            \"'groups' must be a string, dict, or list\"\n\n        if vars is None:\n            vars = {v:v for v in self.names}\n        elif isinstance(vars, str):\n            vars = {vars:vars}\n        elif isinstance(vars, list):\n            vars = {v:v for v in vars}\n\n        if isinstance(groups, str):\n            groups = {groups:groups}\n        elif isinstance(groups, list):\n            groups = {g:g for g in groups}\n\n        # select only numerical\n        vars_num = {var:label for var, label in vars.items() if\n                    self.to_polars().schema[var].is_numeric()}\n        # select only numerical\n        vars_cat = {var:label for var, label in vars.items() if\n                    not self.to_polars().schema[var].is_numeric()}\n\n        # compute statistics for numerical variables\n        if groups is None:\n            res = self.__descriptive_statistics__(self, vars_num)\n        else:\n            res = (self\n                   .select(vars_num | groups)\n                   .nest(list(groups.values()))\n                   .mutate(summary = map(['data'], lambda col:\n                                         self.__descriptive_statistics__(col[0],\n                                                                         vars=vars_num)))\n                   .drop('data')\n                   .unnest('summary')\n                   )\n\n        n = self.nrow\n        res = (res\n               .mutate(null_count = 100*pl.col(\"null_count\")/n,\n                       count = as_integer('count'))\n               .rename({\"count\":'N',\n                        'null_count':'Missing (%)',\n                        \"mean\":\"Mean\",\n                        'std':'Std.Dev.',\n                        'min':\"Min\",\n                        'max':'Max'\n                        })\n               )\n        if include_type:\n            res = res.mutate(Type='Num')\n\n        # compute statistics for categorical variables\n        if vars_cat and include_categorical: \n            res_cat = tibble()\n            for var_cat, label in vars_cat.items():\n                res_cat = res_cat.bind_rows(\n                    self\n                    .freq({var_cat:label}, groups=groups)\n                    .drop('low', 'high')\n                    .rename({'Freq':\"Mean\",\n                             label:'Variable'})\n                    .mutate(Variable = label + \" (\"+pl.col(\"Variable\")+\")\")\n                    .replace_null({'Variable': label + \" (Missing)\"})\n                )\n            if include_type:\n                    res_cat = res_cat.mutate(Type='Cat')\n            res = res.bind_rows(res_cat)\n\n        res = res.arrange('Variable')\n        return res\n\n    def __descriptive_statistics__(self, data, vars=None):\n            res = (data\n                   .select(vars)\n                   .to_polars()\n                   .describe()\n                   .pipe(from_polars)\n                   .pivot_longer(cols=list(vars.values()), names_to='Variable', values_to='value')\n                   .pivot_wider(names_from='statistic', values_from='value')\n                   )\n            return res\n\n    def freq(self, vars=None, groups=None, na_rm=False, na_label=None):\n        \"\"\"\n        Compute frequency table.\n\n        Parameters\n        ----------\n        vars : str, list, or dict\n            Variables to return value frequencies for. \n            If a dict is provided, the key should be the variable name\n            and the values the variable label for the output\n\n        groups : str, list, dict, or None, optional\n            Variable names to condition marginal frequencies on. \n            If a dict is provided, the key should be the variable name\n            and the values the variable label for the output\n            Defaults to None (no grouping).\n\n        na_rm : bool, optional\n            Whether to include NAs in the calculation. Defaults to False.\n\n        na_label : str\n            Label to use for the NA values\n\n        Returns\n        -------\n        tibble\n            A tibble with relative frequencies and counts.\n        \"\"\"\n        assert vars, \"Parameter 'vars' not informed.\"\n        assert isinstance(groups, str) or \\\n            isinstance(groups, list) or\\\n            isinstance(groups, dict) or\\\n            groups is None, \"Incorrect 'groups' argument format. See documentation.\"\n\n        vars_all = []\n\n        if groups is None:\n            groups = {}\n        elif isinstance(groups, str):\n            groups = {groups:groups}\n        elif isinstance(groups, list):\n            groups = {g:g for g in groups}\n        vars_all += list(groups.keys())\n\n        if vars is None:\n            vars = {v:v for v in self.names}\n        elif isinstance(vars, str):\n            vars = {vars:vars}\n        elif isinstance(vars, list):\n            vars = {v:v for v in vars}\n        vars_all += list(vars.keys())\n\n        # labels = False\n        # if isinstance(vars, str):\n        #     vars = [vars]\n        # elif isinstance(vars, dict):\n        #     labels = True\n        #     vars_labels = vars\n        #     vars = list(vars.keys())\n        # elif type(vars) is {}.keys().__class__:\n        #     vars = list(vars)\n\n        # if groups and not isinstance(groups, list):\n        #     groups = [groups]\n        # if groups:\n        #     vars = groups + vars\n\n        res=self.select(vars_all)\n\n        if not na_rm:\n            if na_label is not None:\n                res=res.replace_null({var:na_label for var in vars})\n        else:\n            res=res.drop_null()\n\n        if not groups:\n            res=(res\n                   .group_by(vars_all)\n                 .summarize(n = n())\n                 .mutate(\n                       p     = pl.col(\"n\")/pl.col(\"n\").sum(),\n                       freq  = 100*pl.col(\"p\"),\n                       stdev = 100*np.sqrt((pl.col('p')*(1-pl.col('p')))/pl.col('n'))\n                 )\n            )\n            # for var in vars:\n            #     res = self.__tab_reorder_na__(res, var, na_label)\n        else:\n            res = (res\n                   .group_by(vars_all)\n                   .summarize(n = n())\n                   .group_by(list(groups.keys()))\n                   .mutate(\n                       p     = pl.col(\"n\")/pl.col(\"n\").sum(),\n                       freq  = 100*pl.col(\"p\"),\n                       stdev = 100*np.sqrt((pl.col('p')*(1-pl.col('p')))/pl.col('n'))\n                   )\n            )\n\n        # vars.reverse()\n        res = (\n            res\n            .drop('p')\n            .mutate(n = as_integer('n'),\n                    low  = pl.col('freq')-1.96*pl.col('stdev'),\n                    high = pl.col('freq')+1.96*pl.col('stdev'))\n            .rename({'n':'N',\n                     'stdev':'Std.Dev.',\n                     'freq':'Freq'}, tolower=False)\n            .arrange(list(vars.keys()))\n        )\n\n        res = res.rename(vars | groups)\n        return res\n\n    def tab(self, row, col, groups=None,\n            margins=True, normalize='all',#row/columns\n            margins_name='Total', stat='both',\n            na_rm=True, na_label='NA', digits=2):\n        \"\"\"\n        Create a 2x2 contingency table for two categorical variables, with optional grouping,\n        margins, and normalization.\n\n        Parameters\n        ----------\n        row : str\n            Name of the variable to be used for the rows of the table.\n        col : str\n            Name of the variable to be used for the columns of the table.\n        groups : str or list of str, optional\n            Variable name(s) to use as grouping variables. When provided, a separate 2x2 table\n            is generated for each group.\n        margins : bool, default True\n            If True, include row and column totals (margins) in the table.\n        normalize : {'all', 'row', 'columns'}, default 'all'\n            Specifies how to compute the marginal percentages in each cell:\n              - 'all': percentages computed over the entire table.\n              - 'row': percentages computed across each row.\n              - 'columns': percentages computed down each column.\n        margins_name : str, default 'Total'\n            Name to assign to the row and column totals.\n        stat : {'both', 'perc', 'n'}, default 'both'\n            Determines the statistic to display in each cell:\n              - 'both': returns both percentages and sample size.\n              - 'perc': returns percentages only.\n              - 'n': returns sample size only.\n        na_rm : bool, default True\n            If True, remove rows with missing values in the `row` or `col` variables.\n        na_label : str, default 'NA'\n            Label to use for missing values when `na_rm` is False.\n        digits : int, default 2\n            Number of digits to round the percentages to.\n\n        Returns\n        -------\n        tibble\n            A contingency table as a tibble. The table contains counts and/or percentages as specified\n            by the `stat` parameter, includes margins if requested, and is formatted with group headers\n            when grouping variables are provided.\n        \"\"\"\n        tab = self.select(row, col, groups).mutate(**{row:as_character(row),\n                                                      col:as_character(col)})\n        vars_row = row\n        vars_col = col\n        if na_rm:\n            tab = tab.drop_null()\n        else:\n            repl = {var:na_label for var in [row, col]}\n            tab = tab.replace_null(repl)\n        tab = tab.to_pandas()\n        if groups:\n            groups = [groups] if isinstance(groups, str) else groups\n            ngroups=len(groups)\n            resn = self.__tab_groups__(tab, vars_row, vars_col, normalize=False,\n                                       margins=margins, margins_name=margins_name,\n                                       groups=groups)\n            resp = self.__tab_groups__(tab, vars_row, vars_col, normalize,\n                                       margins, margins_name, groups)\n        else:\n            ngroups=0\n            resn = self.__tab__(tab, vars_row, vars_col, normalize=False,\n                                margins=margins, margins_name=margins_name)\n            resp = self.__tab__(tab, vars_row, vars_col, normalize=normalize,\n                                margins=margins, margins_name=margins_name)\n        colsn=resn.columns[ngroups+1:]\n        colsp=resp.columns[ngroups+1:]\n        res=resp.iloc[:,0:ngroups+1]\n\n        if stat=='both':\n            for coln, colp in zip(colsn, colsp):\n                col = [f\"{round(100*p, digits)} % ({n})\" for p,n\n                       in zip(resp[colp], resn[coln])]\n                res = res.assign(**{coln:col})\n        elif stat=='perc':\n            for colp in colsp:\n                res = res.assign(**{str(colp):100*resp[colp]})\n        else:\n            for coln in colsn:\n                res = res.assign(**{str(coln):100*resp[coln]})\n        # Group columns using varname as label\n        ncat = len(tab[vars_col].unique())\n        ngroups = 0 if not groups else len(groups)\n        col_groups = ['']*(ngroups+1) + [vars_col]*ncat+['']\n        col_ix = pd.MultiIndex.from_arrays([col_groups, res.columns])\n        res.columns = col_ix\n        res.columns.names = ['', '']\n        res.columns.name = ''\n        res.columns = [col[1] for col in res.columns]\n        res = self.__tab_reorder_na__(res, row, na_label)\n        return from_pandas(res)\n\n    def __tab__(self, tab, row, col, normalize='all', margins=True, margins_name='Total'):\n        if normalize=='row':\n            normalize='index'\n        if normalize=='column' or normalize=='col':\n            normalize='columns'\n        res = pd.crosstab(index=[tab[row]],\n                          columns=[tab[col]],\n                          margins=margins, margins_name=margins_name,\n                          normalize=normalize)\n        res = res.reset_index(drop=False)\n        return res\n\n    def __tab_groups__(self, tab, vars_row, vars_col, normalize,\n                       margins, margins_name, groups):\n        res = (tab\n               .groupby(groups)\n               .apply(self.__tab__,\n                      vars_row, vars_col, normalize, margins, margins_name)\n               .reset_index(drop=False)\n        )\n        cols = [col for cidx, col in enumerate(list(res.columns) ) if\n                not bool(re.search(pattern='^level_[0-9]$', string=col))]\n        res=res.filter(cols)\n        return res\n\n    def __tab_reorder_na__(self, tab, row, na_label):\n        tab = from_pandas(tab).to_polars()\n        # Check if \"Total\" column exists and place \"AB\" before it\n        if na_label in tab.columns:\n            if \"Total\" in tab.columns:\n                total_index = tab.columns.index(\"Total\")\n                columns = tab.columns[:total_index] + [na_label] + tab.columns[total_index:]\n                if na_label in tab.columns:\n                    columns.remove(na_label)  # Avoid duplication of \"AB\"\n                tab = tab.select(columns)\n\n        # Check if \"Total\" row exists and move \"ABC\" before it\n        if na_label in tab[row]:\n            na_row = tab.filter(tab[row] == na_label)\n            non_na_rows = tab.filter(tab[row] != na_label)\n            if \"Total\" in tab[row].to_list():\n                total_row_index = non_na_rows[row].to_list().index(\"Total\")\n                before_total_rows = non_na_rows[:total_row_index]\n                after_total_rows = non_na_rows[total_row_index:]\n                tab = pl.concat([before_total_rows, na_row, after_total_rows], how=\"vertical\")\n\n            else:\n                tab = pl.concat([non_na_rows, na_row], how=\"vertical\")\n        return tab.to_pandas()\n\n    # Reporting \n    # ---------\n    def to_latex(self,\n                 header = None,\n                 digits = 4,\n                 caption = None,\n                 label = None,\n                 align = None,\n                 na_rep  =  '',\n                 position = '!htb',\n                 group_rows_by = None,\n                 group_title_align = 'l',\n                 footnotes = None,\n                 index = False,\n                 escape = False,\n                 longtable = False,\n                 longtable_singlespace = True,\n                 rotate = False,\n                 scale = True,\n                 parse_linebreaks=True,\n                 tabular = False\n                 ):\n        \"\"\"\n        Convert the object to a LaTeX tabular representation.\n\n        Parameters\n        ----------\n        header : list of tuples, optional\n            The column headers for the LaTeX table. Each tuple corresponds to a column.\n            Ex: This will create upper level header with grouped columns\n                [(\"\", \"col 1\"),\n                 (\"Group A\", \"col 2\"),\n                 (\"Group A\", \"col 3\"),\n                 (\"Group B\", \"col 4\")\n                 (\"Group B\", \"col 5\"),\n                  ]\n                This will create two upper level header with grouped columns\n                [(\"Group 1\", \"\"       , \"col 1\"),\n                 (\"Group 1\", \"Group A\", \"col 2\"),\n                 (\"Group 1\", \"Group A\", \"col 3\"),\n                 (\"\"       , \"Group B\", \"col 4\")\n                 (\"\"       , \"Group B\", \"col 5\"),\n                  ]\n        digits : int, default=4\n            Number of decimal places to round the numerical values in the table.\n\n        caption : str, optional\n            The caption for the LaTeX table.\n\n        label : str, optional\n            The label for referencing the table in LaTeX.\n\n        align : str, optional\n            Column alignment specifications (e.g., 'lcr').\n\n        na_rep : str, default=''\n            The representation for NaN values in the table.\n\n        position : str, default='!htbp'\n            The placement option for the table in the LaTeX document.\n\n        footnotes : dict, optional\n            A dictionary where keys are column alignments ('c', 'r', or 'l')\n            and values are the respective footnote strings.\n\n        group_rows_by : str, default=None\n            Name of the variable in the data with values to group\n            the rows by.\n\n        group_title_align str, default='l'\n            Alignment of the title of each row group\n\n        index : bool, default=False\n            Whether to include the index in the LaTeX table.\n\n        escape : bool, default=False\n            Whether to escape LaTeX special characters.\n\n        longtable : bool, deafult=False\n            If True, table spans multiple pages\n\n        longtable_singlespace : bool\n            Force single space to longtables\n\n        rotate : bool\n            Whether to use landscape table\n\n        scale : bool, default=True\n            If True, scales the table to fit the linewidth when\n            the table exceeds that size\n            Note: ignored when longtable=True. This is a LaTeX\n                  limitation because longtable does not use\n                  tabular.\n\n        parse_linebreaks : book, default=True\n            If True, parse \\\\n and replace it with \\\\makecel\n            to produce linebreaks\n\n        tabular : bool, default=False\n            Whether to use a tabular format for the output.\n\n        Returns\n        -------\n            str\n                A LaTeX formatted string of the tibble.\n        \"\"\"\n\n        assert footnotes is None or isinstance(footnotes, dict),\\\n            \"'footnote' must be a dictionary\"\n\n        # this must be the first operation\n        if group_rows_by is not None:\n            self = self.arrange(group_rows_by)\n            tabm = self.to_pandas().drop([group_rows_by], axis=1)\n        else:\n            tabm = self.to_pandas()\n        ncols = tabm.shape[1]\n\n        if tabular and not longtable:\n            position=None\n\n        if align is None:\n            align = 'l'*ncols\n\n        if header is not None:\n            tabm.columns = pd.MultiIndex.from_tuples(header)\n\n        tabl = (tabm\n                # .round(digits)\n                # .astype(str)\n                .to_latex(index = index,\n                          escape = escape,\n                          caption = caption,\n                          label = label,\n                          sparsify = True,\n                          multirow = True,\n                          multicolumn = True,\n                          multicolumn_format = 'c',\n                          column_format = align,\n                          bold_rows = True,\n                          na_rep = na_rep,\n                          float_format=f\"%.{digits}f\",\n                          position = position\n                          ))\n\n        # split to add elements\n        rows = tabl.splitlines()\n\n        if group_rows_by is not None:\n            rows = self.__to_latex_group_rows__(group_rows_by, group_title_align, ncols, rows)\n\n        # add centering\n        row = [i for i, txt in enumerate(rows) if\n               bool(re.search(pattern='begin.*tabular', string=txt))][0]\n        rows.insert(row,f\"\\\\centering\")\n\n        footnotes_formated = \"\"\n        if footnotes is not None:\n            for align_note, footnote in footnotes.items():\n                footnote = [footnote] if isinstance(footnote, str) else footnote\n                for fni in footnote:\n                    notes = f\"\\\\multicolumn{{{ncols}}}{{{align_note}}}{{{fni}}}\\\\\\\\\"\n                    footnotes_formated += notes\n                    if not longtable:\n                        row = [idx for idx, s in enumerate(rows) if 'bottomrule' in s ][0]\n                        rows.insert(row + 1, notes)\n\n\n        # rejoin table\n        tabl = \"\\n\".join(rows)\n\n        # add midrules\n        if header is not None:\n            tabl = self.__to_latex_add_midrules_to_table__(tabl)\n\n        if longtable:\n            tabl = self.__to_latex_multipage__(tabl, caption, ncols, align,\n                                               label, position,\n                                               footnotes_formated,\n                                               longtable_singlespace)\n\n        if rotate:\n            tabl = re.sub(pattern=\"^\", repl='\\\\\\\\begin{landscape}', string=tabl)\n            tabl = re.sub(pattern=\"$\", repl='\\\\\\\\end{landscape}', string=tabl)\n\n        if scale and not longtable:\n            box = '\\\\resizebox{\\\\ifdim\\\\width&gt;\\\\linewidth\\\\linewidth\\\\else\\\\width\\\\fi}{!}{'\n            tabl = tabl.replace('\\\\begin{tabular}', f\"{box}\\n\\\\begin{{tabular}}\")\n            tabl = tabl.replace('\\\\end{tabular}', \"\\\\end{tabular}}\")\n\n        # linebreaks:\n        if parse_linebreaks:\n            tabl = self.__to_latex_breaklines__(tabl)    \n\n        return tabl\n\n    def __to_latex_process_header_line_for_cmid__(self, line: str) -&gt; str:\n        # Given a header line (without the trailing newline),\n        # parse for multicolumn commands and generate a line of cmidrule(s)\n        # based on the non-empty group labels.\n\n        # Example:\n        #   Input line: r\"\\\\multicolumn{3}{c}{Combine} &amp; \\\\multicolumn{3}{c}{} \\\\\"\n        #   Output: r\"\\\\cmidrule(lr){1-3} \\\\\"\n\n        # Remove trailing \"\\\\\" if present\n        line_clean = line.strip()\n        if line_clean.endswith(r'\\\\'):\n            line_clean = line_clean[:-2].strip()\n\n        # Split the row into cells (assuming &amp; is the column separator)\n        cells = [cell.strip() for cell in line_clean.split('&amp;')]\n        col_counter = 0\n        midrules = []\n\n        # Regex to capture multicolumn: number of columns and content.\n        # This assumes a simple structure without nested braces.\n        multicolumn_pattern = re.compile(r'\\\\multicolumn\\{(\\d+)\\}\\{[^}]*\\}\\{([^}]*)\\}')\n\n        for cell in cells:\n            m = multicolumn_pattern.search(cell)\n            if m:\n                span = int(m.group(1))\n                content = m.group(2).strip()\n                start = col_counter + 1\n                end = col_counter + span\n                # Only add a midrule if the cell\u2019s content is not empty\n                if content:\n                    midrules.append(r'\\cmidrule(lr){' + f\"{start}-{end}\" + '}')\n                col_counter += span\n            else:\n                # A normal cell occupies one column.\n                col_counter += 1\n\n        if midrules:\n            # Join the midrule commands (separated by a space) and add the trailing \\\\.\n            return \" \".join(midrules) #+ r' \\\\'\n        else:\n            return \"\"\n\n    def __to_latex_add_midrules_to_table__(self, latex_table: str) -&gt; str:\n        # Given a LaTeX table (as a string) that uses booktabs commands,\n        # insert automatically generated cmidrule lines for header rows that\n        # contain multicolumn cells.\n\n        # Assumes that the header is contained between the \\\\toprule and the first \\\\midrule.\n        lines = latex_table.splitlines()\n        new_lines = []\n        in_header = False\n        header_lines = []  # temporarily hold header lines\n\n        for line in lines:\n            # When we hit \\toprule, we start the header section.\n            if r'\\toprule' in line:\n                in_header = True\n                new_lines.append(line)\n            # When we hit the first \\midrule, process any stored header rows.\n            elif in_header and r'\\midrule' in line:\n                # Process each header line: output the line and, if applicable, a cmidrule line.\n                for hline in header_lines:\n                    new_lines.append(hline)\n                    cmid_line = self.__to_latex_process_header_line_for_cmid__(hline)\n                    if cmid_line:\n                        new_lines.append(cmid_line)\n                # Now add the \\midrule line and stop header processing.\n                new_lines.append(line)\n                in_header = False\n                header_lines = []\n            elif in_header:\n                # Collect header rows (these are the lines between \\toprule and \\midrule).\n                header_lines.append(line)\n            else:\n                # Outside the header section, just pass the line along.\n                new_lines.append(line)\n\n        return \"\\n\".join(new_lines)\n\n    def __to_latex_multipage__(self, tabl, caption, ncols, align,\n                               label, position, footnote,\n                               longtable_singlespace):\n        header_old = self.__to_latex_extract_header__(tabl)\n        header_new = f\"\"\"\n          {header_old}\n\n        \\\\endfirsthead\n          \\\\caption[]{{ {caption} }}\\\\\\\\\n\n         \\\\multicolumn{{{ncols}}}{{l}}{{\\\\textit{{(continued)}}}}\\\\\\\\\n        \\\\toprule\n          {header_old}\n        \\\\midrule\n        \\\\endhead\n\n        \\\\bottomrule\n        {footnote}\n        \\\\multicolumn{{{ncols}}}{{r@{{}}}}{{\\\\textit{{(continued \\\\ldots)}}}}\\\\\\\\\n        \\\\endfoot\n        {footnote}\n        \\\\endlastfoot\n        \"\"\"\n\n        longtable_begin = f'\\\\begin{{longtable}}{{{align}}}'\n        longtable_end   = f'\\\\end{{longtable}}'\n        if longtable_singlespace:\n            longtable_begin = '\\\\begin{spacing}{1}\\n' + longtable_begin \n            longtable_end   =  longtable_end + \"\\n\\\\end{spacing}\"\n\n        tabl = (tabl\n                .replace(f\"\\\\begin{{table}}[{position}]\", longtable_begin)\n                .replace(\"\\\\end{table}\", longtable_end)\n\n                .replace(f\"\\\\label{{{label}}}\", f\"\\\\label{{{label}}}\\\\\\\\\")\n\n                .replace(\"\\\\centering\", '')\n                .replace(f\"\\\\begin{{tabular}}{{{align}}}\", '')\n                .replace(\"\\\\end{tabular}\", '')\n\n                .replace(header_old, header_new)\n                )\n        return tabl\n\n    def __to_latex_extract_header__(self, latex_table: str) -&gt; str:\n        # Extract the header section from a LaTeX table.\n\n        # The header is defined as the text between the first occurrence of\n        # '\\\\toprule' and '\\\\midrule'. This function returns that section\n        # as a single string.\n\n        # Parameters:\n        #   latex_table (str): The complete LaTeX table as a string.\n\n        # Returns:\n        #   str: The header lines between '\\\\toprule' and '\\\\midrule', with\n        #        surrounding whitespace removed.\n\n        # Use re.DOTALL so that '.' matches newline characters.\n        pattern = re.compile(r'\\\\toprule\\s*(.*?)\\s*\\\\midrule', re.DOTALL)\n        match = pattern.search(latex_table)\n        if match:\n            return match.group(1).strip()\n        else:\n            return \"\"\n\n    def __to_latex_group_rows__(self, group_rows_by, group_title_align, ncols, rows):\n\n        position_first_row = self.__to_latex_group_rows_starting_positions__(rows)\n        position_last_row = self.__to_latex_group_rows_ending_positions__(rows, position_first_row)\n\n        # get groups locations\n        groups = (self\n                  .pull(group_rows_by)\n                  .to_list())\n        groups_row_locations = {groups[0]: 0}\n        for i in range(1, len(groups)):\n            if groups[i] != groups[i-1]:\n                groups_row_locations[groups[i]] = i\n\n        # insert horizontal space on grouped rows\n        for i in range(position_first_row, position_last_row):\n            rows[i] = '\\\\hspace{1em}' + rows[i] \n\n        # insert groups heading rows\n        for key, pos in sorted(groups_row_locations.items(),\n                               key=lambda item: item[1], reverse=True):\n            group_title = f\"\\\\addlinespace[0.3em]\\\\multicolumn{{{ncols}}}{{{group_title_align}}}{{ \\\\textbf{{{key}}} }}\\\\\\\\\"\n            rows.insert(position_first_row + pos, group_title )\n\n        return rows\n\n    def __to_latex_group_rows_starting_positions__(self, rows):\n        # Given a list of LaTeX table rows, returns the index of the first row\n        # containing '\\\\midrule' after the last occurrence of a row containing '\\\\toprule'.\n        # If either token is not found, the function returns None.\n\n        last_top_index = -1\n        res = None\n\n        # Iterate over rows to find the last index containing '\\toprule'\n        for i, row in enumerate(rows):\n            if r'\\toprule' in row:\n                last_top_index = i\n\n        if last_top_index == -1:\n            res = None\n\n        # Search for the first occurrence of '\\midrule' after the last '\\toprule'\n        for i in range(last_top_index + 1, len(rows)):\n            if r'\\midrule' in rows[i]:\n                res = i+1  # Return the index of the row containing '\\midrule'\n\n        return res\n\n    def __to_latex_group_rows_ending_positions__(self, rows, position_first_row):\n        last_table_row_index = -1\n        for i, row in enumerate(rows[position_first_row:]):\n            if r'\\bottomrule' in row:\n                last_table_row_index = position_first_row + i\n                break\n\n        return last_table_row_index \n\n    def __to_latex_breaklines__(self, table_str):\n        # Given a LaTeX table string containing a tabular environment,\n        # replace internal newline characters within table cells (i.e. those\n        # that occur within the cell content, not the row terminators) by \n        # LaTeX line breaks and wrap the cell text with \\makecell{...}.\n\n        # Table rules such as \\\\toprule, \\midrule, and \\\\bottomrule are left untouched.\n\n        # Parameters:\n        #     table_str (str): A string containing a LaTeX table.\n\n        # Returns:\n        #     str: The modified LaTeX table string.\n\n        def process_tabular(match):\n            # match.group(1): The \\begin{tabular}{...} line\n            # match.group(2): The content inside the tabular environment\n            # match.group(3): The \\end{tabular} line\n            begin_tabular = match.group(1)\n            content = match.group(2)\n            end_tabular = match.group(3)\n\n            # Split the content into parts while preserving the row separator.\n            # We assume each row ends with a double backslash (\\\\) followed by optional whitespace and a newline.\n            parts = re.split(r'(\\\\\\\\\\s*\\n|\\\\toprule\\n|\\\\midrule\\n|\\\\bottomrule\\n)', content)\n\n            # Reassemble rows as tuples: (row_text, row_separator)\n            rows = []\n            for i in range(0, len(parts), 2):\n                row_text = parts[i]\n                separator = parts[i+1] if i+1 &lt; len(parts) else ''\n                rows.append((row_text, separator))\n\n            processed_rows = []\n            for row_text, row_sep in rows:\n                # Skip processing for rows that are table rules.\n                if row_text.strip() in ('\\\\toprule', '\\\\midrule', '\\\\bottomrule'):\n                    processed_rows.append(row_text + row_sep)\n                    continue\n\n                # Split the row into cells using the ampersand (&amp;) as the delimiter.\n                cells = row_text.split('&amp;')\n                new_cells = []\n                for cell in cells:\n                    # Remove only trailing whitespace from the cell.\n                    cell_clean = cell.rstrip()\n                    # Check if the cell contains an internal newline.\n                    if '\\n' in cell_clean:\n                        # Remove any extra whitespace from the beginning and end.\n                        cell_core = cell_clean.strip()\n                        # Split the cell content by newline, strip each line, and join with LaTeX's line-break command.\n                        cell_lines = cell_core.split('\\n')\n                        cell_with_breaks = r'\\\\'.join(line.strip() for line in cell_lines)\n                        # Wrap the content with \\makecell{...}\n                        cell_processed = r'\\makecell{' + cell_with_breaks + '}'\n                    else:\n                        cell_processed = cell\n                    new_cells.append(cell_processed)\n                # Reassemble the row from its cells and append the preserved row separator.\n                new_row = \" &amp; \".join(new_cells)\n                processed_rows.append(new_row + row_sep)\n\n            # Reassemble the entire tabular content.\n            new_content = \"\".join(processed_rows)\n            return begin_tabular + new_content + end_tabular\n\n        # Process only the tabular environment in the table string.\n        new_table_str = re.sub(\n            r'(\\\\begin\\{tabular\\}\\{[^}]*\\})(.*?)(\\\\end\\{tabular\\})',\n            process_tabular,\n            table_str,\n            flags=re.DOTALL\n        )\n        return new_table_str\n\n    # Exporting table \n    # ---------------\n    def to_excel(self, *args, **kws):\n        \"\"\"\n        Save table to excel.\n\n        Details\n        -------\n        See polars `write_excel()` for details.\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        self.to_polars().write_excel(*args, **kws)\n\n    def to_csv(self, *args, **kws):\n        \"\"\"\n        Save table to csv.\n\n        Details\n        -------\n        See polars `write_csv()` for details.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self.to_polars().write_csv(*args, **kws)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.names","title":"<code>names</code>  <code>property</code>","text":"<p>Get column names</p> <p>Returns:</p> Type Description <code>list</code> <p>Names of the columns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.names\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.ncol","title":"<code>ncol</code>  <code>property</code>","text":"<p>Get number of columns</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of columns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.ncol\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.nrow","title":"<code>nrow</code>  <code>property</code>","text":"<p>Get number of rows</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of rows</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.nrow\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.arrange","title":"<code>arrange(*args)</code>","text":"<p>Arrange/sort rows</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>Columns to sort by</p> <code>()</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n&gt;&gt;&gt; # Arrange in ascending order\n&gt;&gt;&gt; df.arrange('x', 'y')\n&gt;&gt;&gt; # Arrange some columns descending\n&gt;&gt;&gt; df.arrange(tp.desc('x'), 'y')\n</code></pre> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble orderd by *args</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def arrange(self, *args):\n    \"\"\"\n    Arrange/sort rows\n\n    Parameters\n    ----------\n    *args : str\n        Columns to sort by\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n    &gt;&gt;&gt; # Arrange in ascending order\n    &gt;&gt;&gt; df.arrange('x', 'y')\n    &gt;&gt;&gt; # Arrange some columns descending\n    &gt;&gt;&gt; df.arrange(tp.desc('x'), 'y')\n\n    Returns\n    ------- \n    tibble\n        Original tibble orderd by *args\n    \"\"\"\n    exprs = _as_list(args)\n    desc = [True if isinstance(expr, DescCol) else False for expr in exprs]\n    return super()\\\n        .sort(exprs, descending = desc, nulls_last=True)\\\n        .pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.bind_cols","title":"<code>bind_cols(*args)</code>","text":"<p>Bind data frames by columns</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>tibble</code> <p>Data frame to bind</p> <code>()</code> <p>Returns:</p> Type Description <code>tibble</code> <p>The original tibble with added columns  from the other tibble specified in *args</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n&gt;&gt;&gt; df2 = tp.tibble({'a': ['c', 'c', 'c'], 'b': range(4, 7)})\n&gt;&gt;&gt; df1.bind_cols(df2)\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def bind_cols(self, *args):\n    \"\"\"\n    Bind data frames by columns\n\n    Parameters\n    ----------\n    *args : tibble\n        Data frame to bind\n\n    Returns\n    ------- \n    tibble\n        The original tibble with added columns \n        from the other tibble specified in *args\n\n    Examples\n    --------\n    &gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n    &gt;&gt;&gt; df2 = tp.tibble({'a': ['c', 'c', 'c'], 'b': range(4, 7)})\n    &gt;&gt;&gt; df1.bind_cols(df2)\n    \"\"\"\n    frames = _as_list(args)\n    out = self.to_polars()\n    for frame in frames:\n        out = out.hstack(frame)\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.bind_rows","title":"<code>bind_rows(*args)</code>","text":"<p>Bind data frames by row</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>(tibble, list)</code> <p>Data frames to bind by row</p> <code>()</code> <p>Returns:</p> Type Description <code>tibble</code> <p>The original tibble with added rows  from the other tibble specified in *args</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n&gt;&gt;&gt; df2 = tp.tibble({'x': ['c', 'c', 'c'], 'y': range(4, 7)})\n&gt;&gt;&gt; df1.bind_rows(df2)\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def bind_rows(self, *args):\n    \"\"\"\n    Bind data frames by row\n\n    Parameters\n    ----------\n    *args : tibble, list\n        Data frames to bind by row\n\n    Returns\n    ------- \n    tibble\n        The original tibble with added rows \n        from the other tibble specified in *args\n\n    Examples\n    --------\n    &gt;&gt;&gt; df1 = tp.tibble({'x': ['a', 'a', 'b'], 'y': range(3)})\n    &gt;&gt;&gt; df2 = tp.tibble({'x': ['c', 'c', 'c'], 'y': range(4, 7)})\n    &gt;&gt;&gt; df1.bind_rows(df2)\n    \"\"\"\n    frames = _as_list(args)\n    out = pl.concat([self, *frames], how = \"diagonal\")\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.clone","title":"<code>clone()</code>","text":"<p>Very cheap deep clone</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def clone(self):\n    \"\"\"\n    Very cheap deep clone\n    \"\"\"\n    return super().clone().pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.count","title":"<code>count(*args, sort=False, name='n')</code>","text":"<p>Returns row counts of the dataset.  If bare column names are provided, count() returns counts by group.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>(str, Expr)</code> <p>Columns to group by</p> <code>()</code> <code>sort</code> <code>bool</code> <p>Should columns be ordered in descending order by count</p> <code>False</code> <code>name</code> <code>str</code> <p>The name of the new column in the output. If omitted, it will default to \u201cn\u201d.</p> <code>'n'</code> <p>Returns:</p> Type Description <code>tibble</code> <p>If no agument is provided, just return the nomber of rows. If column names are provided, it will count the unique  values across columns</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': [1, 1, 2, 3],\n...:                 'b': ['a', 'a', 'b', 'b']})\n&gt;&gt;&gt; df.count()\nshape: (1, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   n \u2502\n\u2502 u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   4 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; df.count('a', 'b')\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   a   b       n \u2502\n\u2502 i64   str   u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   1   a       2 \u2502\n\u2502   2   b       1 \u2502\n\u2502   3   b       1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def count(self, *args, sort = False, name = 'n'):\n    \"\"\"\n    Returns row counts of the dataset. \n    If bare column names are provided, count() returns counts by group.\n\n    Parameters\n    ----------\n    *args : str, Expr\n        Columns to group by\n    sort : bool\n        Should columns be ordered in descending order by count\n    name : str\n        The name of the new column in the output. If omitted, it will default to \"n\".\n\n    Returns\n    ------- \n    tibble\n        If no agument is provided, just return the nomber of rows.\n        If column names are provided, it will count the unique \n        values across columns\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': [1, 1, 2, 3],\n    ...:                 'b': ['a', 'a', 'b', 'b']})\n    &gt;&gt;&gt; df.count()\n    shape: (1, 1)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   n \u2502\n    \u2502 u32 \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502   4 \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2518\n    &gt;&gt;&gt; df.count('a', 'b')\n    shape: (3, 3)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   a   b       n \u2502\n    \u2502 i64   str   u32 \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502   1   a       2 \u2502\n    \u2502   2   b       1 \u2502\n    \u2502   3   b       1 \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n    args = _as_list(args)\n\n    out = self.summarize(pl.len().alias(name), by = args)\n\n    if sort == True:\n        out = out.arrange(desc(name))\n\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.crossing","title":"<code>crossing(*args, **kwargs)</code>","text":"<p>Expands the existing tibble for each value of the variables used in the <code>crossing()</code> argument. See Returns.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>list</code> <p>One unamed list is accepted.</p> <code>()</code> <code>*kwargs</code> <code>list</code> <p>keyword will be the variable name, and the values in the list will be in the expanded tibble</p> <code>{}</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble with varibles containing all combinations of the values in the arguments passed to <code>crossing()</code>. The original tibble will be replicated for each unique combination.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': [1, 2], \"b\": [3, 5]})\n&gt;&gt;&gt; df\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   a     b \u2502\n\u2502 i64   i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   1     3 \u2502\n\u2502   2     5 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; df.crossing(c = ['a', 'b', 'c'])\nshape: (6, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   a     b   c   \u2502\n\u2502 i64   i64   str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   1     3   a   \u2502\n\u2502   1     3   b   \u2502\n\u2502   1     3   c   \u2502\n\u2502   2     5   a   \u2502\n\u2502   2     5   b   \u2502\n\u2502   2     5   c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def crossing(self, *args, **kwargs):\n    \"\"\"\n    Expands the existing tibble for each value of the\n    variables used in the `crossing()` argument. See Returns.\n\n    Parameters\n    ----------\n    *args : list\n        One unamed list is accepted. \n\n    *kwargs : list\n        keyword will be the variable name, and the values in the list\n        will be in the expanded tibble\n\n    Returns\n    ------- \n    tibble\n        A tibble with varibles containing all combinations of the\n        values in the arguments passed to `crossing()`. The original\n        tibble will be replicated for each unique combination.\n\n    Examples\n    -------- \n    &gt;&gt;&gt; df = tp.tibble({'a': [1, 2], \"b\": [3, 5]})\n    &gt;&gt;&gt; df\n    shape: (2, 2)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   a     b \u2502\n    \u2502 i64   i64 \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502   1     3 \u2502\n    \u2502   2     5 \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    &gt;&gt;&gt; df.crossing(c = ['a', 'b', 'c'])\n    shape: (6, 3)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   a     b   c   \u2502\n    \u2502 i64   i64   str \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502   1     3   a   \u2502\n    \u2502   1     3   b   \u2502\n    \u2502   1     3   c   \u2502\n    \u2502   2     5   a   \u2502\n    \u2502   2     5   b   \u2502\n    \u2502   2     5   c   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n    out = self.mutate(*args, **kwargs).to_polars()\n    for var,_ in kwargs.items():\n        out = out.explode(var)\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.descriptive_statistics","title":"<code>descriptive_statistics(vars=None, groups=None, include_categorical=True, include_type=False)</code>","text":"<p>Compute descriptive statistics for numerical variables and optionally frequency statistics for categorical variables, with support for grouping.</p> <p>Parameters:</p> Name Type Description Default <code>vars</code> <code>str, list, dict, or None</code> <p>The variables for which to compute statistics. - If None, all variables in the dataset (as given by <code>self.names</code>) are used. - If a string, it is interpreted as a single variable name. - If a list, each element is treated as a variable name. - If a dict, keys are variable names and values are their labels.</p> <code>None</code> <code>groups</code> <code>str, list, dict, or None</code> <p>Variable(s) to group by when computing statistics. - If None, overall statistics are computed. - If a string, it is interpreted as a single grouping variable. - If a list, each element is treated as a grouping variable. - If a dict, keys are grouping variable names and values are their labels.</p> <code>None</code> <code>include_categorical</code> <code>bool</code> <p>Whether to include frequency statistics for categorical variables in the output.</p> <code>True</code> <code>include_type</code> <code>bool</code> <p>If True, adds a column indicating the variable type (\u201cNum\u201d for numerical, \u201cCat\u201d for categorical).</p> <code>False</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble containing the descriptive statistics. For numerical variables, the statistics include:     - N: count of non-missing values     - Missing (%): percentage of missing values     - Mean: average value     - Std.Dev.: standard deviation     - Min: minimum value     - Max: maximum value If grouping is specified, these statistics are computed for each group. When <code>include_categorical</code> is True, frequency statistics for categorical variables are appended to the result.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def descriptive_statistics(self, vars=None, groups=None,\n                           include_categorical=True,\n                           include_type=False):\n    \"\"\"\n    Compute descriptive statistics for numerical variables and optionally\n    frequency statistics for categorical variables, with support for grouping.\n\n    Parameters\n    ----------\n    vars : str, list, dict, or None, default None\n        The variables for which to compute statistics.\n        - If None, all variables in the dataset (as given by `self.names`) are used.\n        - If a string, it is interpreted as a single variable name.\n        - If a list, each element is treated as a variable name.\n        - If a dict, keys are variable names and values are their labels.\n    groups : str, list, dict, or None, default None\n        Variable(s) to group by when computing statistics.\n        - If None, overall statistics are computed.\n        - If a string, it is interpreted as a single grouping variable.\n        - If a list, each element is treated as a grouping variable.\n        - If a dict, keys are grouping variable names and values are their labels.\n    include_categorical : bool, default True\n        Whether to include frequency statistics for categorical variables in the output.\n    include_type : bool, default False\n        If True, adds a column indicating the variable type (\"Num\" for numerical, \"Cat\" for categorical).\n\n    Returns\n    -------\n    tibble\n        A tibble containing the descriptive statistics.\n        For numerical variables, the statistics include:\n            - N: count of non-missing values\n            - Missing (%): percentage of missing values\n            - Mean: average value\n            - Std.Dev.: standard deviation\n            - Min: minimum value\n            - Max: maximum value\n        If grouping is specified, these statistics are computed for each group.\n        When `include_categorical` is True, frequency statistics for categorical variables are appended\n        to the result.\n    \"\"\"\n    assert isinstance(vars, str) or isinstance(vars, list) or \\\n        isinstance(vars, dict) or vars is None, \\\n        \"'vars' must be a string, dict, or list\"\n    assert isinstance(groups, str) or isinstance(groups, list) or \\\n        isinstance(groups, dict) or groups is None, \\\n        \"'groups' must be a string, dict, or list\"\n\n    if vars is None:\n        vars = {v:v for v in self.names}\n    elif isinstance(vars, str):\n        vars = {vars:vars}\n    elif isinstance(vars, list):\n        vars = {v:v for v in vars}\n\n    if isinstance(groups, str):\n        groups = {groups:groups}\n    elif isinstance(groups, list):\n        groups = {g:g for g in groups}\n\n    # select only numerical\n    vars_num = {var:label for var, label in vars.items() if\n                self.to_polars().schema[var].is_numeric()}\n    # select only numerical\n    vars_cat = {var:label for var, label in vars.items() if\n                not self.to_polars().schema[var].is_numeric()}\n\n    # compute statistics for numerical variables\n    if groups is None:\n        res = self.__descriptive_statistics__(self, vars_num)\n    else:\n        res = (self\n               .select(vars_num | groups)\n               .nest(list(groups.values()))\n               .mutate(summary = map(['data'], lambda col:\n                                     self.__descriptive_statistics__(col[0],\n                                                                     vars=vars_num)))\n               .drop('data')\n               .unnest('summary')\n               )\n\n    n = self.nrow\n    res = (res\n           .mutate(null_count = 100*pl.col(\"null_count\")/n,\n                   count = as_integer('count'))\n           .rename({\"count\":'N',\n                    'null_count':'Missing (%)',\n                    \"mean\":\"Mean\",\n                    'std':'Std.Dev.',\n                    'min':\"Min\",\n                    'max':'Max'\n                    })\n           )\n    if include_type:\n        res = res.mutate(Type='Num')\n\n    # compute statistics for categorical variables\n    if vars_cat and include_categorical: \n        res_cat = tibble()\n        for var_cat, label in vars_cat.items():\n            res_cat = res_cat.bind_rows(\n                self\n                .freq({var_cat:label}, groups=groups)\n                .drop('low', 'high')\n                .rename({'Freq':\"Mean\",\n                         label:'Variable'})\n                .mutate(Variable = label + \" (\"+pl.col(\"Variable\")+\")\")\n                .replace_null({'Variable': label + \" (Missing)\"})\n            )\n        if include_type:\n                res_cat = res_cat.mutate(Type='Cat')\n        res = res.bind_rows(res_cat)\n\n    res = res.arrange('Variable')\n    return res\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.distinct","title":"<code>distinct(*args, keep_all=True)</code>","text":"<p>Select distinct/unique rows</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>(str, Expr)</code> <p>Columns to find distinct/unique rows</p> <code>()</code> <code>keep_all</code> <code>boll</code> <p>If True, keep all columns. Otherwise, return only the ones used to select the distinct rows.</p> <code>True</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Tibble after removing the repeated rows based on *args</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.distinct()\n&gt;&gt;&gt; df.distinct('b')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def distinct(self, *args, keep_all = True):\n    \"\"\"\n    Select distinct/unique rows\n\n    Parameters\n    ----------\n    *args : str, Expr\n        Columns to find distinct/unique rows\n\n    keep_all : boll\n        If True, keep all columns. Otherwise, return\n        only the ones used to select the distinct rows.\n\n    Returns\n    ------- \n    tibble\n        Tibble after removing the repeated rows based on *args\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.distinct()\n    &gt;&gt;&gt; df.distinct('b')\n    \"\"\"\n    args = _as_list(args)\n    # \n    if len(args) == 0:\n        df = super().unique()\n    else:\n        df = super().unique(args)\n    if not keep_all and len(args) &gt; 0:\n        df = df.select(args)\n    return df.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.drop","title":"<code>drop(*args)</code>","text":"<p>Drop unwanted columns</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>Columns to drop</p> <code>()</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Tibble with columns in *args dropped</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.drop('x', 'y')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def drop(self, *args):\n    \"\"\"\n    Drop unwanted columns\n\n    Parameters\n    ----------\n    *args : str\n        Columns to drop\n\n    Returns\n    ------- \n    tibble\n        Tibble with columns in *args dropped\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.drop('x', 'y')\n    \"\"\"\n    args = _as_list(args)\n    drop_cols = self.select(args).names\n    return super().drop(drop_cols).pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.drop_null","title":"<code>drop_null(*args)</code>","text":"<p>Drop rows containing missing values</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>Columns to drop nulls from (defaults to all)</p> <code>()</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Tibble with rows in *args with missing values dropped</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble(x = [1, None, 3], y = [None, 'b', 'c'], z = range(3)}\n&gt;&gt;&gt; df.drop_null()\n&gt;&gt;&gt; df.drop_null('x', 'y')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def drop_null(self, *args):\n    \"\"\"\n    Drop rows containing missing values\n\n    Parameters\n    ----------\n    *args : str\n        Columns to drop nulls from (defaults to all)\n\n    Returns\n    ------- \n    tibble\n        Tibble with rows in *args with missing values dropped\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble(x = [1, None, 3], y = [None, 'b', 'c'], z = range(3)}\n    &gt;&gt;&gt; df.drop_null()\n    &gt;&gt;&gt; df.drop_null('x', 'y')\n    \"\"\"\n    args = _as_list(args)\n    if len(args) == 0:\n        out = super().drop_nulls()\n    else:\n        out = super().drop_nulls(args)\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.equals","title":"<code>equals(other, null_equal=True)</code>","text":"<p>Check if two tibbles are equal</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def equals(self, other, null_equal = True):\n    \"\"\"\n    Check if two tibbles are equal\n    \"\"\"\n    df = self.to_polars()\n    other = other.to_polars()\n    return df.equals(other, null_equal = null_equal)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.fill","title":"<code>fill(*args, direction='down', by=None)</code>","text":"<p>Fill in missing values with previous or next value</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>Columns to fill</p> <code>()</code> <code>direction</code> <code>str</code> <p>Direction to fill. One of [\u2018down\u2019, \u2018up\u2019, \u2018downup\u2019, \u2018updown\u2019]</p> <code>'down'</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Tibble with missing values filled</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': [1, None, 3, 4, 5],\n...                 'b': [None, 2, None, None, 5],\n...                 'groups': ['a', 'a', 'a', 'b', 'b']})\n&gt;&gt;&gt; df.fill('a', 'b')\n&gt;&gt;&gt; df.fill('a', 'b', by = 'groups')\n&gt;&gt;&gt; df.fill('a', 'b', direction = 'downup')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def fill(self, *args, direction = 'down', by = None):\n    \"\"\"\n    Fill in missing values with previous or next value\n\n    Parameters\n    ----------\n    *args : str\n        Columns to fill\n    direction : str\n        Direction to fill. One of ['down', 'up', 'downup', 'updown']\n    by : str, list\n        Columns to group by\n\n    Returns\n    ------- \n    tibble\n        Tibble with missing values filled\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': [1, None, 3, 4, 5],\n    ...                 'b': [None, 2, None, None, 5],\n    ...                 'groups': ['a', 'a', 'a', 'b', 'b']})\n    &gt;&gt;&gt; df.fill('a', 'b')\n    &gt;&gt;&gt; df.fill('a', 'b', by = 'groups')\n    &gt;&gt;&gt; df.fill('a', 'b', direction = 'downup')\n    \"\"\"\n    args = _as_list(args)\n    if len(args) == 0: return self\n    args = _col_exprs(args)\n    options = {'down': 'forward', 'up': 'backward'}\n    if direction in ['down', 'up']:\n        direction = options[direction]\n        exprs = [arg.fill_null(strategy = direction) for arg in args]\n    elif direction == 'downup':\n        exprs = [\n            arg.fill_null(strategy = 'forward')\n            .fill_null(strategy = 'backward')\n            for arg in args\n        ]\n    elif direction == 'updown':\n        exprs = [\n            arg.fill_null(strategy = 'backward')\n            .fill_null(strategy = 'forward')\n            for arg in args\n        ]\n    else:\n        raise ValueError(\"direction must be one of down, up, downup, or updown\")\n\n    return self.mutate(*exprs, by = by)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.filter","title":"<code>filter(*args, by=None)</code>","text":"<p>Filter rows on one or more conditions</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Expr</code> <p>Conditions to filter by</p> <code>()</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble with rows that match condition.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.filter(col('a') &lt; 2, col('b') == 'a')\n&gt;&gt;&gt; df.filter((col('a') &lt; 2) &amp; (col('b') == 'a'))\n&gt;&gt;&gt; df.filter(col('a') &lt;= tp.mean(col('a')), by = 'b')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def filter(self, *args,\n           by = None):\n    \"\"\"\n    Filter rows on one or more conditions\n\n    Parameters\n    ----------\n    *args : Expr\n        Conditions to filter by\n    by : str, list\n        Columns to group by\n\n    Returns\n    ------- \n    tibble\n        A tibble with rows that match condition.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.filter(col('a') &lt; 2, col('b') == 'a')\n    &gt;&gt;&gt; df.filter((col('a') &lt; 2) &amp; (col('b') == 'a'))\n    &gt;&gt;&gt; df.filter(col('a') &lt;= tp.mean(col('a')), by = 'b')\n    \"\"\"\n    args = _as_list(args)\n    exprs = ft.reduce(lambda a, b: a &amp; b, args)\n\n    if _uses_by(by):\n        out = super().group_by(by).map_groups(lambda x: x.filter(exprs))\n    else:\n        out = super().filter(exprs)\n\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.freq","title":"<code>freq(vars=None, groups=None, na_rm=False, na_label=None)</code>","text":"<p>Compute frequency table.</p> <p>Parameters:</p> Name Type Description Default <code>vars</code> <code>str, list, or dict</code> <p>Variables to return value frequencies for.  If a dict is provided, the key should be the variable name and the values the variable label for the output</p> <code>None</code> <code>groups</code> <code>str, list, dict, or None</code> <p>Variable names to condition marginal frequencies on.  If a dict is provided, the key should be the variable name and the values the variable label for the output Defaults to None (no grouping).</p> <code>None</code> <code>na_rm</code> <code>bool</code> <p>Whether to include NAs in the calculation. Defaults to False.</p> <code>False</code> <code>na_label</code> <code>str</code> <p>Label to use for the NA values</p> <code>None</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble with relative frequencies and counts.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def freq(self, vars=None, groups=None, na_rm=False, na_label=None):\n    \"\"\"\n    Compute frequency table.\n\n    Parameters\n    ----------\n    vars : str, list, or dict\n        Variables to return value frequencies for. \n        If a dict is provided, the key should be the variable name\n        and the values the variable label for the output\n\n    groups : str, list, dict, or None, optional\n        Variable names to condition marginal frequencies on. \n        If a dict is provided, the key should be the variable name\n        and the values the variable label for the output\n        Defaults to None (no grouping).\n\n    na_rm : bool, optional\n        Whether to include NAs in the calculation. Defaults to False.\n\n    na_label : str\n        Label to use for the NA values\n\n    Returns\n    -------\n    tibble\n        A tibble with relative frequencies and counts.\n    \"\"\"\n    assert vars, \"Parameter 'vars' not informed.\"\n    assert isinstance(groups, str) or \\\n        isinstance(groups, list) or\\\n        isinstance(groups, dict) or\\\n        groups is None, \"Incorrect 'groups' argument format. See documentation.\"\n\n    vars_all = []\n\n    if groups is None:\n        groups = {}\n    elif isinstance(groups, str):\n        groups = {groups:groups}\n    elif isinstance(groups, list):\n        groups = {g:g for g in groups}\n    vars_all += list(groups.keys())\n\n    if vars is None:\n        vars = {v:v for v in self.names}\n    elif isinstance(vars, str):\n        vars = {vars:vars}\n    elif isinstance(vars, list):\n        vars = {v:v for v in vars}\n    vars_all += list(vars.keys())\n\n    # labels = False\n    # if isinstance(vars, str):\n    #     vars = [vars]\n    # elif isinstance(vars, dict):\n    #     labels = True\n    #     vars_labels = vars\n    #     vars = list(vars.keys())\n    # elif type(vars) is {}.keys().__class__:\n    #     vars = list(vars)\n\n    # if groups and not isinstance(groups, list):\n    #     groups = [groups]\n    # if groups:\n    #     vars = groups + vars\n\n    res=self.select(vars_all)\n\n    if not na_rm:\n        if na_label is not None:\n            res=res.replace_null({var:na_label for var in vars})\n    else:\n        res=res.drop_null()\n\n    if not groups:\n        res=(res\n               .group_by(vars_all)\n             .summarize(n = n())\n             .mutate(\n                   p     = pl.col(\"n\")/pl.col(\"n\").sum(),\n                   freq  = 100*pl.col(\"p\"),\n                   stdev = 100*np.sqrt((pl.col('p')*(1-pl.col('p')))/pl.col('n'))\n             )\n        )\n        # for var in vars:\n        #     res = self.__tab_reorder_na__(res, var, na_label)\n    else:\n        res = (res\n               .group_by(vars_all)\n               .summarize(n = n())\n               .group_by(list(groups.keys()))\n               .mutate(\n                   p     = pl.col(\"n\")/pl.col(\"n\").sum(),\n                   freq  = 100*pl.col(\"p\"),\n                   stdev = 100*np.sqrt((pl.col('p')*(1-pl.col('p')))/pl.col('n'))\n               )\n        )\n\n    # vars.reverse()\n    res = (\n        res\n        .drop('p')\n        .mutate(n = as_integer('n'),\n                low  = pl.col('freq')-1.96*pl.col('stdev'),\n                high = pl.col('freq')+1.96*pl.col('stdev'))\n        .rename({'n':'N',\n                 'stdev':'Std.Dev.',\n                 'freq':'Freq'}, tolower=False)\n        .arrange(list(vars.keys()))\n    )\n\n    res = res.rename(vars | groups)\n    return res\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.full_join","title":"<code>full_join(df, left_on=None, right_on=None, on=None, suffix='_right')</code>","text":"<p>Perform an full join</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>tibble</code> <p>Lazy DataFrame to join with.</p> required <code>left_on</code> <code>(str, list)</code> <p>Join column(s) of the left DataFrame.</p> <code>None</code> <code>right_on</code> <code>(str, list)</code> <p>Join column(s) of the right DataFrame.</p> <code>None</code> <code>on</code> <p>Join column(s) of both DataFrames. If set, <code>left_on</code> and <code>right_on</code> should be None.</p> <code>None</code> <code>suffix</code> <code>str</code> <p>Suffix to append to columns with a duplicate name.</p> <code>'_right'</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Union between the original and the df tibbles. The rows that don\u2019t match in one of the tibbles will be completed with missing values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df1.full_join(df2)\n&gt;&gt;&gt; df1.full_join(df2, on = 'x')\n&gt;&gt;&gt; df1.full_join(df2, left_on = 'left_x', right_on = 'x')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def full_join(self, df, left_on = None, right_on = None, on = None, suffix: str = '_right'):\n    \"\"\"\n    Perform an full join\n\n    Parameters\n    ----------\n    df : tibble\n        Lazy DataFrame to join with.\n    left_on : str, list\n        Join column(s) of the left DataFrame.\n    right_on : str, list\n        Join column(s) of the right DataFrame.\n    on: str, list\n        Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n    suffix : str\n        Suffix to append to columns with a duplicate name.\n\n    Returns\n    ------- \n    tibble\n        Union between the original and the df tibbles. The\n        rows that don't match in one of the tibbles will be\n        completed with missing values.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df1.full_join(df2)\n    &gt;&gt;&gt; df1.full_join(df2, on = 'x')\n    &gt;&gt;&gt; df1.full_join(df2, left_on = 'left_x', right_on = 'x')\n    \"\"\"\n    if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n        on = list(set(self.names) &amp; set(df.names))\n    return super().join(df, on, 'outer',\n                        left_on = left_on,\n                        right_on= right_on, suffix= suffix).pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.glimpse","title":"<code>glimpse(regex='.')</code>","text":"<p>Print compact information about the data</p> <p>Parameters:</p> Name Type Description Default <code>regex</code> <code>(str, list, dict)</code> <p>Return information of the variables that match the regular  expression, the list, or the dictionary. If dictionary is  used, the variable names must be the dictionary keys.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def glimpse(self, regex='.'):\n    \"\"\"\n    Print compact information about the data\n\n    Parameters\n    ----------\n    regex : str, list, dict\n        Return information of the variables that match the regular \n        expression, the list, or the dictionary. If dictionary is \n        used, the variable names must be the dictionary keys.\n\n    Returns\n    -------\n    None\n\n    \"\"\"\n    assert isinstance(regex, str) or\\\n        isinstance(regex, list) or\\\n        isinstance(regex, dict), \"regex must be a list, dict, or regular expression\"\n\n    # if isinstance(regex, str):\n    #     df = self.select(regex=regex)\n    # elif isinstance(regex, dict):\n    #     df = self.select(names=list(regex.keys()))\n    # else:\n    #     df = self.select(names=regex)\n    print(f\"Columns matching pattern '{regex}':\")\n    df = self.select(matches(regex)).to_pandas()\n    size_col=80\n    header_var = 'Var'\n    header_type = 'Type'\n    header_uniq = 'Uniq'\n    header_missing = 'Miss'\n    header_missing_perc = '(%)'\n    header_head = 'Head'\n    # \n    length_col  = np.max([len(header_var)] +\n                         [len(col) for col  in df.columns])\n    length_type = np.max([len(header_type)] +\n                         [len(col) for col  in\n                          df.dtypes.astype(str).values]) + 2\n    length_nvalues = np.max([len(header_uniq),\n                             len(str(np.max(df\n                                            .apply(pd.unique)\n                                            .apply(len))))])\n    length_missing = np.max([len(header_missing)] +\n                            df.isna().sum().astype(str).apply(len).tolist())\n    try:\n        length_missing_perc = np.max([len(header_missing_perc), \n                                        len((100*df.isna().sum()/df.shape[0])\n                                            .max().astype(int)\n                                            .astype(str))+2]\n                                       )\n    except:\n        length_missing_perc = 3\n\n    length_head = size_col - (length_col + length_type + length_nvalues + length_missing )\n    # \n    header = (f\"{header_var:&gt;{length_col}s} \"+\n              f\"{header_type:{length_type}s}\"+\n              f\"{header_uniq:&gt;{length_nvalues}s} \"+\n              f\"{header_missing:&gt;{length_missing}s} \"+\n              f\"{header_missing_perc:&gt;{length_missing_perc}s} \"+\n              f\"{header_head:{length_head}s}\")\n    print(header)\n    hline = \"-\"*size_col\n    # print(hline)\n    for col in df.columns:\n        dtype = str(df[col].dtype)\n        nvalues = len(df[col].unique())\n        missings = df[col].isna().sum()\n        missings_perc = str(int(100*missings/self.nrow))+\"%\"\n        # \n        vals = str(df[col].values)\n        vals = vals[:length_head] + (vals[length_head+1:], '...')[len(vals) &gt; length_head]\n        # \n        print(f\"{col:&gt;{length_col}.{length_col}s} \"+\n              f\"{'&lt;'+dtype+'&gt;':{length_type}.{length_type}s}\"+\n              f\"{nvalues:&gt;{length_nvalues}d} \"+\n              f\"{missings:&gt;{length_missing}d}\"+\n              f\"{missings_perc:&gt;{length_missing_perc}s} \"\n              f\"{vals:.{length_head+3}s}\")\n    # print(hline)\n    # print(header)\n    print('')\n    print(f\"[Rows: {self.nrow}; Columns {self.ncol}]\")\n    return None\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.group_by","title":"<code>group_by(group, *args, **kwargs)</code>","text":"<p>Takes an existing tibble and converts it into a grouped tibble where operations are performed \u201cby group\u201d. ungroup() happens automatically after the operation is performed.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>(str, list)</code> <p>Variable names to group by.</p> required <p>Returns:</p> Type Description <code>Grouped tibble</code> <p>A tibble with values grouped by one or more columns.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def group_by(self, group, *args, **kwargs):\n    \"\"\"\n    Takes an existing tibble and converts it into a grouped tibble\n    where operations are performed \"by group\". ungroup() happens\n    automatically after the operation is performed.\n\n    Parameters\n    ---------- \n    group : str, list\n        Variable names to group by.\n\n    Returns\n    -------\n    Grouped tibble\n        A tibble with values grouped by one or more columns.\n    \"\"\"\n    res = TibbleGroupBy(self, group, maintain_order=True)\n    return res\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.head","title":"<code>head(n=5, *, by=None)</code>","text":"<p>Alias for <code>.slice_head()</code></p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def head(self, n = 5, *, by = None):\n    \"\"\"\n    Alias for `.slice_head()`\n    \"\"\"\n    return self.slice_head(n, by = by)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.inner_join","title":"<code>inner_join(df, left_on=None, right_on=None, on=None, suffix='_right')</code>","text":"<p>Perform an inner join</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>tibble</code> <p>Lazy DataFrame to join with.</p> required <code>left_on</code> <code>(str, list)</code> <p>Join column(s) of the left DataFrame.</p> <code>None</code> <code>right_on</code> <code>(str, list)</code> <p>Join column(s) of the right DataFrame.</p> <code>None</code> <code>on</code> <p>Join column(s) of both DataFrames. If set, <code>left_on</code> and <code>right_on</code> should be None.</p> <code>None</code> <code>suffix</code> <code>str</code> <p>Suffix to append to columns with a duplicate name.</p> <code>'_right'</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble with intersection of cases in the original and df tibbles.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df1.inner_join(df2)\n&gt;&gt;&gt; df1.inner_join(df2, on = 'x')\n&gt;&gt;&gt; df1.inner_join(df2, left_on = 'left_x', right_on = 'x')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def inner_join(self, df, left_on = None, right_on = None, on = None, suffix = '_right'):\n    \"\"\"\n    Perform an inner join\n\n    Parameters\n    ----------\n    df : tibble\n        Lazy DataFrame to join with.\n    left_on : str, list\n        Join column(s) of the left DataFrame.\n    right_on : str, list\n        Join column(s) of the right DataFrame.\n    on: str, list\n        Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n    suffix : str\n        Suffix to append to columns with a duplicate name.\n\n    Returns\n    ------- \n    tibble\n        A tibble with intersection of cases in the original and\n        df tibbles.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df1.inner_join(df2)\n    &gt;&gt;&gt; df1.inner_join(df2, on = 'x')\n    &gt;&gt;&gt; df1.inner_join(df2, left_on = 'left_x', right_on = 'x')\n    \"\"\"\n    if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n        on = list(set(self.names) &amp; set(df.names))\n    return super().join(df, on, 'inner',\n                        left_on = left_on,\n                        right_on= right_on,\n                        suffix= suffix).pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.left_join","title":"<code>left_join(df, left_on=None, right_on=None, on=None, suffix='_right')</code>","text":"<p>Perform a left join</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>tibble</code> <p>Lazy DataFrame to join with.</p> required <code>left_on</code> <code>(str, list)</code> <p>Join column(s) of the left DataFrame.</p> <code>None</code> <code>right_on</code> <code>(str, list)</code> <p>Join column(s) of the right DataFrame.</p> <code>None</code> <code>on</code> <p>Join column(s) of both DataFrames. If set, <code>left_on</code> and <code>right_on</code> should be None.</p> <code>None</code> <code>suffix</code> <code>str</code> <p>Suffix to append to columns with a duplicate name.</p> <code>'_right'</code> <p>Returns:</p> Type Description <code>tibble</code> <p>The original tibble with added columns from tibble df if they match columns in the original one. Columns to match on are given in the function parameters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df1.left_join(df2)\n&gt;&gt;&gt; df1.left_join(df2, on = 'x')\n&gt;&gt;&gt; df1.left_join(df2, left_on = 'left_x', right_on = 'x')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def left_join(self, df, left_on = None, right_on = None, on = None, suffix = '_right'):\n    \"\"\"\n    Perform a left join\n\n    Parameters\n    ----------\n    df : tibble\n        Lazy DataFrame to join with.\n    left_on : str, list\n        Join column(s) of the left DataFrame.\n    right_on : str, list\n        Join column(s) of the right DataFrame.\n    on: str, list\n        Join column(s) of both DataFrames. If set, `left_on` and `right_on` should be None.\n    suffix : str\n        Suffix to append to columns with a duplicate name.\n\n    Returns\n    ------- \n    tibble\n         The original tibble with added columns from tibble df if\n         they match columns in the original one. Columns to match\n         on are given in the function parameters.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df1.left_join(df2)\n    &gt;&gt;&gt; df1.left_join(df2, on = 'x')\n    &gt;&gt;&gt; df1.left_join(df2, left_on = 'left_x', right_on = 'x')\n    \"\"\"\n    if (left_on == None) &amp; (right_on == None) &amp; (on == None):\n        on = list(set(self.names) &amp; set(df.names))\n    return super().join(df, on, 'left',  left_on = left_on, right_on= right_on, suffix= suffix).pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.mutate","title":"<code>mutate(*args, by=None, **kwargs)</code>","text":"<p>Add or modify columns</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Expr</code> <p>Column expressions to add or modify</p> <code>()</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <code>**kwargs</code> <code>Expr</code> <p>Column expressions to add or modify</p> <code>{}</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with new column created.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), c = ['a', 'a', 'b']})\n&gt;&gt;&gt; df.mutate(double_a = col('a') * 2,\n...           a_plus_b = col('a') + col('b'))\n&gt;&gt;&gt; df.mutate(row_num = row_number(), by = 'c')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def mutate(self, *args, by = None, **kwargs):\n    \"\"\"\n    Add or modify columns\n\n    Parameters\n    ----------\n    *args : Expr\n        Column expressions to add or modify\n    by : str, list\n        Columns to group by\n    **kwargs : Expr\n        Column expressions to add or modify\n\n    Returns\n    ------- \n    tibble\n        Original tibble with new column created.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), c = ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.mutate(double_a = col('a') * 2,\n    ...           a_plus_b = col('a') + col('b'))\n    &gt;&gt;&gt; df.mutate(row_num = row_number(), by = 'c')\n    \"\"\"\n    exprs = _as_list(args) + _kwargs_as_exprs(kwargs)\n\n    out = self.to_polars()\n\n    if _uses_by(by):\n        out = out.group_by(by).map_groups(lambda x: _mutate_cols(x, exprs))\n    else:\n        out = _mutate_cols(out, exprs)\n\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.nest","title":"<code>nest(by, *args, **kwargs)</code>","text":"<p>creates a nested tibble</p> <p>Parameters:</p> Name Type Description Default <code>by</code> <code>(list, str)</code> <p>Columns to nest on</p> required <code>kwargs</code> <p>data : list of column names    columns to select to include in the nested data    If not provided, include all columns except the ones    used in \u2018by\u2019</p> <p>key : str    name of the resulting nested column. </p> <p>names_sep : str     If not provided (default), the names in the nested     data will come from the former names. If a string,     the new inner names in the nested dataframe will use     the outer names with names_sep automatically stripped.     This makes names_sep roughly     symmetric between nesting and unnesting.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tibble</code> <p>The resulting tibble with have a column that contains nested tibbles</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def nest(self, by, *args, **kwargs):\n    \"\"\"\n    creates a nested tibble\n\n    Parameters\n    ----------\n    by : list, str\n        Columns to nest on\n\n    kwargs :\n        data : list of column names\n           columns to select to include in the nested data\n           If not provided, include all columns except the ones\n           used in 'by'\n\n         key : str\n           name of the resulting nested column. \n\n         names_sep : str\n            If not provided (default), the names in the nested\n            data will come from the former names. If a string,\n            the new inner names in the nested dataframe will use\n            the outer names with names_sep automatically stripped.\n            This makes names_sep roughly\n            symmetric between nesting and unnesting.\n\n    Returns\n    -------\n    tibble\n        The resulting tibble with have a column that contains\n        nested tibbles\n\n    \"\"\"\n    key  = kwargs.get(\"key\", 'data')\n    data = kwargs.get(\"data\", [c for c in self.names if c not in by])\n    names_sep = kwargs.get(\"names_sep\", None)\n\n    out = (self\n           .group_by(by)\n           .agg(**{\n               key : pl.struct(data).map_elements(\n                   # lambda cols: from_polars( pl.DataFrame(cols.to_list()) ) )\n                   lambda cols: from_polars(pl.DataFrame({'data':cols}).unnest('data')) )\n                   # lambda cols: tibble(cols.to_list()) )\n           })\n           .pipe(from_polars)\n           )\n    # to keep enum order in the nested data\n    # enum_columns = [col for col in self.select(data).names\n    #                 if self.pull(col).dtype == pl.Enum]\n    # if enum_columns:\n    #     for col in enum_columns:\n    #         cats = self.pull(col).cat.get_categories().to_list()\n    #         print(cats)\n    #         out = out.mutate(**{key : map([key], lambda row:\n    #                                       row[0].mutate(col = as_factor(col, cats) )\n    #                                       }\n    # # to keep factors\n    # factors = [col for col in self.select(data).names\n    #                 if self.pull(col).dtype == pl.Categorical]\n    # if factors:\n    #     for col in factors:\n    #         out = out.mutate(**{col : as_factor(col)})\n\n\n    if names_sep is not None:\n        new_names = {col:f\"{col}_{names_sep}\" for col in data}\n        print(new_names)\n        out = out.mutate(**{key:col(key).map_elements(lambda row: row.rename(new_names))})\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.pivot_longer","title":"<code>pivot_longer(cols=None, names_to='name', values_to='value')</code>","text":"<p>Pivot data from wide to long</p> <p>Parameters:</p> Name Type Description Default <code>cols</code> <code>Expr</code> <p>List of the columns to pivot. Defaults to all columns.</p> <code>None</code> <code>names_to</code> <code>str</code> <p>Name of the new \u201cnames\u201d column.</p> <code>'name'</code> <code>values_to</code> <p>Name of the new \u201cvalues\u201d column</p> <code>'value'</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble, but in long format.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'id': ['id1', 'id2'], 'a': [1, 2], 'b': [1, 2]})\n&gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'])\n&gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'], names_to = 'stuff', values_to = 'things')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def pivot_longer(self,\n                 cols = None,\n                 names_to = \"name\",\n                 values_to = \"value\"):\n    \"\"\"\n    Pivot data from wide to long\n\n    Parameters\n    ----------\n    cols : Expr\n        List of the columns to pivot. Defaults to all columns.\n    names_to : str\n        Name of the new \"names\" column.\n    values_to: str\n        Name of the new \"values\" column\n\n    Returns\n    ------- \n    tibble\n        Original tibble, but in long format.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'id': ['id1', 'id2'], 'a': [1, 2], 'b': [1, 2]})\n    &gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'])\n    &gt;&gt;&gt; df.pivot_longer(cols = ['a', 'b'], names_to = 'stuff', values_to = 'things')\n    \"\"\"\n    if cols is None:\n        cols = everything()\n    if isinstance(cols, dict):\n        cols = list(cols.keys())\n\n    df_cols = pl.Series(self.names)\n    value_vars = self.select(cols).names\n    id_vars = df_cols.filter(df_cols.is_in(value_vars).not_()).to_list()\n    out = super().melt(id_vars, value_vars, names_to, values_to)\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.pivot_wider","title":"<code>pivot_wider(names_from='name', values_from='value', id_cols=None, values_fn='first', values_fill=None)</code>","text":"<p>Pivot data from long to wide</p> <p>Parameters:</p> Name Type Description Default <code>names_from</code> <code>str</code> <p>Column to get the new column names from.</p> <code>'name'</code> <code>values_from</code> <code>str</code> <p>Column to get the new column values from</p> <code>'value'</code> <code>id_cols</code> <code>(str, list)</code> <p>A set of columns that uniquely identifies each observation. Defaults to all columns in the data table except for the columns specified in <code>names_from</code> and <code>values_from</code>.</p> <code>None</code> <code>values_fn</code> <code>str</code> <p>Function for how multiple entries per group should be dealt with. Any of \u2018first\u2019, \u2018count\u2019, \u2018sum\u2019, \u2018max\u2019, \u2018min\u2019, \u2018mean\u2019, \u2018median\u2019, \u2018last\u2019</p> <code>'first'</code> <code>values_fill</code> <code>str</code> <p>If values are missing/null, what value should be filled in. Can use: \u201cbackward\u201d, \u201cforward\u201d, \u201cmean\u201d, \u201cmin\u201d, \u201cmax\u201d, \u201czero\u201d, \u201cone\u201d</p> <code>None</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble, but in wide format.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'id': [1, 1], 'variable': ['a', 'b'], 'value': [1, 2]})\n&gt;&gt;&gt; df.pivot_wider(names_from = 'variable', values_from = 'value')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def pivot_wider(self,\n                names_from = 'name',\n                values_from = 'value',\n                id_cols = None,\n                values_fn = 'first', \n                values_fill = None\n                ):\n    \"\"\"\n    Pivot data from long to wide\n\n    Parameters\n    ----------\n    names_from : str\n        Column to get the new column names from.\n    values_from : str\n        Column to get the new column values from\n    id_cols : str, list\n        A set of columns that uniquely identifies each observation.\n        Defaults to all columns in the data table except for the columns specified in\n        `names_from` and `values_from`.\n    values_fn : str\n        Function for how multiple entries per group should be dealt with.\n        Any of 'first', 'count', 'sum', 'max', 'min', 'mean', 'median', 'last'\n    values_fill : str\n        If values are missing/null, what value should be filled in.\n        Can use: \"backward\", \"forward\", \"mean\", \"min\", \"max\", \"zero\", \"one\"\n\n    Returns\n    ------- \n    tibble\n        Original tibble, but in wide format.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'id': [1, 1], 'variable': ['a', 'b'], 'value': [1, 2]})\n    &gt;&gt;&gt; df.pivot_wider(names_from = 'variable', values_from = 'value')\n    \"\"\"\n    if id_cols == None:\n        df_cols = pl.Series(self.names)\n        from_cols = pl.Series(self.select(names_from, values_from).names)\n        id_cols = df_cols.filter(df_cols.is_in(from_cols).not_()).to_list()\n\n    no_id = len(id_cols) == 0\n\n    if no_id:\n        id_cols = '___id__'\n        self = self.mutate(___id__ = pl.lit(1))\n\n    out = (\n        super()\n        .pivot(index=id_cols, on=names_from, values=values_from, aggregate_function=values_fn)\n        .pipe(from_polars)\n    )\n\n    if values_fill != None:\n        new_cols = pl.Series(out.names)\n        new_cols = new_cols.filter(~new_cols.is_in(id_cols))\n        fill_exprs = [col(new_col).fill_null(values_fill) for new_col in new_cols]\n        out = out.mutate(*fill_exprs)\n\n    if no_id: out = out.drop('___id__')\n\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.print","title":"<code>print(n=1000, ncols=1000, str_length=1000, digits=2)</code>","text":"<p>Print the DataFrame</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to print</p> <code>1000</code> <code>ncols</code> <code>int</code> <p>Number of columns to print</p> <code>1000</code> <code>str_length</code> <code>int</code> <p>Maximum length of the strings.</p> <code>1000</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def print(self, n=1000, ncols=1000, str_length=1000, digits=2):\n    \"\"\"\n    Print the DataFrame\n\n    Parameters\n    ----------\n    n : int, default=1000\n        Number of rows to print\n\n    ncols : int, default=1000\n        Number of columns to print\n\n    str_length : int, default=1000\n        Maximum length of the strings.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    with pl.Config(set_tbl_rows=n,\n                   set_tbl_cols=ncols,\n                   float_precision=digits,\n                   fmt_str_lengths=str_length):\n        print(self)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.pull","title":"<code>pull(var=None)</code>","text":"<p>Extract a column as a series</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>str</code> <p>Name of the column to extract. Defaults to the last column.</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>The series will contain the values of the column from <code>var</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3))\n&gt;&gt;&gt; df.pull('a')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def pull(self, var = None):\n    \"\"\"\n    Extract a column as a series\n\n    Parameters\n    ----------\n    var : str\n        Name of the column to extract. Defaults to the last column.\n\n    Returns\n    ------- \n    Series\n        The series will contain the values of the column from `var`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3))\n    &gt;&gt;&gt; df.pull('a')\n    \"\"\"\n    if var == None:\n        var = self.names[-1]\n\n    return super().get_column(var)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.relevel","title":"<code>relevel(x, ref)</code>","text":"<p>Change the reference level a string or factor and covert to factor</p> Inputs <p>x : str     Variable name</p> <p>ref : str    Reference level</p> <p>Returns:</p> Type Description <code>tibble</code> <p>The original tibble with the column specified in <code>x</code> as an ordered factors, with first category specified in <code>ref</code>.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def relevel(self, x, ref):\n    \"\"\"\n    Change the reference level a string or factor and covert to factor\n\n    Inputs\n    ------\n    x : str\n        Variable name\n\n    ref : str\n       Reference level\n\n    Returns\n    ------- \n    tibble\n        The original tibble with the column specified in `x` as\n        an ordered factors, with first category specified in `ref`.\n    \"\"\"\n    levels = self.pull(x).unique().to_list()\n    relevels = [ref] + [l for l in levels if l != ref]\n    self = self.mutate(**{x : as_factor(x, relevels)})\n    return self\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.relocate","title":"<code>relocate(*args, before=None, after=None)</code>","text":"<p>Move a column or columns to a new position</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>(str, Expr)</code> <p>Columns to move</p> <code>()</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with columns relocated.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.relocate('a', before = 'c')\n&gt;&gt;&gt; df.relocate('b', after = 'c')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def relocate(self, *args, before = None, after = None):\n    \"\"\"\n    Move a column or columns to a new position\n\n    Parameters\n    ----------\n    *args : str, Expr\n        Columns to move\n\n    Returns\n    ------- \n    tibble\n        Original tibble with columns relocated.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.relocate('a', before = 'c')\n    &gt;&gt;&gt; df.relocate('b', after = 'c')\n    \"\"\"\n    cols_all = pl.Series(self.names)\n    locs_all = pl.Series(range(len(cols_all)))\n    locs_dict = {k:v for k,v in zip(cols_all, locs_all)}\n    locs_df = pl.DataFrame(locs_dict, orient = \"row\")\n\n    cols_relocate = _as_list(args)\n    locs_relocate = pl.Series(locs_df.select(cols_relocate).row(0))\n\n    if (len(locs_relocate) == 0):\n        return self\n\n    uses_before = before != None\n    uses_after = after != None\n\n    if (uses_before &amp; uses_after):\n        raise ValueError(\"Cannot provide both before and after\")\n    elif (not_(uses_before) &amp; not_(uses_after)):\n        before = cols_all[0]\n        uses_before = True\n\n    if uses_before:\n        before = locs_df.select(before).get_column(before)\n        locs_start = locs_all.filter(locs_all &lt; before)\n    else:\n        after = locs_df.select(after).get_column(after)\n        locs_start = locs_all.filter(locs_all &lt;= after)\n\n    locs_start = locs_start.filter(~locs_start.is_in(locs_relocate))\n    final_order = pl.concat([locs_start, locs_relocate, locs_all]).unique(maintain_order = True)\n    final_order = cols_all[final_order].to_list()\n\n    return self.select(final_order)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.rename","title":"<code>rename(columns=None, regex=False, tolower=False, strict=False)</code>","text":"<p>Rename columns</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>dict</code> <p>Dictionary mapping of old and new names</p> <code>None</code> <code>regex</code> <code>bool</code> <p>If True, uses regular expression replacement</p> <code>False</code> <code>tolower</code> <code>bool</code> <p>If True, convert all to lower case</p> <code>False</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with columns renamed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'x': range(3), 't': range(3), 'z': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.rename({'x': 'new_x'})\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def rename(self, columns=None, regex=False, tolower=False, strict=False):\n    \"\"\"\n    Rename columns\n\n    Parameters\n    ----------\n    columns : dict, default None\n        Dictionary mapping of old and new names\n        {&lt;old name&gt;:&lt;new name&gt;, ...}\n\n    regex : bool, default False\n        If True, uses regular expression replacement\n        {&lt;matched from&gt;:&lt;matched to&gt;}\n\n    tolower : bool, default False\n        If True, convert all to lower case\n\n    Returns\n    ------- \n    tibble\n        Original tibble with columns renamed.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'x': range(3), 't': range(3), 'z': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.rename({'x': 'new_x'}) \n    \"\"\"\n    assert isinstance(columns, dict) or columns is None,\\\n        \"'columns' must be a dictionary or None.\"\n\n    if columns is not None:\n        if regex:\n            self = self.__rename_regexp__(columns)\n        else:\n            self = super().rename(columns, strict=False).pipe(from_polars)\n\n    if tolower:\n        self = self.__rename_tolower__()\n    return self\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.replace","title":"<code>replace(rep, regex=False)</code>","text":"<p>Replace method from polars pandas. Replaces values of a column.</p> <p>Parameters:</p> Name Type Description Default <code>rep</code> <code>dict</code> <p>Format to use polars\u2019 replace:     {:{:, \u2026}} Format to use pandas\u2019 replace: required <code>regex</code> <code>bool</code> <p>If true, replace using regular expression. It uses pandas replace()</p> <code>False</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with values of columns replaced based on rep`.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def replace(self, rep, regex=False):\n    \"\"\"\n    Replace method from polars pandas. Replaces values of a column.\n\n    Parameters\n    ----------\n    rep : dict\n        Format to use polars' replace:\n            {&lt;varname&gt;:{&lt;old value&gt;:&lt;new value&gt;, ...}}\n        Format to use pandas' replace:\n            {&lt;old value&gt;:&lt;new value&gt;, ...}\n\n    regex : bool\n        If true, replace using regular expression. It uses pandas\n        replace()\n\n    Returns\n    -------\n    tibble\n        Original tibble with values of columns replaced based on\n        rep`.\n    \"\"\"\n    if regex or not all(isinstance(value, dict) for value in rep.values()):\n        engine = 'pandas'\n    else:\n        engine = 'polars'\n\n    if engine=='polars':\n        out = self.to_polars()\n        for var, rep in rep.items():\n            try:\n                out = out.with_columns(**{var : pl.col(var).replace(rep)})\n            except :\n                out = out.with_columns(**{var : pl.col(var).replace_strict(rep)})\n        out = out.pipe(from_polars)\n    else:\n        out = self.to_pandas()\n        out = out.replace(to_replace=rep, regex=regex)\n        out = out.pipe(from_pandas)\n\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.replace_null","title":"<code>replace_null(replace=None)</code>","text":"<p>Replace null values</p> <p>Parameters:</p> Name Type Description Default <code>replace</code> <code>dict</code> <p>Dictionary of column/replacement pairs</p> <code>None</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with missing/null values replaced.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble(x = [0, None], y = [None, None])\n&gt;&gt;&gt; df.replace_null(dict(x = 1, y = 2))\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def replace_null(self, replace = None):\n    \"\"\"\n    Replace null values\n\n    Parameters\n    ----------\n    replace : dict\n        Dictionary of column/replacement pairs\n\n    Returns\n    -------\n    tibble\n        Original tibble with missing/null values replaced.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble(x = [0, None], y = [None, None])\n    &gt;&gt;&gt; df.replace_null(dict(x = 1, y = 2))\n    \"\"\"\n    if replace == None: return self\n    if type(replace) != dict:\n        ValueError(\"replace must be a dictionary of column/replacement pairs\")\n    replace_exprs = [col(key).fill_null(value) for key, value in replace.items()]\n    return self.mutate(*replace_exprs)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.select","title":"<code>select(*args)</code>","text":"<p>Select or drop columns</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str, list, dict, of combinations of them</code> <p>Columns to select. It can combine names, list of names, and a dict. If dict, it will rename the columns based on the dict. It also accepts tp.matches() and tp.contains() <code>()</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'abcba': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.select('a', 'b')\n&gt;&gt;&gt; df.select(col('a'), col('b'))\n&gt;&gt;&gt; df.select({'a': 'new name'}, tp.matches(\"c\"))\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def select(self, *args):\n    \"\"\"\n    Select or drop columns\n\n    Parameters\n    ----------\n    *args : str, list, dict, of combinations of them\n        Columns to select. It can combine names, list of names,\n        and a dict. If dict, it will rename the columns based\n        on the dict.\n        It also accepts tp.matches(&lt;regex&gt;) and tp.contains(&lt;str&gt;)\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'abcba': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.select('a', 'b')\n    &gt;&gt;&gt; df.select(col('a'), col('b'))\n    &gt;&gt;&gt; df.select({'a': 'new name'}, tp.matches(\"c\"))\n    \"\"\"\n    # convert to list if dict.keys or dict.values are used\n    cols_to_select = []\n    cols_to_rename = {}\n    for arg in args:\n        if isinstance(arg, {}.keys().__class__) or\\\n           isinstance(arg, {}.values().__class__):\n            cols_to_select += list(arg)\n\n        elif isinstance(arg, dict):\n            cols_to_select += [col for col,_ in arg.items()] \n            cols_to_rename |= arg \n\n        elif isinstance(arg, str):\n            cols_to_select += [arg]\n\n        elif isinstance(arg, list):\n            cols_to_select += arg\n\n        elif isinstance(arg, set):\n            cols_to_select += list(arg)\n\n    # # rename columns if dict is used\n    # cols_dict = [d for d in args if isinstance(d, dict)]\n    # if cols_dict:\n    #     cols_dict = cols_dict[0]\n    #     dict_list = list(cols_dict.values())\n    #     self = self.rename(cols_dict)\n    # else:\n    #     dict_list = []\n\n    # # collect str and list elements\n    # cols_list = [c for c in args if isinstance(c, str) or isinstance(c, list)]\n    # # flatten list\n    # cols_list = list(chain.from_iterable((x if isinstance(x, list)\n    #                                       else [x] for x in cols_list ))) \n\n    # # collect dict.keys() or dict.values()\n    # cols_dict_keys   = [k for k in args if isinstance( k, type({}.keys()) )]\n    # cols_dict_values = [k for k in args if isinstance( k, type({}.values()) )]\n\n    # # collect set\n    # cols_set = [s for s in args if isinstance(s, set)]\n    # if cols_set:\n    #     cols_set = list(cols_set[0])\n\n    # cols = cols_list + dict_list + cols_dict_keys +cols_dict_values +cols_set \n\n    # remove non-existing columns\n    cols_to_select = [col for col in cols_to_select \n                      if col in self.names \n                      or (col.startswith(\"^\") and col.endswith(\"$\"))] \n    # cols = [col for col in cols if col in self.names or\n    #         (col.startswith(\"^\") and col.endswith(\"$\"))]\n\n    cols = _col_exprs(cols_to_select)\n    return super().select(cols).pipe(from_polars).rename(cols_to_rename)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.separate","title":"<code>separate(sep_col, into, sep='_', remove=True)</code>","text":"<p>Separate a character column into multiple columns</p> <p>Parameters:</p> Name Type Description Default <code>sep_col</code> <code>str</code> <p>Column to split into multiple columns</p> required <code>into</code> <code>list</code> <p>List of new column names</p> required <code>sep</code> <code>str</code> <p>Separator to split on. Default to \u2018_\u2019</p> <code>'_'</code> <code>remove</code> <code>bool</code> <p>If True removes the input column from the output data frame</p> <code>True</code> <p>Returns:</p> Type Description <code>tibble</code> <p>Original tibble with a column splitted based on <code>sep</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble(x = ['a_a', 'b_b', 'c_c'])\n&gt;&gt;&gt; df.separate('x', into = ['left', 'right'])\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def separate(self, sep_col, into, sep = '_', remove = True):\n    \"\"\"\n    Separate a character column into multiple columns\n\n    Parameters\n    ----------\n    sep_col : str\n        Column to split into multiple columns\n    into : list\n        List of new column names\n    sep : str\n        Separator to split on. Default to '_'\n    remove : bool\n        If True removes the input column from the output data frame\n\n    Returns\n    -------\n    tibble\n        Original tibble with a column splitted based on `sep`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble(x = ['a_a', 'b_b', 'c_c'])\n    &gt;&gt;&gt; df.separate('x', into = ['left', 'right'])\n    \"\"\"\n    into_len = len(into) - 1\n    sep_df = (\n        self\n        .to_polars()\n        .select(col(sep_col)\n                .str.split_exact(sep, into_len)\n                .alias(\"_seps\")\n                .struct\n                .rename_fields(into))\n        .unnest(\"_seps\")\n        .pipe(from_polars)\n    )\n    out = self.bind_cols(sep_df)\n    if remove == True:\n        out = out.drop(sep_col)\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.set_names","title":"<code>set_names(nm=None)</code>","text":"<p>Change the column names of the data frame</p> <p>Parameters:</p> Name Type Description Default <code>nm</code> <code>list</code> <p>A list of new names for the data frame</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble(x = range(3), y = range(3))\n&gt;&gt;&gt; df.set_names(['a', 'b'])\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def set_names(self, nm = None):\n    \"\"\"\n    Change the column names of the data frame\n\n    Parameters\n    ----------\n    nm : list\n        A list of new names for the data frame\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble(x = range(3), y = range(3))\n    &gt;&gt;&gt; df.set_names(['a', 'b'])\n    \"\"\"\n    if nm == None: nm = self.names\n    nm = _as_list(nm)\n    rename_dict = {k:v for k, v in zip(self.names, nm)}\n    return self.rename(rename_dict)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.slice","title":"<code>slice(*args, by=None)</code>","text":"<p>Grab rows from a data frame</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>(int, list)</code> <p>Rows to grab</p> <code>()</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.slice(0, 1)\n&gt;&gt;&gt; df.slice(0, by = 'c')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def slice(self, *args, by = None):\n    \"\"\"\n    Grab rows from a data frame\n\n    Parameters\n    ----------\n    *args : int, list\n        Rows to grab\n    by : str, list\n        Columns to group by\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.slice(0, 1)\n    &gt;&gt;&gt; df.slice(0, by = 'c')\n    \"\"\"\n    rows = _as_list(args)\n    if _uses_by(by):\n        df = super(tibble, self).group_by(by).map_groups(lambda x: x.select(pl.all().gather(rows)))\n    else:\n        df = super(tibble, self).select(pl.all().gather(rows))\n    return df.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.slice_head","title":"<code>slice_head(n=5, *, by=None)</code>","text":"<p>Grab top rows from a data frame</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to grab</p> <code>5</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.slice_head(2)\n&gt;&gt;&gt; df.slice_head(1, by = 'c')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def slice_head(self, n = 5, *, by = None):\n    \"\"\"\n    Grab top rows from a data frame\n\n    Parameters\n    ----------\n    n : int\n        Number of rows to grab\n    by : str, list\n        Columns to group by\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.slice_head(2)\n    &gt;&gt;&gt; df.slice_head(1, by = 'c')\n    \"\"\"\n    col_order = self.names\n    if _uses_by(by):\n        df = super(tibble, self).group_by(by).head(n)\n    else:\n        df = super(tibble, self).head(n)\n    df = df.select(col_order)\n    return df.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.slice_tail","title":"<code>slice_tail(n=5, *, by=None)</code>","text":"<p>Grab bottom rows from a data frame</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to grab</p> <code>5</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.slice_tail(2)\n&gt;&gt;&gt; df.slice_tail(1, by = 'c')\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def slice_tail(self, n = 5, *, by = None):\n    \"\"\"\n    Grab bottom rows from a data frame\n\n    Parameters\n    ----------\n    n : int\n        Number of rows to grab\n    by : str, list\n        Columns to group by\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.slice_tail(2)\n    &gt;&gt;&gt; df.slice_tail(1, by = 'c')\n    \"\"\"\n    col_order = self.names\n    if _uses_by(by):\n        df = super(tibble, self).group_by(by).tail(n)\n    else:\n        df = super(tibble, self).tail(n)\n    df = df.select(col_order)\n    return df.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.summarise","title":"<code>summarise(*args, by=None, **kwargs)</code>","text":"<p>Alias for <code>.summarize()</code></p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def summarise(self, *args,\n              by = None,\n              **kwargs):\n    \"\"\"Alias for `.summarize()`\"\"\"\n    return self.summarize(*args, by = by, **kwargs)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.summarize","title":"<code>summarize(*args, by=None, **kwargs)</code>","text":"<p>Aggregate data with summary statistics</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Expr</code> <p>Column expressions to add or modify</p> <code>()</code> <code>by</code> <code>(str, list)</code> <p>Columns to group by</p> <code>None</code> <code>**kwargs</code> <code>Expr</code> <p>Column expressions to add or modify</p> <code>{}</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A tibble with the summaries</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n&gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')))\n&gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n...              by = 'c')\n&gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n...              max_b = tp.max(col('b')))\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def summarize(self, *args,\n              by = None,\n              **kwargs):\n    \"\"\"\n    Aggregate data with summary statistics\n\n    Parameters\n    ----------\n    *args : Expr\n        Column expressions to add or modify\n    by : str, list\n        Columns to group by\n    **kwargs : Expr\n        Column expressions to add or modify\n\n    Returns\n    -------\n    tibble\n        A tibble with the summaries\n\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble({'a': range(3), 'b': range(3), 'c': ['a', 'a', 'b']})\n    &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')))\n    &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n    ...              by = 'c')\n    &gt;&gt;&gt; df.summarize(avg_a = tp.mean(col('a')),\n    ...              max_b = tp.max(col('b')))\n    \"\"\"\n    exprs = _as_list(args) + _kwargs_as_exprs(kwargs)\n    if _uses_by(by):\n        out = super(tibble, self).group_by(by).agg(exprs)\n    else:\n        out = super(tibble, self).select(exprs)\n    return out.pipe(from_polars)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.tab","title":"<code>tab(row, col, groups=None, margins=True, normalize='all', margins_name='Total', stat='both', na_rm=True, na_label='NA', digits=2)</code>","text":"<p>Create a 2x2 contingency table for two categorical variables, with optional grouping, margins, and normalization.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>str</code> <p>Name of the variable to be used for the rows of the table.</p> required <code>col</code> <code>str</code> <p>Name of the variable to be used for the columns of the table.</p> required <code>groups</code> <code>str or list of str</code> <p>Variable name(s) to use as grouping variables. When provided, a separate 2x2 table is generated for each group.</p> <code>None</code> <code>margins</code> <code>bool</code> <p>If True, include row and column totals (margins) in the table.</p> <code>True</code> <code>normalize</code> <code>(all, row, columns)</code> <p>Specifies how to compute the marginal percentages in each cell:   - \u2018all\u2019: percentages computed over the entire table.   - \u2018row\u2019: percentages computed across each row.   - \u2018columns\u2019: percentages computed down each column.</p> <code>'all'</code> <code>margins_name</code> <code>str</code> <p>Name to assign to the row and column totals.</p> <code>'Total'</code> <code>stat</code> <code>(both, perc, n)</code> <p>Determines the statistic to display in each cell:   - \u2018both\u2019: returns both percentages and sample size.   - \u2018perc\u2019: returns percentages only.   - \u2018n\u2019: returns sample size only.</p> <code>'both'</code> <code>na_rm</code> <code>bool</code> <p>If True, remove rows with missing values in the <code>row</code> or <code>col</code> variables.</p> <code>True</code> <code>na_label</code> <code>str</code> <p>Label to use for missing values when <code>na_rm</code> is False.</p> <code>'NA'</code> <code>digits</code> <code>int</code> <p>Number of digits to round the percentages to.</p> <code>2</code> <p>Returns:</p> Type Description <code>tibble</code> <p>A contingency table as a tibble. The table contains counts and/or percentages as specified by the <code>stat</code> parameter, includes margins if requested, and is formatted with group headers when grouping variables are provided.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def tab(self, row, col, groups=None,\n        margins=True, normalize='all',#row/columns\n        margins_name='Total', stat='both',\n        na_rm=True, na_label='NA', digits=2):\n    \"\"\"\n    Create a 2x2 contingency table for two categorical variables, with optional grouping,\n    margins, and normalization.\n\n    Parameters\n    ----------\n    row : str\n        Name of the variable to be used for the rows of the table.\n    col : str\n        Name of the variable to be used for the columns of the table.\n    groups : str or list of str, optional\n        Variable name(s) to use as grouping variables. When provided, a separate 2x2 table\n        is generated for each group.\n    margins : bool, default True\n        If True, include row and column totals (margins) in the table.\n    normalize : {'all', 'row', 'columns'}, default 'all'\n        Specifies how to compute the marginal percentages in each cell:\n          - 'all': percentages computed over the entire table.\n          - 'row': percentages computed across each row.\n          - 'columns': percentages computed down each column.\n    margins_name : str, default 'Total'\n        Name to assign to the row and column totals.\n    stat : {'both', 'perc', 'n'}, default 'both'\n        Determines the statistic to display in each cell:\n          - 'both': returns both percentages and sample size.\n          - 'perc': returns percentages only.\n          - 'n': returns sample size only.\n    na_rm : bool, default True\n        If True, remove rows with missing values in the `row` or `col` variables.\n    na_label : str, default 'NA'\n        Label to use for missing values when `na_rm` is False.\n    digits : int, default 2\n        Number of digits to round the percentages to.\n\n    Returns\n    -------\n    tibble\n        A contingency table as a tibble. The table contains counts and/or percentages as specified\n        by the `stat` parameter, includes margins if requested, and is formatted with group headers\n        when grouping variables are provided.\n    \"\"\"\n    tab = self.select(row, col, groups).mutate(**{row:as_character(row),\n                                                  col:as_character(col)})\n    vars_row = row\n    vars_col = col\n    if na_rm:\n        tab = tab.drop_null()\n    else:\n        repl = {var:na_label for var in [row, col]}\n        tab = tab.replace_null(repl)\n    tab = tab.to_pandas()\n    if groups:\n        groups = [groups] if isinstance(groups, str) else groups\n        ngroups=len(groups)\n        resn = self.__tab_groups__(tab, vars_row, vars_col, normalize=False,\n                                   margins=margins, margins_name=margins_name,\n                                   groups=groups)\n        resp = self.__tab_groups__(tab, vars_row, vars_col, normalize,\n                                   margins, margins_name, groups)\n    else:\n        ngroups=0\n        resn = self.__tab__(tab, vars_row, vars_col, normalize=False,\n                            margins=margins, margins_name=margins_name)\n        resp = self.__tab__(tab, vars_row, vars_col, normalize=normalize,\n                            margins=margins, margins_name=margins_name)\n    colsn=resn.columns[ngroups+1:]\n    colsp=resp.columns[ngroups+1:]\n    res=resp.iloc[:,0:ngroups+1]\n\n    if stat=='both':\n        for coln, colp in zip(colsn, colsp):\n            col = [f\"{round(100*p, digits)} % ({n})\" for p,n\n                   in zip(resp[colp], resn[coln])]\n            res = res.assign(**{coln:col})\n    elif stat=='perc':\n        for colp in colsp:\n            res = res.assign(**{str(colp):100*resp[colp]})\n    else:\n        for coln in colsn:\n            res = res.assign(**{str(coln):100*resp[coln]})\n    # Group columns using varname as label\n    ncat = len(tab[vars_col].unique())\n    ngroups = 0 if not groups else len(groups)\n    col_groups = ['']*(ngroups+1) + [vars_col]*ncat+['']\n    col_ix = pd.MultiIndex.from_arrays([col_groups, res.columns])\n    res.columns = col_ix\n    res.columns.names = ['', '']\n    res.columns.name = ''\n    res.columns = [col[1] for col in res.columns]\n    res = self.__tab_reorder_na__(res, row, na_label)\n    return from_pandas(res)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.tail","title":"<code>tail(n=5, *, by=None)</code>","text":"<p>Alias for <code>.slice_tail()</code></p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def tail(self, n = 5, *, by = None):\n    \"\"\"Alias for `.slice_tail()`\"\"\"\n    return self.slice_tail(n, by = by)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_csv","title":"<code>to_csv(*args, **kws)</code>","text":"<p>Save table to csv.</p> Details <p>See polars <code>write_csv()</code> for details.</p> <p>Returns:</p> Type Description <code>None</code> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_csv(self, *args, **kws):\n    \"\"\"\n    Save table to csv.\n\n    Details\n    -------\n    See polars `write_csv()` for details.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    self.to_polars().write_csv(*args, **kws)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_dict","title":"<code>to_dict(*, as_series=True)</code>","text":"<p>Aggregate data with summary statistics</p> <p>Parameters:</p> Name Type Description Default <code>as_series</code> <code>bool</code> <p>If True - returns the dict values as Series If False - returns the dict values as lists</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.to_dict()\n&gt;&gt;&gt; df.to_dict(as_series = False)\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_dict(self, *, as_series = True):\n    \"\"\"\n    Aggregate data with summary statistics\n\n    Parameters\n    ----------\n    as_series : bool\n        If True - returns the dict values as Series\n        If False - returns the dict values as lists\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.to_dict()\n    &gt;&gt;&gt; df.to_dict(as_series = False)\n    \"\"\"\n    return super().to_dict(as_series = as_series)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_excel","title":"<code>to_excel(*args, **kws)</code>","text":"<p>Save table to excel.</p> Details <p>See polars <code>write_excel()</code> for details.</p> <p>Returns:</p> Type Description <code>None</code> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_excel(self, *args, **kws):\n    \"\"\"\n    Save table to excel.\n\n    Details\n    -------\n    See polars `write_excel()` for details.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    self.to_polars().write_excel(*args, **kws)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_latex","title":"<code>to_latex(header=None, digits=4, caption=None, label=None, align=None, na_rep='', position='!htb', group_rows_by=None, group_title_align='l', footnotes=None, index=False, escape=False, longtable=False, longtable_singlespace=True, rotate=False, scale=True, parse_linebreaks=True, tabular=False)</code>","text":"<p>Convert the object to a LaTeX tabular representation.</p> <p>Parameters:</p> Name Type Description Default <code>header</code> <code>list of tuples</code> <p>The column headers for the LaTeX table. Each tuple corresponds to a column. Ex: This will create upper level header with grouped columns     [(\u201c\u201d, \u201ccol 1\u201d),      (\u201cGroup A\u201d, \u201ccol 2\u201d),      (\u201cGroup A\u201d, \u201ccol 3\u201d),      (\u201cGroup B\u201d, \u201ccol 4\u201d)      (\u201cGroup B\u201d, \u201ccol 5\u201d),       ]     This will create two upper level header with grouped columns     [(\u201cGroup 1\u201d, \u201c\u201d       , \u201ccol 1\u201d),      (\u201cGroup 1\u201d, \u201cGroup A\u201d, \u201ccol 2\u201d),      (\u201cGroup 1\u201d, \u201cGroup A\u201d, \u201ccol 3\u201d),      (\u201c\u201d       , \u201cGroup B\u201d, \u201ccol 4\u201d)      (\u201c\u201d       , \u201cGroup B\u201d, \u201ccol 5\u201d),       ]</p> <code>None</code> <code>digits</code> <code>int</code> <p>Number of decimal places to round the numerical values in the table.</p> <code>4</code> <code>caption</code> <code>str</code> <p>The caption for the LaTeX table.</p> <code>None</code> <code>label</code> <code>str</code> <p>The label for referencing the table in LaTeX.</p> <code>None</code> <code>align</code> <code>str</code> <p>Column alignment specifications (e.g., \u2018lcr\u2019).</p> <code>None</code> <code>na_rep</code> <code>str</code> <p>The representation for NaN values in the table.</p> <code>''</code> <code>position</code> <code>str</code> <p>The placement option for the table in the LaTeX document.</p> <code>'!htbp'</code> <code>footnotes</code> <code>dict</code> <p>A dictionary where keys are column alignments (\u2018c\u2019, \u2018r\u2019, or \u2018l\u2019) and values are the respective footnote strings.</p> <code>None</code> <code>group_rows_by</code> <code>str</code> <p>Name of the variable in the data with values to group the rows by.</p> <code>None</code> <code>group_title_align</code> <p>Alignment of the title of each row group</p> <code>'l'</code> <code>index</code> <code>bool</code> <p>Whether to include the index in the LaTeX table.</p> <code>False</code> <code>escape</code> <code>bool</code> <p>Whether to escape LaTeX special characters.</p> <code>False</code> <code>longtable</code> <code>bool, deafult=False</code> <p>If True, table spans multiple pages</p> <code>False</code> <code>longtable_singlespace</code> <code>bool</code> <p>Force single space to longtables</p> <code>True</code> <code>rotate</code> <code>bool</code> <p>Whether to use landscape table</p> <code>False</code> <code>scale</code> <code>bool</code> <p>If True, scales the table to fit the linewidth when the table exceeds that size Note: ignored when longtable=True. This is a LaTeX       limitation because longtable does not use       tabular.</p> <code>True</code> <code>parse_linebreaks</code> <code>book</code> <p>If True, parse \\n and replace it with \\makecel to produce linebreaks</p> <code>True</code> <code>tabular</code> <code>bool</code> <p>Whether to use a tabular format for the output.</p> <code>False</code> <p>Returns:</p> Type Description <code>    str</code> <p>A LaTeX formatted string of the tibble.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_latex(self,\n             header = None,\n             digits = 4,\n             caption = None,\n             label = None,\n             align = None,\n             na_rep  =  '',\n             position = '!htb',\n             group_rows_by = None,\n             group_title_align = 'l',\n             footnotes = None,\n             index = False,\n             escape = False,\n             longtable = False,\n             longtable_singlespace = True,\n             rotate = False,\n             scale = True,\n             parse_linebreaks=True,\n             tabular = False\n             ):\n    \"\"\"\n    Convert the object to a LaTeX tabular representation.\n\n    Parameters\n    ----------\n    header : list of tuples, optional\n        The column headers for the LaTeX table. Each tuple corresponds to a column.\n        Ex: This will create upper level header with grouped columns\n            [(\"\", \"col 1\"),\n             (\"Group A\", \"col 2\"),\n             (\"Group A\", \"col 3\"),\n             (\"Group B\", \"col 4\")\n             (\"Group B\", \"col 5\"),\n              ]\n            This will create two upper level header with grouped columns\n            [(\"Group 1\", \"\"       , \"col 1\"),\n             (\"Group 1\", \"Group A\", \"col 2\"),\n             (\"Group 1\", \"Group A\", \"col 3\"),\n             (\"\"       , \"Group B\", \"col 4\")\n             (\"\"       , \"Group B\", \"col 5\"),\n              ]\n    digits : int, default=4\n        Number of decimal places to round the numerical values in the table.\n\n    caption : str, optional\n        The caption for the LaTeX table.\n\n    label : str, optional\n        The label for referencing the table in LaTeX.\n\n    align : str, optional\n        Column alignment specifications (e.g., 'lcr').\n\n    na_rep : str, default=''\n        The representation for NaN values in the table.\n\n    position : str, default='!htbp'\n        The placement option for the table in the LaTeX document.\n\n    footnotes : dict, optional\n        A dictionary where keys are column alignments ('c', 'r', or 'l')\n        and values are the respective footnote strings.\n\n    group_rows_by : str, default=None\n        Name of the variable in the data with values to group\n        the rows by.\n\n    group_title_align str, default='l'\n        Alignment of the title of each row group\n\n    index : bool, default=False\n        Whether to include the index in the LaTeX table.\n\n    escape : bool, default=False\n        Whether to escape LaTeX special characters.\n\n    longtable : bool, deafult=False\n        If True, table spans multiple pages\n\n    longtable_singlespace : bool\n        Force single space to longtables\n\n    rotate : bool\n        Whether to use landscape table\n\n    scale : bool, default=True\n        If True, scales the table to fit the linewidth when\n        the table exceeds that size\n        Note: ignored when longtable=True. This is a LaTeX\n              limitation because longtable does not use\n              tabular.\n\n    parse_linebreaks : book, default=True\n        If True, parse \\\\n and replace it with \\\\makecel\n        to produce linebreaks\n\n    tabular : bool, default=False\n        Whether to use a tabular format for the output.\n\n    Returns\n    -------\n        str\n            A LaTeX formatted string of the tibble.\n    \"\"\"\n\n    assert footnotes is None or isinstance(footnotes, dict),\\\n        \"'footnote' must be a dictionary\"\n\n    # this must be the first operation\n    if group_rows_by is not None:\n        self = self.arrange(group_rows_by)\n        tabm = self.to_pandas().drop([group_rows_by], axis=1)\n    else:\n        tabm = self.to_pandas()\n    ncols = tabm.shape[1]\n\n    if tabular and not longtable:\n        position=None\n\n    if align is None:\n        align = 'l'*ncols\n\n    if header is not None:\n        tabm.columns = pd.MultiIndex.from_tuples(header)\n\n    tabl = (tabm\n            # .round(digits)\n            # .astype(str)\n            .to_latex(index = index,\n                      escape = escape,\n                      caption = caption,\n                      label = label,\n                      sparsify = True,\n                      multirow = True,\n                      multicolumn = True,\n                      multicolumn_format = 'c',\n                      column_format = align,\n                      bold_rows = True,\n                      na_rep = na_rep,\n                      float_format=f\"%.{digits}f\",\n                      position = position\n                      ))\n\n    # split to add elements\n    rows = tabl.splitlines()\n\n    if group_rows_by is not None:\n        rows = self.__to_latex_group_rows__(group_rows_by, group_title_align, ncols, rows)\n\n    # add centering\n    row = [i for i, txt in enumerate(rows) if\n           bool(re.search(pattern='begin.*tabular', string=txt))][0]\n    rows.insert(row,f\"\\\\centering\")\n\n    footnotes_formated = \"\"\n    if footnotes is not None:\n        for align_note, footnote in footnotes.items():\n            footnote = [footnote] if isinstance(footnote, str) else footnote\n            for fni in footnote:\n                notes = f\"\\\\multicolumn{{{ncols}}}{{{align_note}}}{{{fni}}}\\\\\\\\\"\n                footnotes_formated += notes\n                if not longtable:\n                    row = [idx for idx, s in enumerate(rows) if 'bottomrule' in s ][0]\n                    rows.insert(row + 1, notes)\n\n\n    # rejoin table\n    tabl = \"\\n\".join(rows)\n\n    # add midrules\n    if header is not None:\n        tabl = self.__to_latex_add_midrules_to_table__(tabl)\n\n    if longtable:\n        tabl = self.__to_latex_multipage__(tabl, caption, ncols, align,\n                                           label, position,\n                                           footnotes_formated,\n                                           longtable_singlespace)\n\n    if rotate:\n        tabl = re.sub(pattern=\"^\", repl='\\\\\\\\begin{landscape}', string=tabl)\n        tabl = re.sub(pattern=\"$\", repl='\\\\\\\\end{landscape}', string=tabl)\n\n    if scale and not longtable:\n        box = '\\\\resizebox{\\\\ifdim\\\\width&gt;\\\\linewidth\\\\linewidth\\\\else\\\\width\\\\fi}{!}{'\n        tabl = tabl.replace('\\\\begin{tabular}', f\"{box}\\n\\\\begin{{tabular}}\")\n        tabl = tabl.replace('\\\\end{tabular}', \"\\\\end{tabular}}\")\n\n    # linebreaks:\n    if parse_linebreaks:\n        tabl = self.__to_latex_breaklines__(tabl)    \n\n    return tabl\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert to a pandas DataFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.to_pandas()\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_pandas(self):\n    \"\"\"\n    Convert to a pandas DataFrame\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.to_pandas()\n    \"\"\"\n    # keep order of factors (pl.Enum)\n    enum_columns = [col for col in self.names if self.pull(col).dtype == pl.Enum]\n    res = self.to_polars().to_pandas()\n    if enum_columns :\n        for col in enum_columns:\n            # Get unique categories in order of appearance\n            categories_in_order = self.pull(col).cat.get_categories().to_list()\n            # Convert the column to Categorical\n            res[col] = pd.Categorical(\n                res[col],\n                categories=categories_in_order,\n                ordered=True\n            )\n    return res\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert to a polars DataFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.to_polars()\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def to_polars(self):\n    \"\"\"\n    Convert to a polars DataFrame\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.to_polars()\n    \"\"\"\n    self = copy.copy(self)\n    self.__class__ = pl.DataFrame\n    return self\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.unite","title":"<code>unite(col='_united', unite_cols=[], sep='_', remove=True)</code>","text":"<p>Unite multiple columns by pasting strings together</p> <p>Parameters:</p> Name Type Description Default <code>col</code> <code>str</code> <p>Name of the new column</p> <code>'_united'</code> <code>unite_cols</code> <code>list</code> <p>List of columns to unite</p> <code>[]</code> <code>sep</code> <code>str</code> <p>Separator to use between values</p> <code>'_'</code> <code>remove</code> <code>bool</code> <p>If True removes input columns from the data frame</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = tp.tibble(a = [\"a\", \"a\", \"a\"], b = [\"b\", \"b\", \"b\"], c = range(3))\n&gt;&gt;&gt; df.unite(\"united_col\", unite_cols = [\"a\", \"b\"])\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def unite(self, col = \"_united\", unite_cols = [], sep = \"_\", remove = True):\n    \"\"\"\n    Unite multiple columns by pasting strings together\n\n    Parameters\n    ----------\n    col : str\n        Name of the new column\n    unite_cols : list\n        List of columns to unite\n    sep : str\n        Separator to use between values\n    remove : bool\n        If True removes input columns from the data frame\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = tp.tibble(a = [\"a\", \"a\", \"a\"], b = [\"b\", \"b\", \"b\"], c = range(3))\n    &gt;&gt;&gt; df.unite(\"united_col\", unite_cols = [\"a\", \"b\"])\n    \"\"\"\n    if len(unite_cols) == 0:\n        unite_cols = self.names\n    else: \n        unite_cols = _col_exprs(unite_cols)\n        unite_cols = self.select(unite_cols).names\n    out = self.mutate(str_c(*unite_cols, sep = sep).alias(col))\n    out = out.relocate(col, before = unite_cols[0])\n    if remove == True:\n        out = out.drop(unite_cols)\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.unnest","title":"<code>unnest(col)</code>","text":"<p>Unnest a nested tibble</p> <p>Parameters:</p> Name Type Description Default <code>col</code> <code>str</code> <p>Columns to unnest</p> required <p>Returns:</p> Type Description <code>tibble</code> <p>The nested tibble will be expanded and become unested rows of the original tibble.</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def unnest(self, col):\n    \"\"\"\n    Unnest a nested tibble\n    Parameters\n    ----------\n    col : str\n        Columns to unnest\n\n    Returns\n    -------\n    tibble\n        The nested tibble will be expanded and become unested\n        rows of the original tibble.\n\n    \"\"\"\n    assert isinstance(col, str), \"'col', must be a string\"\n    # not run: error if nested df has different columns\n    # out = (self\n    #        .mutate(**{\n    #            col : pl.col(col).map_elements(lambda d: d.to_struct())\n    #        })\n    #        .to_polars()\n    #        .explode(col)\n    #        .unnest(col)\n    #        )\n    # return out.pipe(from_polars)\n    out = tibble()\n    for row in self.to_polars().iter_rows(named=True):\n        n = row[col].nrow\n        ids = {c:v for c, v in row.items() if c not in col}\n        cols = list(ids.keys())\n        df_ids = from_polars(pl.DataFrame(ids)\n                             .with_columns(pl.col(cols) .repeat_by(n))\n                             .explode(cols))\n        out = out.bind_rows(df_ids.bind_cols(row[col]))\n    out = self.__unnest_cast__(self, out)\n    return out\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.write_csv","title":"<code>write_csv(file=None, has_headers=True, sep=',')</code>","text":"<p>Write a data frame to a csv</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def write_csv(self,\n              file = None,\n              has_headers = True,\n              sep = ','):\n    \"\"\"Write a data frame to a csv\"\"\"\n    return super().write_csv(file, include_header = has_headers, separator = sep)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.tibble.write_parquet","title":"<code>write_parquet(file=str, compression='snappy', use_pyarrow=False, **kwargs)</code>","text":"<p>Write a data frame to a parquet</p> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def write_parquet(self,\n                  file = str,\n                  compression = 'snappy',\n                  use_pyarrow = False,\n                  **kwargs):\n    \"\"\"Write a data frame to a parquet\"\"\"\n    return super().write_parquet(file, compression = compression, use_pyarrow = use_pyarrow, **kwargs)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.abs","title":"<code>abs(x)</code>","text":"<p>Absolute value</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(abs_x = tp.abs('x'))\n&gt;&gt;&gt; df.mutate(abs_x = tp.abs(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def abs(x):\n    \"\"\"\n    Absolute value\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(abs_x = tp.abs('x'))\n    &gt;&gt;&gt; df.mutate(abs_x = tp.abs(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.abs()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_boolean","title":"<code>as_boolean(x)</code>","text":"<p>Convert column to string. Alias to as_logical (R naming).</p> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_boolean(x):\n    \"\"\"\n    Convert column to string. Alias to as_logical (R naming).\n    \"\"\"\n    return as_logical(x)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_categorical","title":"<code>as_categorical(*args, **kwargs)</code>","text":"<p>Convert to factor. Alias for as_factor</p> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_categorical(*args, **kwargs):\n    \"Convert to factor. Alias for as_factor\"\n    return as_factor(*args, **kwargs)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_character","title":"<code>as_character(x)</code>","text":"<p>Convert to string. Defaults to Utf8.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Str</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(string_x = tp.as_string('x'))\n# or equivalently\n&gt;&gt;&gt; df.mutate(character_x = tp.as_character('x'))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_character(x):\n    \"\"\"\n    Convert to string. Defaults to Utf8.\n\n    Parameters\n    ----------\n    x : Str \n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(string_x = tp.as_string('x'))\n    # or equivalently\n    &gt;&gt;&gt; df.mutate(character_x = tp.as_character('x'))\n    \"\"\"\n    x = _col_expr(x)\n    return x.cast(pl.Utf8)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_factor","title":"<code>as_factor(x, levels=None)</code>","text":"<p>Convert to factor (R naming), equlivalent to Enum or Categorical (polars), depending on whether \u2018levels\u2019 is provided. </p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Str</code> <p>Column to operate on</p> required <code>levels</code> <code>list of str</code> <p>Categories to use in the factor. The catogories will be ordered as they appear in the list. If None (default), it will create an unordered factor (polars Categorical).</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(factor_x = tp.as_factor('x'))\n# or equivalently\n&gt;&gt;&gt; df.mutate(categorical_x = tp.as_categorical('x'))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_factor(x, levels = None):\n    \"\"\"\n    Convert to factor (R naming), equlivalent to Enum or\n    Categorical (polars), depending on whether 'levels' is provided. \n\n    Parameters\n    ----------\n    x : Str\n        Column to operate on\n\n    levels : list of str\n        Categories to use in the factor. The catogories will be ordered\n        as they appear in the list. If None (default), it will\n        create an unordered factor (polars Categorical).\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(factor_x = tp.as_factor('x'))\n    # or equivalently\n    &gt;&gt;&gt; df.mutate(categorical_x = tp.as_categorical('x'))\n    \"\"\"\n    x = _col_expr(x)\n    x = x.cast(pl.String)\n    if levels is None:\n        x = x.cast(pl.Categorical)\n    else:\n        x = x.cast(pl.Enum(levels))\n    return x\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_float","title":"<code>as_float(x)</code>","text":"<p>Convert to float. Defaults to Float64.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(float_x = tp.as_float(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_float(x):\n    \"\"\"\n    Convert to float. Defaults to Float64.\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(float_x = tp.as_float(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.cast(pl.Float64)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_integer","title":"<code>as_integer(x)</code>","text":"<p>Convert to integer. Defaults to Int64.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Expr</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(int_x = tp.as_integer(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_integer(x):\n    \"\"\"\n    Convert to integer. Defaults to Int64.\n\n    Parameters\n    ----------\n    x : Expr\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(int_x = tp.as_integer(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.cast(pl.Int64)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_logical","title":"<code>as_logical(x)</code>","text":"<p>Convert to a boolean (polars) or \u2018logical\u2019 (R naming)</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Str</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(bool_x = tp.as_boolean(col('x')))\n# or equivalently\n&gt;&gt;&gt; df.mutate(logical_x = tp.as_logical(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_logical(x):\n    \"\"\"\n    Convert to a boolean (polars) or 'logical' (R naming)\n\n    Parameters\n    ----------\n    x : Str\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(bool_x = tp.as_boolean(col('x')))\n    # or equivalently\n    &gt;&gt;&gt; df.mutate(logical_x = tp.as_logical(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.cast(pl.Boolean)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.as_string","title":"<code>as_string(x)</code>","text":"<p>Convert column to string. Alias to as_character (R naming). Equivalent to Utf8 type (polars)</p> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def as_string(x):\n    '''\n    Convert column to string. Alias to as_character (R naming).\n    Equivalent to Utf8 type (polars)\n    '''\n    return as_character(x)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.cast","title":"<code>cast(x, dtype)</code>","text":"<p>General type conversion.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <code>dtype</code> <code>DataType</code> <p>Type to convert to</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(abs_x = tp.cast(col('x'), tp.Float64))\n</code></pre> Source code in <code>tidypolars4sci/type_conversion.py</code> <pre><code>def cast(x, dtype):\n    \"\"\"\n    General type conversion.\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n    dtype : DataType\n        Type to convert to\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(abs_x = tp.cast(col('x'), tp.Float64))\n    \"\"\"\n    x = _col_expr(x)\n    return x.cast(dtype)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.cor","title":"<code>cor(x, y, method='pearson')</code>","text":"<p>Find the correlation of two columns</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Expr</code> <p>A column</p> required <code>y</code> <code>Expr</code> <p>A column</p> required <code>method</code> <code>str</code> <p>Type of correlation to find. Either \u2018pearson\u2019 or \u2018spearman\u2019.</p> <code>'pearson'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(cor = tp.cor(col('x'), col('y')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def cor(x, y, method = 'pearson'):\n    \"\"\"\n    Find the correlation of two columns\n\n    Parameters\n    ----------\n    x : Expr\n        A column\n    y : Expr\n        A column\n    method : str\n        Type of correlation to find. Either 'pearson' or 'spearman'.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(cor = tp.cor(col('x'), col('y')))\n    \"\"\"\n    if pl.Series([method]).is_in(['pearson', 'spearman']).not_().item():\n        ValueError(\"`method` must be either 'pearson' or 'spearman'\")\n    return pl.corr(x, y, method = method)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.count","title":"<code>count(x)</code>","text":"<p>Number of observations in each group</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(count = tp.count(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def count(x):\n    \"\"\"\n    Number of observations in each group\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(count = tp.count(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.count()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.cov","title":"<code>cov(x, y)</code>","text":"<p>Find the covariance of two columns</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Expr</code> <p>A column</p> required <code>y</code> <code>Expr</code> <p>A column</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(cor = tp.cov(col('x'), col('y')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def cov(x, y):\n    \"\"\"\n    Find the covariance of two columns\n\n    Parameters\n    ----------\n    x : Expr\n        A column\n    y : Expr\n        A column\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(cor = tp.cov(col('x'), col('y')))\n    \"\"\"\n    return pl.cov(x, y)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.first","title":"<code>first(x)</code>","text":"<p>Get first value</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(first_x = tp.first('x'))\n&gt;&gt;&gt; df.summarize(first_x = tp.first(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def first(x):\n    \"\"\"\n    Get first value\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(first_x = tp.first('x'))\n    &gt;&gt;&gt; df.summarize(first_x = tp.first(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.first()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.floor","title":"<code>floor(x)</code>","text":"<p>Round numbers down to the lower integer</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.mutate(floor_x = tp.floor(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def floor(x):\n    \"\"\"\n    Round numbers down to the lower integer\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.mutate(floor_x = tp.floor(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.floor()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.from_pandas","title":"<code>from_pandas(df)</code>","text":"<p>Convert from pandas DataFrame to tibble</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pd.DataFrame to convert to a tibble</p> required <p>Returns:</p> Type Description <code>tibble</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tp.from_pandas(df)\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def from_pandas(df):\n    \"\"\"\n    Convert from pandas DataFrame to tibble\n\n    Parameters\n    ----------\n    df : DataFrame\n        pd.DataFrame to convert to a tibble\n\n    Returns\n    -------\n    tibble\n\n    Examples\n    --------\n    &gt;&gt;&gt; tp.from_pandas(df)\n    \"\"\"\n    if isinstance(df, pd.DataFrame):\n        try:\n            # Try to convert directly\n            df = from_polars(pl.from_pandas(df))\n        except Exception as e:\n            print(f\"Error during conversion: {e}\")\n            print(\"Identifying problematic columns...\")\n\n            # Identify problematic columns by attempting individual conversions\n            problematic_columns = []\n            for column in df.columns:\n                try:\n                    pl.from_pandas(df[[column]])\n                except Exception as col_error:\n                    print(f\"Column '{column}' caused an error: {col_error}\")\n                    problematic_columns.append(column)\n\n            # Convert problematic columns to string type\n            for column in problematic_columns:\n                df[column] = df[column].astype(str)\n    elif isinstance(df, tibble):\n        pass\n    elif isinstance(df, pl.DataFrame):\n        df = from_polars(df)\n    else:\n        df = None\n    return df\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.from_polars","title":"<code>from_polars(df)</code>","text":"<p>Convert from polars DataFrame to tibble</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pl.DataFrame to convert to a tibble</p> required <p>Returns:</p> Type Description <code>tibble</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tp.from_polars(df)\n</code></pre> Source code in <code>tidypolars4sci/tibble_df.py</code> <pre><code>def from_polars(df):\n    \"\"\"\n    Convert from polars DataFrame to tibble\n\n    Parameters\n    ----------\n    df : DataFrame\n        pl.DataFrame to convert to a tibble\n\n    Returns\n    -------\n    tibble\n\n    Examples\n    --------\n    &gt;&gt;&gt; tp.from_polars(df)\n    \"\"\"\n    # df = copy.copy(df)\n    # df.__class__ = tibble\n    df = tibble(df)\n    return df\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.last","title":"<code>last(x)</code>","text":"<p>Get last value</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(last_x = tp.last('x'))\n&gt;&gt;&gt; df.summarize(last_x = tp.last(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def last(x):\n    \"\"\"\n    Get last value\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(last_x = tp.last('x'))\n    &gt;&gt;&gt; df.summarize(last_x = tp.last(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.last()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.length","title":"<code>length(x)</code>","text":"<p>Number of observations in each group</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(length = tp.length(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def length(x):\n    \"\"\"\n    Number of observations in each group\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(length = tp.length(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.count()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.max","title":"<code>max(x)</code>","text":"<p>Get column max</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(max_x = tp.max('x'))\n&gt;&gt;&gt; df.summarize(max_x = tp.max(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def max(x):\n    \"\"\"\n    Get column max\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(max_x = tp.max('x'))\n    &gt;&gt;&gt; df.summarize(max_x = tp.max(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.max()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.mean","title":"<code>mean(x)</code>","text":"<p>Get column mean</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(mean_x = tp.mean('x'))\n&gt;&gt;&gt; df.summarize(mean_x = tp.mean(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def mean(x):\n    \"\"\"\n    Get column mean\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(mean_x = tp.mean('x'))\n    &gt;&gt;&gt; df.summarize(mean_x = tp.mean(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.mean()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.median","title":"<code>median(x)</code>","text":"<p>Get column median</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(median_x = tp.median('x'))\n&gt;&gt;&gt; df.summarize(median_x = tp.median(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def median(x):\n    \"\"\"\n    Get column median\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(median_x = tp.median('x'))\n    &gt;&gt;&gt; df.summarize(median_x = tp.median(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.median()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.min","title":"<code>min(x)</code>","text":"<p>Get column minimum</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(min_x = tp.min('x'))\n&gt;&gt;&gt; df.summarize(min_x = tp.min(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def min(x):\n    \"\"\"\n    Get column minimum\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(min_x = tp.min('x'))\n    &gt;&gt;&gt; df.summarize(min_x = tp.min(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.min()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.min_rank","title":"<code>min_rank(x)</code>","text":"<p>Assigns a minimum rank to each element in the input list, handling ties by assigning the same (lowest) rank to tied values. The next distinct value\u2019s rank is increased by the number of tied values before it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>list</code> <p>A list of values (numeric or otherwise) to be ranked.</p> required <p>Returns:</p> Type Description <code>list of int</code> <p>A list of ranks corresponding to the elements of <code>x</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; min_rank([10, 20, 20, 30])\n[1, 2, 2, 4]\n&gt;&gt;&gt; min_rank([3, 1, 2])\n[3, 1, 2]  # since sorted order is 1,2,3 =&gt; ranks are assigned as per their order\n&gt;&gt;&gt; min_rank([\"b\", \"a\", \"a\", \"c\"])\n[2, 1, 1, 4]\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def min_rank(x):\n    \"\"\"\n    Assigns a minimum rank to each element in the input list, handling ties by\n    assigning the same (lowest) rank to tied values. The next distinct value's rank\n    is increased by the number of tied values before it.\n\n    Parameters\n    ----------\n    x : list\n        A list of values (numeric or otherwise) to be ranked.\n\n    Returns\n    -------\n    list of int\n        A list of ranks corresponding to the elements of `x`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; min_rank([10, 20, 20, 30])\n    [1, 2, 2, 4]\n    &gt;&gt;&gt; min_rank([3, 1, 2])\n    [3, 1, 2]  # since sorted order is 1,2,3 =&gt; ranks are assigned as per their order\n    &gt;&gt;&gt; min_rank([\"b\", \"a\", \"a\", \"c\"])\n    [2, 1, 1, 4]\n    \"\"\"\n    # Get the indices of the x sorted by their corresponding elements\n    indices = sorted(range(len(x)), key=lambda i: x[i])\n    ranks = [None] * len(x)\n\n    current_rank = 1\n    i = 0\n    n = len(x)\n\n    # Iterate through sorted x and assign ranks\n    while i &lt; n:\n        val = x[indices[i]]\n        # Find how many times this value is repeated\n        j = i\n        while j &lt; n and x[indices[j]] == val:\n            j += 1\n\n        # The group from i to j-1 (inclusive) are all the same value\n        count = j - i\n        # Assign the current_rank to all tied elements\n        for k in range(i, j):\n            ranks[indices[k]] = current_rank\n        # Increment the rank by the count of elements in this tie group\n        current_rank += count\n        i = j\n\n    return ranks\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.n","title":"<code>n()</code>","text":"<p>Number of observations in each group</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(count = tp.n())\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def n():\n    \"\"\"\n    Number of observations in each group\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(count = tp.n())\n    \"\"\"\n    return pl.len()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.quantile","title":"<code>quantile(x, quantile=0.5)</code>","text":"<p>Get number of distinct values in a column</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <code>quantile</code> <code>float</code> <p>Quantile to return</p> <code>0.5</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(quantile_x = tp.quantile('x', .25))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def quantile(x, quantile = .5):\n    \"\"\"\n    Get number of distinct values in a column\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    quantile : float\n        Quantile to return\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(quantile_x = tp.quantile('x', .25))\n    \"\"\"\n    x = _col_expr(x)\n    return x.quantile(quantile)\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.scale","title":"<code>scale(x)</code>","text":"<p>Standardize the input by scaling it to a mean of 0 and a standard deviation of 1.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Expr</code> <p>Column to operate on</p> required <p>Returns:</p> Type Description <code>array - like</code> <p>The standardized version of the input data.</p> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def scale(x):\n    \"\"\"\n    Standardize the input by scaling it to a mean of 0 and a standard deviation of 1.\n\n    Parameters\n    ----------\n    x : Expr\n        Column to operate on\n\n    Returns\n    -------\n    array-like\n        The standardized version of the input data.\n    \"\"\"\n    x = _col_expr(x)\n    return (x - x.mean()) / x.std()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.sd","title":"<code>sd(x)</code>","text":"<p>Get column standard deviation</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(sd_x = tp.sd('x'))\n&gt;&gt;&gt; df.summarize(sd_x = tp.sd(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def sd(x):\n    \"\"\"\n    Get column standard deviation\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(sd_x = tp.sd('x'))\n    &gt;&gt;&gt; df.summarize(sd_x = tp.sd(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.std()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.sum","title":"<code>sum(x)</code>","text":"<p>Get column sum</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>(Expr, Series)</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(sum_x = tp.sum('x'))\n&gt;&gt;&gt; df.summarize(sum_x = tp.sum(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def sum(x):\n    \"\"\"\n    Get column sum\n\n    Parameters\n    ----------\n    x : Expr, Series\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(sum_x = tp.sum('x'))\n    &gt;&gt;&gt; df.summarize(sum_x = tp.sum(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.sum()\n</code></pre>"},{"location":"api/#tidypolars4sci.tibble_df.var","title":"<code>var(x)</code>","text":"<p>Get column variance</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Expr</code> <p>Column to operate on</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; df.summarize(sum_x = tp.var('x'))\n&gt;&gt;&gt; df.summarize(sum_x = tp.var(col('x')))\n</code></pre> Source code in <code>tidypolars4sci/stats.py</code> <pre><code>def var(x):\n    \"\"\"\n    Get column variance\n\n    Parameters\n    ----------\n    x : Expr\n        Column to operate on\n\n    Examples\n    --------\n    &gt;&gt;&gt; df.summarize(sum_x = tp.var('x'))\n    &gt;&gt;&gt; df.summarize(sum_x = tp.var(col('x')))\n    \"\"\"\n    x = _col_expr(x)\n    return x.var()\n</code></pre>"},{"location":"comparing/","title":"Comparing","text":""},{"location":"comparing/#mutate","title":"Mutate","text":"tidypolars4sciPolarsPandastidyverse <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre>"},{"location":"releases/","title":"Releases","text":"<p>Check the GitHub page for information about releases.</p>"},{"location":"case-studies/pivot-wide/","title":"Pivot wide","text":""},{"location":"case-studies/pivot-wide/#performance","title":"Performance","text":"<p>Let us use the data set <code>mtcars</code> to create a table in wide format using <code>pivot_wide</code>. Here are the variables</p> <pre><code>import tidypolars4sci as tp\nfrom tidypolars4sci.data import mtcars\n\nmtcars.glimpse()\n</code></pre> <pre><code>Columns matching pattern '.':\n Var Type     Uniq Miss (%) Head                                                       \nname &lt;object&gt;   32    0 0% ['Mazda RX4' 'Mazda RX4 Wag' 'Datsun 710' 'Hornet 4 Drive'\n...\n mpg &lt;float64&gt;  25    0 0% [21.  21.  22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16....\n cyl &lt;int64&gt;     3    0 0% [6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 ...\ndisp &lt;float64&gt;  27    0 0% [160.  160.  108.  258.  360.  225.  360.  146.7 140.8 167....\n  hp &lt;int64&gt;    22    0 0% [110 110  93 110 175 105 245  62  95 123 123 180 180 180 20...\ndrat &lt;float64&gt;  22    0 0% [3.9  3.9  3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 3.92 3.0...\n  wt &lt;float64&gt;  29    0 0% [2.62  2.875 2.32  3.215 3.44  3.46  3.57  3.19  3.15  3.44...\nqsec &lt;float64&gt;  30    0 0% [16.46 17.02 18.61 19.44 17.02 20.22 15.84 20.   22.9  18.3...\n  vs &lt;int64&gt;     2    0 0% [0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 ...\n  am &lt;int64&gt;     2    0 0% [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 ...\ngear &lt;int64&gt;     3    0 0% [4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 ...\ncarb &lt;int64&gt;     6    0 0% [4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 ...\n\n[Rows: 32; Columns 12]\n</code></pre> <p>A simple pivot wide operation:</p> <pre><code>from tidypolars4sci.data import mtcars\n\ntab = (mtcars\n       .select('name', 'am')\n       .pivot_wider(values_from='name', names_from='am')\n       )\nprint(tab)\n</code></pre> <pre><code>shape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1        0      \u2502\n\u2502 str      str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Mazda\u2026   Horne\u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Table below shows summary after 1,000 repetitions comparing the same operation in Pandas, Polars, and tidypolars4sci:</p> <pre><code>shape: (3, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Mpdule           Mean (sec)   SD (sec)   Min (sec)   Max (sec)   How much slower than polars? \u2502\n\u2502 str                     f64        f64         f64         f64   str                          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Polars              0.00042    0.00010     0.00026     0.00099   1.0x (baseline)              \u2502\n\u2502 TidyPolars4sci      0.00079    0.00022     0.00049     0.00199   1.9x                         \u2502\n\u2502 Pandas              0.00227    0.00065     0.00147     0.00544   5.4x                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Here is the summary of the performance:</p> <p></p>"},{"location":"case-studies/pivot-wide/#sintax-comparison","title":"Sintax comparison","text":"tidypolars4sciPandasPolars <pre><code>tab = (df\n       .select(col, 'am')\n       .pivot_wider(values_from=col, names_from='am',\n                    values_fn=tp.element().sort().str.concat(\"; \"))\n       )\n</code></pre> <pre><code>tab=(df\n     .filter(['name', \"am\"])\n     .pivot_table(index=None, values=col, columns=\"am\",\n                  aggfunc=lambda col: \"; \".join(sorted(col))\n                  )\n     )\n</code></pre> <pre><code>tab = (df\n       .select([col, \"am\"])\n       .with_columns(idx=0)\n       .pivot(index='idx', on=\"am\", values=col,\n              aggregate_function=pl.element().sort().str.concat(\"; \")\n              )\n       )\n</code></pre>"},{"location":"case-studies/regression-table/","title":"Regression Table","text":""},{"location":"case-studies/regression-table/#motivating-example","title":"Motivating example","text":"<p>Regression tables with multiple models displayed in the table columns are common in academic publications, and they usually follow the same standard format. The table below is an example from Fournier, Soroka, and Nir (2020) showing the effect of negative and positive televised news reports and political ideology on people's emotional arousal and activation, captured by physiological galvanic skin activity. It is easy to produce this type of table with tidypolars, keeping everything in a tidy format.</p> <p></p>"},{"location":"case-studies/regression-table/#data","title":"Data","text":"<p>The synthetic data <code>vote</code> contains information about Democratic and Republican voters, including demographics and voting behavior:</p> Loading data and modules<pre><code>import tidypolars4sci as tp\nimport tools4sci as t4\nfrom tidypolars4sci.data import vote as df\nimport numpy as np\n# \nfrom statsmodels.formula.api import ols as lm\nfrom statsmodels.formula.api import glm as glm\nfrom statsmodels.api import families as family\n\n# variables:\ndf.__codebook__.print()\n</code></pre> <pre><code>shape: (9, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Variable            Type    Description                                                                                  \u2502\n\u2502 str                 str     str                                                                                          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 age                 int     Age                                                                                          \u2502\n\u2502 income              float   Income (standardized)                                                                        \u2502\n\u2502 gender              int     Gender (Male=0; Female=1)                                                                    \u2502\n\u2502 ideology            float   Ideology self-placement (left=-10 to right=10)                                               \u2502\n\u2502 treatment           int     Treatment group (treated=1; control=0)                                                       \u2502\n\u2502 group               str     Group                                                                                        \u2502\n\u2502 partisanship        str     Partisanship (Democrat or Republican)                                                        \u2502\n\u2502 vote_conservative   int     Voted for the most conservative in-party candidate (Yes=1, No=0)                             \u2502\n\u2502 rate_conservative   float   Voters rate of the most conservative in-party candidate (Dislike=low value; Like=high value) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"case-studies/regression-table/#estimating","title":"Estimating","text":"<p>Here are the functions for the estimation, prediction, and summarizing:</p> Functions for estimation, summary, and prediction<pre><code>def create_formula(outcome, adjusted):\n    if adjusted:\n        # Adjustments are hard-coded here but could have been provided\n        # as arguments for the function instead.\n        adjustments = \"income + age + gender\"\n    else:\n        adjustments = \"1\"\n    formula = f\"{outcome} ~ treatment * ideology + {adjustments}\"\n    return formula\n\ndef estimate(data, model, formula):\n    # need to covert to pandas for statsmodels\n    data = data.to_pandas()\n    if model == 'Linear':\n        res = lm(formula, data=data).fit()\n    else:\n        # logit  model with clustered std. errors by the variable 'group'\n        res = glm(formula, data=data, family=family.Binomial()).fit(cov_type=\"cluster\",\n                                                                    cov_kwds={\"groups\": data[\"group\"]})\n    return res\n\ndef get_summary(fit):\n    res = fit.summary2().tables[1].reset_index(drop=False, names='term')\n    return tp.from_pandas(res)\n\ndef predict(fit, data, at):\n    newdata = t4.simulate.newdata(data, at=at)\n    pred = fit.get_prediction(newdata.to_pandas()).summary_frame(alpha=0.05)\n    return newdata.bind_cols(tp.from_pandas(pred))\n</code></pre> <p>And here is how to run the estimation in tidypolars and produce a table with tidy results (click on the (+) sign to see code comments):</p> Tidy estimation, summary, and prediction<pre><code>res = (df\n       .nest('partisanship') # (1)!\n       .crossing(outcome = ['rate_conservative', \"vote_conservative\"], # (2)!\n                 adjusted = ['Yes', 'No'])\n       .mutate(\n           model = tp.case_when(tp.col(\"outcome\").str.contains('rate'), 'Linear', # (3)!\n                                tp.col(\"outcome\").str.contains('vote'), 'Logit'),\n           formula = tp.map(['outcome', 'adjusted'], lambda row: create_formula(*row))) # (4)!\n       .mutate(\n           fit     = tp.map(['data', 'model', 'formula'], lambda row: estimate(*row)), # (5)!\n           summ    = tp.map([\"fit\"], lambda fit: get_summary(*fit)), # (6)!\n           pred    = tp.map([\"fit\", \"data\"], lambda row: predict(*row,\n                                                                 at={'treatment':[0, 1],\n                                                                     'ideology':range(-10, 10)}))  # (7)!\n       )\n       )\n</code></pre> <ol> <li>Nest the data by partisanship.</li> <li><code>crossing()</code> expands (replicates) each row of the nested data for     different outcomes and an indicator of whether the model uses     adjustment variables.</li> <li>This variable indicates which model is estimated depending on the     outcome variable: <code>rate_conservative</code> (continuous) uses a linear     model; <code>vote_conservative</code> (binary) uses a logit model.</li> <li>The function <code>map()</code> performs a row-wise operation, creating the     regression formula depending on the outcome and whether the     estimation is adjusted; the star (*) used in <code>*row</code> unpacks the     columns for the function <code>create_formula()</code>.</li> <li>Fit the models in each row.</li> <li>Create a tidy summary (tibble) for each estimated model in the rows.</li> <li>Create tables (tibbles) with predicted values at specified values of     the predictors <code>treatment</code> and <code>ideology</code>.</li> </ol> Check the resulting tibble<pre><code>res\n</code></pre> <pre><code>shape: (8, 9)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 parti\u2026   data     outco\u2026   adjus\u2026   model    formu\u2026   fit      summ     pred   \u2502\n\u2502 str      object   str      str      str      str      object   object   object \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 repub\u2026   shape\u2026   rate_\u2026   Yes      Linea\u2026   rate_\u2026   &lt;stat\u2026   shape\u2026   shape\u2026 \u2502\n\u2502 repub\u2026   shape\u2026   rate_\u2026   No       Linea\u2026   rate_\u2026   &lt;stat\u2026   shape\u2026   shape\u2026 \u2502\n\u2502 repub\u2026   shape\u2026   vote_\u2026   Yes      Logit    vote_\u2026   &lt;stat\u2026   shape\u2026   shape\u2026 \u2502\n\u2502 \u2026        \u2026        \u2026        \u2026        \u2026        \u2026        \u2026        \u2026        \u2026      \u2502\n\u2502 democ\u2026   shape\u2026   rate_\u2026   No       Linea\u2026   rate_\u2026   &lt;stat\u2026   shape\u2026   shape\u2026 \u2502\n\u2502 democ\u2026   shape\u2026   vote_\u2026   Yes      Logit    vote_\u2026   &lt;stat\u2026   shape\u2026   shape\u2026 \u2502\n\u2502 democ\u2026   shape\u2026   vote_\u2026   No       Logit    vote_\u2026   &lt;stat\u2026   shape\u2026   shape\u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"case-studies/regression-table/#summarizing","title":"Summarizing","text":""},{"location":"case-studies/regression-table/#single-model","title":"Single model","text":"<p>Let us see <code>statmmodel</code> summary the results for a particular model:</p> <pre><code>pty = 'democrat'\nmodel = 'Logit'\nadjusted = 'Yes'\ntab = (res\n       .filter(tp.col(\"partisanship\")==pty)\n       .filter(tp.col(\"model\")==model)\n       .filter(tp.col(\"adjusted\")==adjusted)\n       .pull('fit')\n       )\n\n# result of the first model estimated\ntab[0].summary()\n</code></pre> <pre><code>                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      vote_conservative   No. Observations:                 1017\nModel:                            GLM   Df Residuals:                     1010\nModel Family:                Binomial   Df Model:                            6\nLink Function:                  Logit   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -512.79\nDate:                Thu, 06 Mar 2025   Deviance:                       1025.6\nTime:                        18:07:44   Pearson chi2:                 1.02e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.2843\nCovariance Type:              cluster                                         \n======================================================================================\n                         coef    std err          z      P&gt;|z|      [0.025      0.975]\n--------------------------------------------------------------------------------------\nIntercept             -0.1600      0.159     -1.008      0.314      -0.471       0.151\ntreatment             -0.4336      0.092     -4.724      0.000      -0.613      -0.254\nideology              -0.0805      0.031     -2.562      0.010      -0.142      -0.019\ntreatment:ideology    -0.2886      0.043     -6.765      0.000      -0.372      -0.205\nincome                -0.0467      0.064     -0.731      0.465      -0.172       0.079\nage                    0.0200      0.005      3.972      0.000       0.010       0.030\ngender                -0.1203      0.124     -0.967      0.333      -0.364       0.123\n======================================================================================\n</code></pre> <p>Here is the tidy summary:</p> <pre><code>shape: (7, 7)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 term                 Coef.   Std.Err.       z   P&gt;|z|   [0.025   0.975] \u2502\n\u2502 str                    f64        f64     f64     f64      f64      f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Intercept            -0.16       0.16   -1.01    0.31    -0.47     0.15 \u2502\n\u2502 treatment            -0.43       0.09   -4.72    0.00    -0.61    -0.25 \u2502\n\u2502 ideology             -0.08       0.03   -2.56    0.01    -0.14    -0.02 \u2502\n\u2502 treatment:ideology   -0.29       0.04   -6.76    0.00    -0.37    -0.20 \u2502\n\u2502 income               -0.05       0.06   -0.73    0.46    -0.17     0.08 \u2502\n\u2502 age                   0.02       0.01    3.97    0.00     0.01     0.03 \u2502\n\u2502 gender               -0.12       0.12   -0.97    0.33    -0.36     0.12 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"case-studies/regression-table/#multiple-models","title":"Multiple models","text":"<p>The goal is to create something like this:</p> <p></p> <p>To create a regression table with different models displayed in the columns, formatted for publication, we can use the function <code>models2tab()</code> from the model <code>tools4sci</code>. One of the outcomes will be a <code>tibble</code> with the models (<code>tab</code>), the other a string with the latex table (<code>tabl</code>). The function uses a dictionary with the estimated models. The keys are the column names. Line breaks with <code>\\n</code> can be used.</p> <pre><code># select the models that will show in the table\nmods = res.filter(tp.col(\"partisanship\")=='democrat')\n\n# prepare the dictionary (keys will be column names)\nmods = {f\"Model {m}\\nAdjusted: {a}\" : fit\n        for m, a, fit in zip(mods.pull('model'),\n                             mods.pull('adjusted'),\n                             mods.pull('fit'))\n        }\nmods\n\n# from the tools4sci module\ntab, tabl = t4.report.models2tab(mods,\n                                 latex=True,\n                                 # we can rename covariates\n                                 covar_labels={\"income\": \"Income (std)\"},\n                                 kws_latex={'caption': \"Example table\",\n                                            'label': \"tab-example\",\n                                            'header':None,\n                                            'align':\"lcccc\",\n                                            'escape':True,\n                                            'longtable':False,\n                                            'rotate':False\n                                            },\n                                 sanitize='partial'\n                                 )\n\n# here is the tidy table (one can save it in xlsx, or csv)\ntab.print()\n</code></pre> <pre><code>shape: (20, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Model Linear    Model Linear   Model Logit     Model Logit  \u2502\n\u2502 str                    Adjusted: Yes   Adjusted: No   Adjusted: Yes   Adjusted: No \u2502\n\u2502                        str             str            str             str          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Intercept              -0.1194         -0.1194        -0.1600         -0.1600      \u2502\n\u2502                        (0.1030)        (0.1030)       (0.1588)        (0.1588)     \u2502\n\u2502 treatment              -0.5137***      -0.5137***     -0.4336***      -0.4336***   \u2502\n\u2502                        (0.0609)        (0.0609)       (0.0918)        (0.0918)     \u2502\n\u2502 ideology               -0.1021***      -0.1021***     -0.0805*        -0.0805*     \u2502\n\u2502                        (0.0074)        (0.0074)       (0.0314)        (0.0314)     \u2502\n\u2502 treatment x ideology   -0.2804***      -0.2804***     -0.2886***      -0.2886***   \u2502\n\u2502                        (0.0104)        (0.0104)       (0.0427)        (0.0427)     \u2502\n\u2502 Income (std)           0.0348          0.0348         -0.0467         -0.0467      \u2502\n\u2502                        (0.0307)        (0.0307)       (0.0639)        (0.0639)     \u2502\n\u2502 age                    0.0234***       0.0234***      0.0200***       0.0200***    \u2502\n\u2502                        (0.0020)        (0.0020)       (0.0050)        (0.0050)     \u2502\n\u2502 gender                 -0.5098***      -0.5098***     -0.1203         -0.1203      \u2502\n\u2502                        (0.0610)        (0.0610)       (0.1244)        (0.1244)     \u2502\n\u2502 N. Obs.                1017            1017           1017            1017         \u2502\n\u2502 R2 (adj)               0.7641          0.7641                                      \u2502\n\u2502 R2 (pseudo)                                           0.2843          0.2843       \u2502\n\u2502 BIC                    2859.2311       2859.2311      -5968.2760      -5968.2760   \u2502\n\u2502 AIC                    2824.7588       2824.7588      1039.5825       1039.5825    \u2502\n\u2502 Std. Error             Classical       Classical      Clustered       Clustered    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>And here is the latex version (note the footnote with p-values; it can be changed using the parameter footnote of the function <code>t4.report.models2tab()</code> of the <code>tools4sci</code> module):</p> <pre><code>\\begin{table}[!htb]\n\\caption{Example table}\n\\label{tab-example}\n\\centering\n\\resizebox{\\ifdim\\width&gt;\\linewidth\\linewidth\\else\\width\\fi}{!}{\n\\begin{tabular}{lcccc}\n\\toprule\n  &amp; \\makecell{Model Linear\\\\Adjusted: Yes} &amp; \\makecell{Model Linear\\\\Adjusted: No} &amp; \\makecell{Model Logit\\\\Adjusted: Yes} &amp; \\makecell{Model Logit\\\\Adjusted: No}\\\\\n\\midrule\nIntercept  &amp;  -0.1194   &amp;  -0.1194   &amp;  -0.1600   &amp;  -0.1600  \\\\\n  &amp;  (0.1030)  &amp;  (0.1030)  &amp;  (0.1588)  &amp;  (0.1588) \\\\\ntreatment  &amp;  -0.5137***  &amp;  -0.5137***  &amp;  -0.4336***  &amp;  -0.4336*** \\\\\n  &amp;  (0.0609)  &amp;  (0.0609)  &amp;  (0.0918)  &amp;  (0.0918) \\\\\nideology  &amp;  -0.1021***  &amp;  -0.1021***  &amp;  -0.0805*  &amp;  -0.0805* \\\\\n  &amp;  (0.0074)  &amp;  (0.0074)  &amp;  (0.0314)  &amp;  (0.0314) \\\\\ntreatment x ideology  &amp;  -0.2804***  &amp;  -0.2804***  &amp;  -0.2886***  &amp;  -0.2886*** \\\\\n  &amp;  (0.0104)  &amp;  (0.0104)  &amp;  (0.0427)  &amp;  (0.0427) \\\\\nIncome (std)  &amp;  0.0348   &amp;  0.0348   &amp;  -0.0467   &amp;  -0.0467  \\\\\n  &amp;  (0.0307)  &amp;  (0.0307)  &amp;  (0.0639)  &amp;  (0.0639) \\\\\nage  &amp;  0.0234***  &amp;  0.0234***  &amp;  0.0200***  &amp;  0.0200*** \\\\\n  &amp;  (0.0020)  &amp;  (0.0020)  &amp;  (0.0050)  &amp;  (0.0050) \\\\\ngender  &amp;  -0.5098***  &amp;  -0.5098***  &amp;  -0.1203   &amp;  -0.1203  \\\\\n  &amp;  (0.0610)  &amp;  (0.0610)  &amp;  (0.1244)  &amp;  (0.1244) \\\\\nN. Obs.  &amp;  1017  &amp;  1017  &amp;  1017  &amp;  1017 \\\\\nR2 (adj)  &amp;  0.7641  &amp;  0.7641  &amp;    &amp;   \\\\\nR2 (pseudo)  &amp;    &amp;    &amp;  0.2843  &amp;  0.2843 \\\\\nBIC  &amp;  2859.2311  &amp;  2859.2311  &amp;  -5968.2760  &amp;  -5968.2760 \\\\\nAIC  &amp;  2824.7588  &amp;  2824.7588  &amp;  1039.5825  &amp;  1039.5825 \\\\\nStd. Error  &amp;  Classical  &amp;  Classical  &amp;  Clustered  &amp;  Clustered \\\\\n\\bottomrule\n\\multicolumn{5}{r}{+ $p&lt;0.1$; * $p&lt;0.05$; ** $p&lt;0.01$; *** $p&lt;0.001$}\\\\\n\\end{tabular}}\n\\end{table}\n</code></pre>"},{"location":"case-studies/regression-table/#bonus","title":"Bonus","text":""},{"location":"case-studies/regression-table/#grouping-rows","title":"Grouping rows","text":"<p>We can group the rows in the table by post-processing the <code>tibble</code> outcome from the <code>models2tab()</code> function using tidypolars function <code>to_latex()</code>. Something like this:</p> <p></p> <p>We need to create a column indicating the row group:</p> <pre><code>tab_rows_grouped = tab.mutate(groups = np.array(['Baseline']*2 +\n                                                ['Core effects']*6 + \n                                                ['Demographics']*6 +\n                                                ['Fit statistics']*6\n                                                )\n                              )\ntab_rows_grouped.print()\n</code></pre> <pre><code>shape: (20, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Model Linear    Model Linear   Model Logit     Model Logit    groups         \u2502\n\u2502 str                    Adjusted: Yes   Adjusted: No   Adjusted: Yes   Adjusted: No   str            \u2502\n\u2502                        str             str            str             str                           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Intercept              -0.1194         -0.1194        -0.1600         -0.1600        Baseline       \u2502\n\u2502                        (0.1030)        (0.1030)       (0.1588)        (0.1588)       Baseline       \u2502\n\u2502 treatment              -0.5137***      -0.5137***     -0.4336***      -0.4336***     Core effects   \u2502\n\u2502                        (0.0609)        (0.0609)       (0.0918)        (0.0918)       Core effects   \u2502\n\u2502 ideology               -0.1021***      -0.1021***     -0.0805*        -0.0805*       Core effects   \u2502\n\u2502                        (0.0074)        (0.0074)       (0.0314)        (0.0314)       Core effects   \u2502\n\u2502 treatment x ideology   -0.2804***      -0.2804***     -0.2886***      -0.2886***     Core effects   \u2502\n\u2502                        (0.0104)        (0.0104)       (0.0427)        (0.0427)       Core effects   \u2502\n\u2502 Income (std)           0.0348          0.0348         -0.0467         -0.0467        Demographics   \u2502\n\u2502                        (0.0307)        (0.0307)       (0.0639)        (0.0639)       Demographics   \u2502\n\u2502 age                    0.0234***       0.0234***      0.0200***       0.0200***      Demographics   \u2502\n\u2502                        (0.0020)        (0.0020)       (0.0050)        (0.0050)       Demographics   \u2502\n\u2502 gender                 -0.5098***      -0.5098***     -0.1203         -0.1203        Demographics   \u2502\n\u2502                        (0.0610)        (0.0610)       (0.1244)        (0.1244)       Demographics   \u2502\n\u2502 N. Obs.                1017            1017           1017            1017           Fit statistics \u2502\n\u2502 R2 (adj)               0.7641          0.7641                                        Fit statistics \u2502\n\u2502 R2 (pseudo)                                           0.2843          0.2843         Fit statistics \u2502\n\u2502 BIC                    2859.2311       2859.2311      -5968.2760      -5968.2760     Fit statistics \u2502\n\u2502 AIC                    2824.7588       2824.7588      1039.5825       1039.5825      Fit statistics \u2502\n\u2502 Std. Error             Classical       Classical      Clustered       Clustered      Fit statistics \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Then, we apply the <code>to_latex()</code> function:</p> <pre><code>tabl = tab_rows_grouped.to_latex(group_rows_by='groups')\nprint(tabl)\n</code></pre> <pre><code>\\begin{table}[!htb]\n\\centering\n\\resizebox{\\ifdim\\width&gt;\\linewidth\\linewidth\\else\\width\\fi}{!}{\n\\begin{tabular}{lllll}\n\\toprule\n  &amp; \\makecell{Model Linear\\\\Adjusted: Yes} &amp; \\makecell{Model Linear\\\\Adjusted: No} &amp; \\makecell{Model Logit\\\\Adjusted: Yes} &amp; \\makecell{Model Logit\\\\Adjusted: No}\\\\\n\\midrule\n\\addlinespace[0.3em]\\multicolumn{5}{l}{ \\textbf{Baseline} }\\\\\n\\hspace{1em}Intercept  &amp;  -0.1194   &amp;  -0.1194   &amp;  -0.1600   &amp;  -0.1600  \\\\\n\\hspace{1em}  &amp;  (0.1030)  &amp;  (0.1030)  &amp;  (0.1588)  &amp;  (0.1588) \\\\\n\\addlinespace[0.3em]\\multicolumn{5}{l}{ \\textbf{Core effects} }\\\\\n\\hspace{1em}treatment  &amp;  -0.5137***  &amp;  -0.5137***  &amp;  -0.4336***  &amp;  -0.4336*** \\\\\n\\hspace{1em}  &amp;  (0.0609)  &amp;  (0.0609)  &amp;  (0.0918)  &amp;  (0.0918) \\\\\n\\hspace{1em}ideology  &amp;  -0.1021***  &amp;  -0.1021***  &amp;  -0.0805*  &amp;  -0.0805* \\\\\n\\hspace{1em}  &amp;  (0.0074)  &amp;  (0.0074)  &amp;  (0.0314)  &amp;  (0.0314) \\\\\n\\hspace{1em}treatment x ideology  &amp;  -0.2804***  &amp;  -0.2804***  &amp;  -0.2886***  &amp;  -0.2886*** \\\\\n\\hspace{1em}  &amp;  (0.0104)  &amp;  (0.0104)  &amp;  (0.0427)  &amp;  (0.0427) \\\\\n\\addlinespace[0.3em]\\multicolumn{5}{l}{ \\textbf{Demographics} }\\\\\n\\hspace{1em}Income (std)  &amp;  0.0348   &amp;  0.0348   &amp;  -0.0467   &amp;  -0.0467  \\\\\n\\hspace{1em}  &amp;  (0.0307)  &amp;  (0.0307)  &amp;  (0.0639)  &amp;  (0.0639) \\\\\n\\hspace{1em}age  &amp;  0.0234***  &amp;  0.0234***  &amp;  0.0200***  &amp;  0.0200*** \\\\\n\\hspace{1em}  &amp;  (0.0020)  &amp;  (0.0020)  &amp;  (0.0050)  &amp;  (0.0050) \\\\\n\\hspace{1em}gender  &amp;  -0.5098***  &amp;  -0.5098***  &amp;  -0.1203   &amp;  -0.1203  \\\\\n\\hspace{1em}  &amp;  (0.0610)  &amp;  (0.0610)  &amp;  (0.1244)  &amp;  (0.1244) \\\\\n\\addlinespace[0.3em]\\multicolumn{5}{l}{ \\textbf{Fit statistics} }\\\\\n\\hspace{1em}N. Obs.  &amp;  1017  &amp;  1017  &amp;  1017  &amp;  1017 \\\\\n\\hspace{1em}R2 (adj)  &amp;  0.7641  &amp;  0.7641  &amp;    &amp;   \\\\\n\\hspace{1em}R2 (pseudo)  &amp;    &amp;    &amp;  0.2843  &amp;  0.2843 \\\\\n\\hspace{1em}BIC  &amp;  2859.2311  &amp;  2859.2311  &amp;  -5968.2760  &amp;  -5968.2760 \\\\\n\\hspace{1em}AIC  &amp;  2824.7588  &amp;  2824.7588  &amp;  1039.5825  &amp;  1039.5825 \\\\\n\\hspace{1em}Std. Error  &amp;  Classical  &amp;  Classical  &amp;  Clustered  &amp;  Clustered \\\\\n\\bottomrule\n\\end{tabular}}\n\\end{table}\n</code></pre>"},{"location":"case-studies/regression-table/#grouping-columns","title":"Grouping columns","text":"<p>We can also group columns instead, producing something like this:</p> <p></p> <p>We need to post-process the <code>tibble</code> outcome from the <code>models2tab()</code> function using tidypolars function <code>to_latex()</code>. The code:</p> <pre><code>caption = \"A regression table\"\nlabel = 'tab-regression'\nheader = [('', ''),\n          ('Linear Models', 'Adjusted: Yes'),\n          ('Linear Models', 'Adjusted: No'),\n          ('Logit Models', 'Adjusted: Yes'),\n          ('Logit Models', 'Adjusted: No'),\n          ]\ntabl = tab.to_latex(caption = caption,\n                    label = label,\n                    header = header,\n                    align = 'lcccc',\n                    footnotes = None)\nprint(tabl)\n</code></pre> <pre><code>\\begin{table}[!htb]\n\\caption{A regression table}\n\\label{tab-regression}\n\\centering\n\\resizebox{\\ifdim\\width&gt;\\linewidth\\linewidth\\else\\width\\fi}{!}{\n\\begin{tabular}{lcccc}\n\\toprule\n  &amp;  \\multicolumn{2}{c}{Linear Models}  &amp;  \\multicolumn{2}{c}{Logit Models} \\\\\n\\cmidrule(lr){2-3} \\cmidrule(lr){4-5}\n  &amp;  Adjusted: Yes  &amp;  Adjusted: No  &amp;  Adjusted: Yes  &amp;  Adjusted: No \\\\\n\\midrule\nIntercept  &amp;  -0.1194   &amp;  -0.1194   &amp;  -0.1600   &amp;  -0.1600  \\\\\n  &amp;  (0.1030)  &amp;  (0.1030)  &amp;  (0.1588)  &amp;  (0.1588) \\\\\ntreatment  &amp;  -0.5137***  &amp;  -0.5137***  &amp;  -0.4336***  &amp;  -0.4336*** \\\\\n  &amp;  (0.0609)  &amp;  (0.0609)  &amp;  (0.0918)  &amp;  (0.0918) \\\\\nideology  &amp;  -0.1021***  &amp;  -0.1021***  &amp;  -0.0805*  &amp;  -0.0805* \\\\\n  &amp;  (0.0074)  &amp;  (0.0074)  &amp;  (0.0314)  &amp;  (0.0314) \\\\\ntreatment x ideology  &amp;  -0.2804***  &amp;  -0.2804***  &amp;  -0.2886***  &amp;  -0.2886*** \\\\\n  &amp;  (0.0104)  &amp;  (0.0104)  &amp;  (0.0427)  &amp;  (0.0427) \\\\\nIncome (std)  &amp;  0.0348   &amp;  0.0348   &amp;  -0.0467   &amp;  -0.0467  \\\\\n  &amp;  (0.0307)  &amp;  (0.0307)  &amp;  (0.0639)  &amp;  (0.0639) \\\\\nage  &amp;  0.0234***  &amp;  0.0234***  &amp;  0.0200***  &amp;  0.0200*** \\\\\n  &amp;  (0.0020)  &amp;  (0.0020)  &amp;  (0.0050)  &amp;  (0.0050) \\\\\ngender  &amp;  -0.5098***  &amp;  -0.5098***  &amp;  -0.1203   &amp;  -0.1203  \\\\\n  &amp;  (0.0610)  &amp;  (0.0610)  &amp;  (0.1244)  &amp;  (0.1244) \\\\\nN. Obs.  &amp;  1017  &amp;  1017  &amp;  1017  &amp;  1017 \\\\\nR2 (adj)  &amp;  0.7641  &amp;  0.7641  &amp;    &amp;   \\\\\nR2 (pseudo)  &amp;    &amp;    &amp;  0.2843  &amp;  0.2843 \\\\\nBIC  &amp;  2859.2311  &amp;  2859.2311  &amp;  -5968.2760  &amp;  -5968.2760 \\\\\nAIC  &amp;  2824.7588  &amp;  2824.7588  &amp;  1039.5825  &amp;  1039.5825 \\\\\nStd. Error  &amp;  Classical  &amp;  Classical  &amp;  Clustered  &amp;  Clustered \\\\\n\\bottomrule\n\\end{tabular}}\n\\end{table}\n</code></pre>"},{"location":"case-studies/regression-table/#plotting-coefficients","title":"Plotting coefficients","text":"<p>The tidy format facilitates plotting the model coefficients. One can use the <code>unnest()</code> function. Here is the code:</p> <pre><code>model = 'Linear'\nadjusted = 'Yes'\ntab = (res\n       .filter(tp.col(\"model\")==model)\n       .filter(tp.col(\"adjusted\")==adjusted)\n       .select('partisanship', 'summ')\n       .unnest('summ')\n       #\n       .filter(~tp.col(\"term\").str.contains('Intercept'))\n       )\ntab.print()\n</code></pre> <pre><code>shape: (12, 8)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 partisanship   term                 Coef.   Std.Err.        t   P&gt;|t|   [0.025   0.975] \u2502\n\u2502 str            str                    f64        f64      f64     f64      f64      f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 republican     treatment            -0.55       0.07    -8.35    0.00    -0.67    -0.42 \u2502\n\u2502 republican     ideology             -0.12       0.01   -14.41    0.00    -0.13    -0.10 \u2502\n\u2502 republican     treatment:ideology   -0.29       0.01   -25.66    0.00    -0.31    -0.27 \u2502\n\u2502 republican     income               -0.01       0.03    -0.25    0.81    -0.07     0.06 \u2502\n\u2502 republican     age                   0.02       0.00     7.81    0.00     0.01     0.02 \u2502\n\u2502 republican     gender               -0.44       0.07    -6.76    0.00    -0.57    -0.31 \u2502\n\u2502 democrat       treatment            -0.51       0.06    -8.44    0.00    -0.63    -0.39 \u2502\n\u2502 democrat       ideology             -0.10       0.01   -13.86    0.00    -0.12    -0.09 \u2502\n\u2502 democrat       treatment:ideology   -0.28       0.01   -27.00    0.00    -0.30    -0.26 \u2502\n\u2502 democrat       income                0.03       0.03     1.13    0.26    -0.03     0.10 \u2502\n\u2502 democrat       age                   0.02       0.00    11.58    0.00     0.02     0.03 \u2502\n\u2502 democrat       gender               -0.51       0.06    -8.36    0.00    -0.63    -0.39 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Here is an example of a possible plot using Altair:</p> <p>{   \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\",   \"config\": {     \"view\": {       \"continuousHeight\": 300,       \"continuousWidth\": 300     }   },   \"data\": {     \"name\": \"data-f99985beb9b1bd22f3c5069d5033afdc\"   },   \"datasets\": {     \"data-f99985beb9b1bd22f3c5069d5033afdc\": [       {         \"Coef.\": -0.5453875271227993,         \"P&gt;|t|\": 2.325085825422768e-16,         \"Std.Err.\": 0.0653182412692631,         \"hi\": -0.41720717008879227,         \"lo\": -0.6735678841568062,         \"partisanship\": \"republican\",         \"t\": -8.34969706049699,         \"term\": \"treatment\"       },       {         \"Coef.\": -0.11672998920234258,         \"P&gt;|t|\": 8.055899574345312e-43,         \"Std.Err.\": 0.008101084204688823,         \"hi\": -0.10083244135749256,         \"lo\": -0.1326275370471926,         \"partisanship\": \"republican\",         \"t\": -14.40918107415554,         \"term\": \"ideology\"       },       {         \"Coef.\": -0.28807694912332255,         \"P&gt;|t|\": 2.272577821261762e-111,         \"Std.Err.\": 0.011228310093157067,         \"hi\": -0.2660425408376438,         \"lo\": -0.3101113574090013,         \"partisanship\": \"republican\",         \"t\": -25.656305065789635,         \"term\": \"treatment:ideology\"       },       {         \"Coef.\": -0.008017956121100761,         \"P&gt;|t|\": 0.8064667941681202,         \"Std.Err.\": 0.03271925395417075,         \"hi\": 0.05619022787520521,         \"lo\": -0.07222614011740673,         \"partisanship\": \"republican\",         \"t\": -0.24505314614848378,         \"term\": \"income\"       },       {         \"Coef.\": 0.016927139267716683,         \"P&gt;|t|\": 1.4553886048999363e-14,         \"Std.Err.\": 0.0021669566636691516,         \"hi\": 0.021179569728624375,         \"lo\": 0.012674708806808991,         \"partisanship\": \"republican\",         \"t\": 7.8114802900835025,         \"term\": \"age\"       },       {         \"Coef.\": -0.4402524009430397,         \"P&gt;|t|\": 2.305992236730476e-11,         \"Std.Err.\": 0.06508529343308622,         \"hi\": -0.3125291801734395,         \"lo\": -0.5679756217126399,         \"partisanship\": \"republican\",         \"t\": -6.76423778277439,         \"term\": \"gender\"       },       {         \"Coef.\": -0.5137398145136601,         \"P&gt;|t|\": 1.1192712446663049e-16,         \"Std.Err.\": 0.06089376892077548,         \"hi\": -0.3942470256354935,         \"lo\": -0.6332326033918267,         \"partisanship\": \"democrat\",         \"t\": -8.436656551543889,         \"term\": \"treatment\"       },       {         \"Coef.\": -0.10214590800016095,         \"P&gt;|t|\": 3.927130599200094e-40,         \"Std.Err.\": 0.007368376775750375,         \"hi\": -0.08768682776840457,         \"lo\": -0.11660498823191733,         \"partisanship\": \"democrat\",         \"t\": -13.86274224417069,         \"term\": \"ideology\"       },       {         \"Coef.\": -0.28039095958730786,         \"P&gt;|t|\": 2.7074723158659304e-121,         \"Std.Err.\": 0.01038562273952341,         \"hi\": -0.2600110907209754,         \"lo\": -0.30077082845364034,         \"partisanship\": \"democrat\",         \"t\": -26.997991995246963,         \"term\": \"treatment:ideology\"       },       {         \"Coef.\": 0.03480719155804167,         \"P&gt;|t|\": 0.25698551718272933,         \"Std.Err.\": 0.030689129988868705,         \"hi\": 0.09502894816150531,         \"lo\": -0.025414565045421965,         \"partisanship\": \"democrat\",         \"t\": 1.1341863249517543,         \"term\": \"income\"       },       {         \"Coef.\": 0.023373717983439,         \"P&gt;|t|\": 3.485716259235037e-29,         \"Std.Err.\": 0.0020192981495198376,         \"hi\": 0.027336218116688654,         \"lo\": 0.019411217850189344,         \"partisanship\": \"democrat\",         \"t\": 11.575169317615114,         \"term\": \"age\"       },       {         \"Coef.\": -0.509783493509636,         \"P&gt;|t|\": 2.0683016060635783e-16,         \"Std.Err.\": 0.06098256476278831,         \"hi\": -0.39011645917103976,         \"lo\": -0.6294505278482323,         \"partisanship\": \"democrat\",         \"t\": -8.35949579183175,         \"term\": \"gender\"       }     ]   },   \"height\": 450,   \"layer\": [     {       \"encoding\": {         \"color\": {           \"field\": \"partisanship\",           \"type\": \"nominal\"         },         \"fill\": {           \"field\": \"partisanship\",           \"type\": \"nominal\"         },         \"x\": {           \"field\": \"lo\",           \"title\": \"Estimate\",           \"type\": \"quantitative\"         },         \"x2\": {           \"field\": \"hi\"         },         \"y\": {           \"field\": \"term\",           \"title\": \"Variables\",           \"type\": \"nominal\"         },         \"yOffset\": {           \"field\": \"partisanship\",           \"type\": \"nominal\"         }       },       \"mark\": {         \"thickness\": 1.2,         \"type\": \"errorbar\"       },       \"name\": \"view_21\"     },     {       \"encoding\": {         \"color\": {           \"field\": \"partisanship\",           \"type\": \"nominal\"         },         \"fill\": {           \"field\": \"partisanship\",           \"title\": \"Partisanship\",           \"type\": \"nominal\"         },         \"x\": {           \"field\": \"Coef\\\\.\",           \"title\": \"Estimate\",           \"type\": \"quantitative\"         },         \"y\": {           \"field\": \"term\",           \"scale\": {             \"padding\": 0.6           },           \"title\": \"Variables\",           \"type\": \"nominal\"         },         \"yOffset\": {           \"field\": \"partisanship\",           \"type\": \"nominal\"         }       },       \"mark\": {         \"type\": \"point\"       }     }   ],   \"params\": [     {       \"bind\": \"scales\",       \"name\": \"param_20\",       \"select\": {         \"encodings\": [           \"x\",           \"y\"         ],         \"type\": \"interval\"       },       \"views\": [         \"view_21\"       ]     }   ],   \"width\": 600 }</p>"},{"location":"case-studies/regression-table/#plotting-fitted-line","title":"Plotting fitted line","text":"<p>The tidy format facilitates plotting the model prediction or fitted values. One can use the <code>unnest()</code> function. Here is the code:</p> <pre><code>model = 'Linear'\nadjusted = 'Yes'\ntab = (res\n       .filter(tp.col(\"model\")==model)\n       .filter(tp.col(\"adjusted\")==adjusted)\n       .select('partisanship', \"pred\")\n       .unnest(\"pred\")\n       )\ntab.head().print()\n</code></pre> <pre><code>shape: (5, 15)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 partisanship     age   income   gender   ideology   treatment   group   vote_conservative   rate_conservative   mean   mean_se   mean_ci_lower   mean_ci_upper   obs_ci_lower   obs_ci_upper \u2502\n\u2502 str              f64      f64      f64        i64         i64   str                   f64                 f64    f64       f64             f64             f64            f64            f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 republican     43.92    -0.04     0.49        -10           0   a                    0.59                0.46   1.81      0.09            1.64            1.98          -0.19           3.82 \u2502\n\u2502 republican     43.92    -0.04     0.49         -9           0   a                    0.59                0.46   1.70      0.08            1.54            1.85          -0.31           3.70 \u2502\n\u2502 republican     43.92    -0.04     0.49         -8           0   a                    0.59                0.46   1.58      0.07            1.43            1.73          -0.42           3.58 \u2502\n\u2502 republican     43.92    -0.04     0.49         -7           0   a                    0.59                0.46   1.46      0.07            1.33            1.60          -0.54           3.46 \u2502\n\u2502 republican     43.92    -0.04     0.49         -6           0   a                    0.59                0.46   1.35      0.06            1.22            1.47          -0.66           3.35 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The plot with predicted values:</p> <p>{   \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\",   \"columns\": 2,   \"config\": {     \"view\": {       \"continuousHeight\": 300,       \"continuousWidth\": 300     }   },   \"data\": {     \"name\": \"data-30a612b71a3f202810f71efbf3c941e1\"   },   \"datasets\": {     \"data-30a612b71a3f202810f71efbf3c941e1\": [       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -10,         \"income\": -0.03684137270467414,         \"mean\": 1.8128005685567476,         \"mean_ci_lower\": 1.6406086589712454,         \"mean_ci_upper\": 1.9849924781422499,         \"mean_se\": 0.08774568081392536,         \"obs_ci_lower\": -0.19202807366847408,         \"obs_ci_upper\": 3.8176292107819694,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -9,         \"income\": -0.03684137270467414,         \"mean\": 1.696070579354405,         \"mean_ci_lower\": 1.5371802277454272,         \"mean_ci_upper\": 1.854960930963383,         \"mean_se\": 0.08096746304895855,         \"obs_ci_lower\": -0.30765943609037727,         \"obs_ci_upper\": 3.6998005947991874,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -8,         \"income\": -0.03684137270467414,         \"mean\": 1.5793405901520623,         \"mean_ci_lower\": 1.433232075694122,         \"mean_ci_upper\": 1.7254491046100027,         \"mean_se\": 0.07445408500715446,         \"obs_ci_lower\": -0.42341639184975555,         \"obs_ci_upper\": 3.58209757215388,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -7,         \"income\": -0.03684137270467414,         \"mean\": 1.4626106009497197,         \"mean_ci_lower\": 1.3286153912788279,         \"mean_ci_upper\": 1.5966058106206116,         \"mean_se\": 0.06828137818251484,         \"obs_ci_lower\": -0.5392991240815241,         \"obs_ci_upper\": 3.4645203259809634,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -6,         \"income\": -0.03684137270467414,         \"mean\": 1.3458806117473772,         \"mean_ci_lower\": 1.2231320944962716,         \"mean_ci_upper\": 1.4686291289984827,         \"mean_se\": 0.062550280329808,         \"obs_ci_lower\": -0.6553077925382536,         \"obs_ci_upper\": 3.347069016033008,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -5,         \"income\": -0.03684137270467414,         \"mean\": 1.2291506225450346,         \"mean_ci_lower\": 1.116522274359943,         \"mean_ci_upper\": 1.3417789707301262,         \"mean_se\": 0.057393237082032894,         \"obs_ci_lower\": -0.7714425334401664,         \"obs_ci_upper\": 3.229743778530236,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -4,         \"income\": -0.03684137270467414,         \"mean\": 1.112420633342692,         \"mean_ci_lower\": 1.0084564318240055,         \"mean_ci_upper\": 1.2163848348613786,         \"mean_se\": 0.05297815480699775,         \"obs_ci_lower\": -0.8877034593468947,         \"obs_ci_upper\": 3.1125447260322785,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -3,         \"income\": -0.03684137270467414,         \"mean\": 0.9956906441403495,         \"mean_ci_lower\": 0.8985442101610595,         \"mean_ci_upper\": 1.0928370781196395,         \"mean_se\": 0.04950395177495351,         \"obs_ci_lower\": -1.0040906590512813,         \"obs_ci_upper\": 2.99547194733198,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -2,         \"income\": -0.03684137270467414,         \"mean\": 0.8789606549380069,         \"mean_ci_lower\": 0.7863768111674785,         \"mean_ci_upper\": 0.9715444987085353,         \"mean_se\": 0.04717894367726501,         \"obs_ci_lower\": -1.1206041974954541,         \"obs_ci_upper\": 2.878525507371468,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -1,         \"income\": -0.03684137270467414,         \"mean\": 0.7622306657356643,         \"mean_ci_lower\": 0.6716129485126111,         \"mean_ci_upper\": 0.8528483829587176,         \"mean_se\": 0.046177043455066284,         \"obs_ci_lower\": -1.2372441157093634,         \"obs_ci_upper\": 2.761705447180692,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 0,         \"income\": -0.03684137270467414,         \"mean\": 0.6455006765333217,         \"mean_ci_lower\": 0.5540849378606648,         \"mean_ci_upper\": 0.7369164152059785,         \"mean_se\": 0.04658369981637929,         \"obs_ci_lower\": -1.3540104307719094,         \"obs_ci_upper\": 2.645011783838553,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 1,         \"income\": -0.03684137270467414,         \"mean\": 0.5287706873309791,         \"mean_ci_lower\": 0.4338624793910105,         \"mean_ci_upper\": 0.6236788952709477,         \"mean_se\": 0.04836339489217966,         \"obs_ci_lower\": -1.470903135794758,         \"obs_ci_upper\": 2.528444510456716,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 2,         \"income\": -0.03684137270467414,         \"mean\": 0.41204069812863653,         \"mean_ci_lower\": 0.3112252099998588,         \"mean_ci_upper\": 0.5128561862574142,         \"mean_se\": 0.05137363110579394,         \"obs_ci_lower\": -1.5879221999288666,         \"obs_ci_upper\": 2.4120035961861395,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 3,         \"income\": -0.03684137270467414,         \"mean\": 0.29531070892629396,         \"mean_ci_lower\": 0.1865659554258619,         \"mean_ci_upper\": 0.404055462426726,         \"mean_se\": 0.05541423202638838,         \"obs_ci_lower\": -1.7050675683937215,         \"obs_ci_upper\": 2.2956889862463092,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 4,         \"income\": -0.03684137270467414,         \"mean\": 0.1785807197239514,         \"mean_ci_lower\": 0.06029063461089412,         \"mean_ci_upper\": 0.2968708048370087,         \"mean_se\": 0.06027834917893433,         \"obs_ci_lower\": -1.8223391625292034,         \"obs_ci_upper\": 2.179500601977106,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 5,         \"income\": -0.03684137270467414,         \"mean\": 0.06185073052160878,         \"mean_ci_lower\": -0.06724276704196924,         \"mean_ci_upper\": 0.1909442280851868,         \"mean_se\": 0.0657835600966045,         \"obs_ci_lower\": -1.939736879869983,         \"obs_ci_upper\": 2.0634383409132004,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 6,         \"income\": -0.03684137270467414,         \"mean\": -0.054879258680733844,         \"mean_ci_lower\": -0.1957450886229143,         \"mean_ci_upper\": 0.0859865712614466,         \"mean_se\": 0.07178251394881997,         \"obs_ci_lower\": -2.0572605942422753,         \"obs_ci_upper\": 1.9475020768808076,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 7,         \"income\": -0.03684137270467414,         \"mean\": -0.1716092478830764,         \"mean_ci_lower\": -0.3249933964524761,         \"mean_ci_upper\": -0.018225099313676718,         \"mean_se\": 0.07816160802609176,         \"obs_ci_lower\": -2.1749101558827415,         \"obs_ci_upper\": 1.8316916601165887,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 8,         \"income\": -0.03684137270467414,         \"mean\": -0.288339237085419,         \"mean_ci_lower\": -0.4548194943965448,         \"mean_ci_upper\": -0.12185897977429319,         \"mean_se\": 0.08483513281783207,         \"obs_ci_lower\": -2.2926853915792735,         \"obs_ci_upper\": 1.7160069174084356,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 9,         \"income\": -0.03684137270467414,         \"mean\": -0.40506922628776165,         \"mean_ci_lower\": -0.5850973329026905,         \"mean_ci_upper\": -0.22504111967283277,         \"mean_se\": 0.09173885589975994,         \"obs_ci_lower\": -2.41058610483336,         \"obs_ci_upper\": 1.600447652257837,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 0,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -10,         \"income\": -0.03684137270467414,         \"mean\": 4.148182532667174,         \"mean_ci_lower\": 3.97405325632586,         \"mean_ci_upper\": 4.322311809008487,         \"mean_se\": 0.08873292560018821,         \"obs_ci_lower\": 2.14318656363405,         \"obs_ci_upper\": 6.153178501700298,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -9,         \"income\": -0.03684137270467414,         \"mean\": 3.743375594341509,         \"mean_ci_lower\": 3.582097924514253,         \"mean_ci_upper\": 3.904653264168765,         \"mean_se\": 0.08218399443470457,         \"obs_ci_lower\": 1.739454857948766,         \"obs_ci_upper\": 5.747296330734251,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -8,         \"income\": -0.03684137270467414,         \"mean\": 3.3385686560158434,         \"mean_ci_lower\": 3.189695652472127,         \"mean_ci_upper\": 3.48744165955956,         \"mean_se\": 0.07586281540289729,         \"obs_ci_lower\": 1.335608096707685,         \"obs_ci_upper\": 5.341529215324002,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -7,         \"income\": -0.03684137270467414,         \"mean\": 2.9337617176901785,         \"mean_ci_lower\": 2.796725014297243,         \"mean_ci_upper\": 3.070798421083114,         \"mean_se\": 0.06983126480595979,         \"obs_ci_lower\": 0.9316461143753432,         \"obs_ci_upper\": 4.935877321005014,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -6,         \"income\": -0.03684137270467414,         \"mean\": 2.528954779364513,         \"mean_ci_lower\": 2.403025642692584,         \"mean_ci_upper\": 2.654883916036442,         \"mean_se\": 0.06417106272987524,         \"obs_ci_lower\": 0.5275687650177403,         \"obs_ci_upper\": 4.530340793711286,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -5,         \"income\": -0.03684137270467414,         \"mean\": 2.124147841038848,         \"mean_ci_lower\": 2.0083875743558046,         \"mean_ci_upper\": 2.2399081077218916,         \"mean_se\": 0.05898920242975475,         \"obs_ci_lower\": 0.12337592242782014,         \"obs_ci_upper\": 4.124919759649876,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -4,         \"income\": -0.03684137270467414,         \"mean\": 1.719340902713183,         \"mean_ci_lower\": 1.6125423366386362,         \"mean_ci_upper\": 1.8261394687877297,         \"mean_se\": 0.054422492396536536,         \"obs_ci_lower\": -0.2809325197657302,         \"obs_ci_upper\": 3.7196143251920963,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -3,         \"income\": -0.03684137270467414,         \"mean\": 1.3145339643875178,         \"mean_ci_lower\": 1.2151627885763836,         \"mean_ci_upper\": 1.413905140198652,         \"mean_se\": 0.050637637365294474,         \"obs_ci_lower\": -0.6853566480065729,         \"obs_ci_upper\": 3.3144245767816085,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -2,         \"income\": -0.03684137270467414,         \"mean\": 0.9097270260618526,         \"mean_ci_lower\": 0.8158839126115129,         \"mean_ci_upper\": 1.0035701395121923,         \"mean_se\": 0.047820643253333114,         \"obs_ci_lower\": -1.089896528735894,         \"obs_ci_upper\": 2.9093505808595994,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": -1,         \"income\": -0.03684137270467414,         \"mean\": 0.5049200877361876,         \"mean_ci_lower\": 0.41435722671977915,         \"mean_ci_upper\": 0.595482948752596,         \"mean_se\": 0.04614908978865706,         \"obs_ci_lower\": -1.4945522083348033,         \"obs_ci_upper\": 2.5043923838071787,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 0,         \"income\": -0.03684137270467414,         \"mean\": 0.10011314941052246,         \"mean_ci_lower\": 0.01033600230526345,         \"mean_ci_upper\": 0.1898902965157815,         \"mean_se\": 0.04574870511190462,         \"obs_ci_lower\": -1.8993237130840859,         \"obs_ci_upper\": 2.099550011905131,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 1,         \"income\": -0.03684137270467414,         \"mean\": -0.30469378891514276,         \"mean_ci_lower\": -0.39624401001099446,         \"mean_ci_upper\": -0.21314356781929106,         \"mean_se\": 0.04665222946919021,         \"obs_ci_lower\": -2.3042110491413763,         \"obs_ci_upper\": 1.694823471311091,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 2,         \"income\": -0.03684137270467414,         \"mean\": -0.7095007272408076,         \"mean_ci_lower\": -0.8052407518726058,         \"mean_ci_upper\": -0.6137607026090094,         \"mean_se\": 0.048787272658055415,         \"obs_ci_lower\": -2.7092142025358115,         \"obs_ci_upper\": 1.290212748054196,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 3,         \"income\": -0.03684137270467414,         \"mean\": -1.1143076655664728,         \"mean_ci_lower\": -1.2163569876796223,         \"mean_ci_upper\": -1.0122583434533232,         \"mean_se\": 0.05200236914134205,         \"obs_ci_lower\": -3.114333139180166,         \"obs_ci_upper\": 0.8857178080472203,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 4,         \"income\": -0.03684137270467414,         \"mean\": -1.5191146038921381,         \"mean_ci_lower\": -1.6292289919822847,         \"mean_ci_upper\": -1.4090002158019916,         \"mean_se\": 0.05611217143498244,         \"obs_ci_lower\": -3.5195678049004475,         \"obs_ci_upper\": 0.4813385971161712,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 5,         \"income\": -0.03684137270467414,         \"mean\": -1.923921542217803,         \"mean_ci_lower\": -2.0435020392841703,         \"mean_ci_upper\": -1.8043410451514361,         \"mean_se\": 0.0609359182577961,         \"obs_ci_lower\": -3.924918125482893,         \"obs_ci_upper\": 0.07707504104728669,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 6,         \"income\": -0.03684137270467414,         \"mean\": -2.3287284805434685,         \"mean_ci_lower\": -2.4588707664703318,         \"mean_ci_upper\": -2.198586194616605,         \"mean_se\": 0.06631800244751235,         \"obs_ci_lower\": -4.330384006738272,         \"obs_ci_upper\": -0.32707295434866523,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 7,         \"income\": -0.03684137270467414,         \"mean\": -2.7335354188691334,         \"mean_ci_lower\": -2.875090130508688,         \"mean_ci_upper\": -2.591980707229579,         \"mean_se\": 0.07213355479436179,         \"obs_ci_lower\": -4.7359653345833586,         \"obs_ci_upper\": -0.7311055031549079,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 8,         \"income\": -0.03684137270467414,         \"mean\": -3.1383423571947984,         \"mean_ci_lower\": -3.291970677116301,         \"mean_ci_upper\": -2.984714037273296,         \"mean_se\": 0.07828603304453247,         \"obs_ci_lower\": -5.141661975139431,         \"obs_ci_upper\": -1.1350227392501662,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Republican\",         \"age\": 43.92268565615463,         \"gender\": 0.4872838250254323,         \"group\": \"a\",         \"ideology\": 9,         \"income\": -0.03684137270467414,         \"mean\": -3.5431492955204638,         \"mean_ci_lower\": -3.709368390301742,         \"mean_ci_upper\": -3.3769302007391855,         \"mean_se\": 0.08470204942245235,         \"obs_ci_lower\": -5.547473774847559,         \"obs_ci_upper\": -1.5388248161933684,         \"rate_conservative\": 0.45688877688284546,         \"treatment\": 1,         \"vote_conservative\": 0.5879959308240081       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -10,         \"income\": 0.003231334765282966,         \"mean\": 1.672110275322947,         \"mean_ci_lower\": 1.5034558410540115,         \"mean_ci_upper\": 1.8407647095918827,         \"mean_se\": 0.08594664367828797,         \"obs_ci_lower\": -0.23285150413147848,         \"obs_ci_upper\": 3.5770720547773727,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -9,         \"income\": 0.003231334765282966,         \"mean\": 1.569964367322786,         \"mean_ci_lower\": 1.4136509322606192,         \"mean_ci_upper\": 1.726277802384953,         \"mean_se\": 0.07965764531274938,         \"obs_ci_lower\": -0.333944494194627,         \"obs_ci_upper\": 3.4738732288401994,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -8,         \"income\": 0.003231334765282966,         \"mean\": 1.4678184593226251,         \"mean_ci_lower\": 1.3234522868112275,         \"mean_ci_upper\": 1.6121846318340227,         \"mean_se\": 0.0735692959501435,         \"obs_ci_lower\": -0.43514676756650217,         \"obs_ci_upper\": 3.3707836862117526,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -7,         \"income\": 0.003231334765282966,         \"mean\": 1.3656725513224641,         \"mean_ci_lower\": 1.2327536905368568,         \"mean_ci_upper\": 1.4985914121080715,         \"mean_se\": 0.06773572254760893,         \"obs_ci_lower\": -0.5364584868912918,         \"obs_ci_upper\": 3.26780358953622,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -6,         \"income\": 0.003231334765282966,         \"mean\": 1.2635266433223034,         \"mean_ci_lower\": 1.141414459893321,         \"mean_ci_upper\": 1.3856388267512858,         \"mean_se\": 0.06222861772619046,         \"obs_ci_lower\": -0.6378797962180152,         \"obs_ci_upper\": 3.164933082862622,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -5,         \"income\": 0.003231334765282966,         \"mean\": 1.1613807353221424,         \"mean_ci_lower\": 1.04924921819453,         \"mean_ci_upper\": 1.2735122524497546,         \"mean_se\": 0.057142449823199486,         \"obs_ci_lower\": -0.7394108208767318,         \"obs_ci_upper\": 3.0621722915210166,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -4,         \"income\": 0.003231334765282966,         \"mean\": 1.0592348273219814,         \"mean_ci_lower\": 0.9560180703142973,         \"mean_ci_upper\": 1.1624515843296654,         \"mean_se\": 0.052599469884213004,         \"obs_ci_lower\": -0.8410516673705375,         \"obs_ci_upper\": 2.9595213220145,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -3,         \"income\": 0.003231334765282966,         \"mean\": 0.9570889193218205,         \"mean_ci_lower\": 0.8614225682712902,         \"mean_ci_upper\": 1.0527552703723508,         \"mean_se\": 0.04875176760921007,         \"obs_ci_lower\": -0.942802423283572,         \"obs_ci_upper\": 2.856980261927213,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -2,         \"income\": 0.003231334765282966,         \"mean\": 0.8549430113216595,         \"mean_ci_lower\": 0.7651180007635747,         \"mean_ci_upper\": 0.9447680218797443,         \"mean_se\": 0.04577500858070323,         \"obs_ci_lower\": -1.0446631572052163,         \"obs_ci_upper\": 2.7545491798485355,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -1,         \"income\": 0.003231334765282966,         \"mean\": 0.7527971033214986,         \"mean_ci_lower\": 0.6667555765888009,         \"mean_ci_upper\": 0.8388386300541963,         \"mean_se\": 0.043846937506778254,         \"obs_ci_lower\": -1.1466339186706376,         \"obs_ci_upper\": 2.652228125313635,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 0,         \"income\": 0.003231334765282966,         \"mean\": 0.6506511953213376,         \"mean_ci_lower\": 0.5660587244653345,         \"mean_ci_upper\": 0.7352436661773408,         \"mean_se\": 0.04310849567662989,         \"obs_ci_lower\": -1.2487147381177985,         \"obs_ci_upper\": 2.550017128760474,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 1,         \"income\": 0.003231334765282966,         \"mean\": 0.5485052873211766,         \"mean_ci_lower\": 0.4629088041524698,         \"mean_ci_upper\": 0.6341017704898835,         \"mean_se\": 0.04362014239889128,         \"obs_ci_lower\": -1.3509056268610202,         \"obs_ci_upper\": 2.4479162015033733,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 2,         \"income\": 0.003231334765282966,         \"mean\": 0.44635937932101577,         \"mean_ci_lower\": 0.3573888238631881,         \"mean_ci_upper\": 0.5353299347788435,         \"mean_se\": 0.04533957651893014,         \"obs_ci_lower\": -1.4532065770811493,         \"obs_ci_upper\": 2.3459253357231806,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 3,         \"income\": 0.003231334765282966,         \"mean\": 0.3442134713208548,         \"mean_ci_lower\": 0.2497524129507792,         \"mean_ci_upper\": 0.43867452969093035,         \"mean_se\": 0.04813754800102646,         \"obs_ci_lower\": -1.5556175618323551,         \"obs_ci_upper\": 2.2440445044740644,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 4,         \"income\": 0.003231334765282966,         \"mean\": 0.2420675633206939,         \"mean_ci_lower\": 0.1403416897161287,         \"mean_ci_upper\": 0.3437934369252591,         \"mean_se\": 0.05183971266129052,         \"obs_ci_lower\": -1.6581385350655338,         \"obs_ci_upper\": 2.1422736617069216,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 5,         \"income\": 0.003231334765282966,         \"mean\": 0.1399216553205329,         \"mean_ci_lower\": 0.029506324975848083,         \"mean_ci_upper\": 0.2503369856652177,         \"mean_se\": 0.05626787753841476,         \"obs_ci_lower\": -1.760769431668282,         \"obs_ci_upper\": 2.0406127423093476,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 6,         \"income\": 0.003231334765282966,         \"mean\": 0.03777574732037192,         \"mean_ci_lower\": -0.08244516180918222,         \"mean_ci_upper\": 0.15799665644992605,         \"mean_se\": 0.061264820485901615,         \"obs_ci_lower\": -1.8635101675213528,         \"obs_ci_upper\": 1.9390616621620966,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 7,         \"income\": 0.003231334765282966,         \"mean\": -0.06437016067978896,         \"mean_ci_lower\": -0.19526217270131715,         \"mean_ci_upper\": 0.06652185134173924,         \"mean_se\": 0.0667028362836266,         \"obs_ci_lower\": -1.9663606395714792,         \"obs_ci_upper\": 1.8376203182119015,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 8,         \"income\": 0.003231334765282966,         \"mean\": -0.16651606867994995,         \"mean_ci_lower\": -0.30875003309228005,         \"mean_ci_upper\": -0.024282104267619842,         \"mean_se\": 0.07248271835416821,         \"obs_ci_lower\": -2.069320725920426,         \"obs_ci_upper\": 1.7362885885605261,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 9,         \"income\": 0.003231334765282966,         \"mean\": -0.26866197668011094,         \"mean_ci_lower\": -0.42276068678551326,         \"mean_ci_upper\": -0.11456326657470861,         \"mean_se\": 0.07852901695779647,         \"obs_ci_lower\": -2.17239028593008,         \"obs_ci_upper\": 1.6350663325698584,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 0,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -10,         \"income\": 0.003231334765282966,         \"mean\": 3.9622800566823657,         \"mean_ci_lower\": 3.803250620376974,         \"mean_ci_upper\": 4.121309492987757,         \"mean_se\": 0.08104172508564757,         \"obs_ci_lower\": 2.0581462839144944,         \"obs_ci_upper\": 5.866413829450237,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -9,         \"income\": 0.003231334765282966,         \"mean\": 3.579743189094897,         \"mean_ci_lower\": 3.4327121724668213,         \"mean_ci_upper\": 3.726774205722973,         \"mean_se\": 0.07492730594701744,         \"obs_ci_lower\": 1.6765739420665928,         \"obs_ci_upper\": 5.482912436123201,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -8,         \"income\": 0.003231334765282966,         \"mean\": 3.197206321507428,         \"mean_ci_lower\": 3.06171587744404,         \"mean_ci_upper\": 3.3326967655708155,         \"mean_se\": 0.06904620663077266,         \"obs_ci_lower\": 1.294893854162462,         \"obs_ci_upper\": 5.099518788852394,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -7,         \"income\": 0.003231334765282966,         \"mean\": 2.8146694539199593,         \"mean_ci_lower\": 2.690134385135958,         \"mean_ci_upper\": 2.9392045227039607,         \"mean_se\": 0.06346332504464193,         \"obs_ci_lower\": 0.9131058745620053,         \"obs_ci_upper\": 4.716233033277913,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -6,         \"income\": 0.003231334765282966,         \"mean\": 2.4321325863324907,         \"mean_ci_lower\": 2.3177993513379738,         \"mean_ci_upper\": 2.5464658213270077,         \"mean_se\": 0.05826444973863155,         \"obs_ci_lower\": 0.5312098757500985,         \"obs_ci_upper\": 4.333055296914883,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -5,         \"income\": 0.003231334765282966,         \"mean\": 2.0495957187450218,         \"mean_ci_lower\": 1.9444911221075742,         \"mean_ci_upper\": 2.154700315382469,         \"mean_se\": 0.0535615168098355,         \"obs_ci_lower\": 0.14920574844473689,         \"obs_ci_upper\": 3.949985689045307,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -4,         \"income\": 0.003231334765282966,         \"mean\": 1.6670588511575528,         \"mean_ci_lower\": 1.5699318920418512,         \"mean_ci_upper\": 1.7641858102732544,         \"mean_se\": 0.04949609645816715,         \"obs_ci_lower\": -0.23290659831005822,         \"obs_ci_upper\": 3.567024300625164,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -3,         \"income\": 0.003231334765282966,         \"mean\": 1.2845219835700838,         \"mean_ci_lower\": 1.1937910710730781,         \"mean_ci_upper\": 1.3752528960670896,         \"mean_se\": 0.04623665805638643,         \"obs_ci_lower\": -0.6151272370667518,         \"obs_ci_upper\": 3.1841712042069195,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -2,         \"income\": 0.003231334765282966,         \"mean\": 0.9019851159826151,         \"mean_ci_lower\": 0.8157161579458508,         \"mean_ci_upper\": 0.9882540740193794,         \"mean_se\": 0.043962836963182275,         \"obs_ci_lower\": -0.9974562219123846,         \"obs_ci_upper\": 2.801426453877615,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": -1,         \"income\": 0.003231334765282966,         \"mean\": 0.5194482483951464,         \"mean_ci_lower\": 0.4353985601048724,         \"mean_ci_upper\": 0.6034979366854203,         \"mean_se\": 0.04283189257411597,         \"obs_ci_lower\": -1.3798935884223575,         \"obs_ci_upper\": 2.4187900852126503,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 0,         \"income\": 0.003231334765282966,         \"mean\": 0.1369113808076775,         \"mean_ci_lower\": 0.052660864931696166,         \"mean_ci_upper\": 0.22116189668365885,         \"mean_se\": 0.04293423472138522,         \"obs_ci_lower\": -1.7624393536300058,         \"obs_ci_upper\": 2.0362621152453606,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 1,         \"income\": 0.003231334765282966,         \"mean\": -0.24562548677979124,         \"mean_ci_lower\": -0.3324801417602774,         \"mean_ci_upper\": -0.15877083179930507,         \"mean_se\": 0.0442613093202462,         \"obs_ci_lower\": -2.1450935160120226,         \"obs_ci_upper\": 1.65384254245244,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 2,         \"income\": 0.003231334765282966,         \"mean\": -0.62816235436726,         \"mean_ci_lower\": -0.7198198423370006,         \"mean_ci_upper\": -0.5365048663975194,         \"mean_se\": 0.04670884280706545,         \"obs_ci_lower\": -2.527856055489765,         \"obs_ci_upper\": 1.271531346755245,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 3,         \"income\": 0.003231334765282966,         \"mean\": -1.010699221954729,         \"mean_ci_lower\": -1.1090366077894183,         \"mean_ci_upper\": -0.9123618361200398,         \"mean_se\": 0.05011293238285814,         \"obs_ci_lower\": -2.910726933446432,         \"obs_ci_upper\": 0.889328489536974,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 4,         \"income\": 0.003231334765282966,         \"mean\": -1.3932360895421976,         \"mean_ci_lower\": -1.499777959937885,         \"mean_ci_upper\": -1.28669421914651,         \"mean_se\": 0.054293954448389525,         \"obs_ci_lower\": -3.293706092760088,         \"obs_ci_upper\": 0.5072339136756929,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 5,         \"income\": 0.003231334765282966,         \"mean\": -1.7757729571296665,         \"mean_ci_lower\": -1.8917207090904353,         \"mean_ci_upper\": -1.6598252051688978,         \"mean_se\": 0.05908721087748012,         \"obs_ci_lower\": -3.6767934578524635,         \"obs_ci_upper\": 0.12524754359313017,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 6,         \"income\": 0.003231334765282966,         \"mean\": -2.158309824717135,         \"mean_ci_lower\": -2.284596698796882,         \"mean_ci_upper\": -2.032022950637388,         \"mean_se\": 0.06435604859620374,         \"obs_ci_lower\": -4.059988934753429,         \"obs_ci_upper\": -0.2566307146808411,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 7,         \"income\": 0.003231334765282966,         \"mean\": -2.540846692304604,         \"mean_ci_lower\": -2.6781953373202922,         \"mean_ci_upper\": -2.403498047288916,         \"mean_se\": 0.0699931496259112,         \"obs_ci_lower\": -4.44329241118103,         \"obs_ci_upper\": -0.6384009734281777,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 8,         \"income\": 0.003231334765282966,         \"mean\": -2.923383559892073,         \"mean_ci_lower\": -3.072355732975473,         \"mean_ci_upper\": -2.774411386808673,         \"mean_se\": 0.0759165232356868,         \"obs_ci_lower\": -4.826703756636905,         \"obs_ci_upper\": -1.0200633631472404,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       },       {         \"Partisanship\": \"Democrat\",         \"age\": 43.49360865290069,         \"gender\": 0.4837758112094395,         \"group\": \"a\",         \"ideology\": 9,         \"income\": 0.003231334765282966,         \"mean\": -3.3059204274795424,         \"mean_ci_lower\": -3.4669562892044055,         \"mean_ci_upper\": -3.1448845657546793,         \"mean_se\": 0.08206420357156388,         \"obs_ci_lower\": -5.210222822516913,         \"obs_ci_upper\": -1.4016180324421716,         \"rate_conservative\": 0.4955641780029095,         \"treatment\": 1,         \"vote_conservative\": 0.6037364798426745       }     ]   },   \"facet\": {     \"field\": \"Partisanship\",     \"type\": \"nominal\"   },   \"params\": [     {       \"bind\": \"scales\",       \"name\": \"param_21\",       \"select\": {         \"encodings\": [           \"x\",           \"y\"         ],         \"type\": \"interval\"       },       \"views\": [         \"view_22\"       ]     }   ],   \"spec\": {     \"layer\": [       {         \"encoding\": {           \"color\": {             \"field\": \"treatment\",             \"type\": \"nominal\"           },           \"x\": {             \"field\": \"ideology\",             \"title\": \"Ideolpty\",             \"type\": \"quantitative\"           },           \"y\": {             \"field\": \"mean\",             \"title\": \"Predicted values\",             \"type\": \"quantitative\"           }         },         \"mark\": {           \"type\": \"line\"         },         \"name\": \"view_22\"       },       {         \"encoding\": {           \"color\": {             \"field\": \"treatment\",             \"title\": \"Treatment group\",             \"type\": \"nominal\"           },           \"size\": {             \"value\": 1           },           \"strokeDash\": {             \"value\": [               5,               3             ]           },           \"x\": {             \"field\": \"ideology\",             \"title\": \"Ideolpty\",             \"type\": \"quantitative\"           },           \"y\": {             \"field\": \"mean_ci_lower\",             \"title\": \"Predicted values\",             \"type\": \"quantitative\"           }         },         \"mark\": {           \"type\": \"line\"         }       },       {         \"encoding\": {           \"color\": {             \"field\": \"treatment\",             \"type\": \"nominal\"           },           \"size\": {             \"value\": 1           },           \"strokeDash\": {             \"value\": [               5,               3             ]           },           \"x\": {             \"field\": \"ideology\",             \"title\": \"Ideolpty\",             \"type\": \"quantitative\"           },           \"y\": {             \"field\": \"mean_ci_upper\",             \"title\": \"Predicted values\",             \"type\": \"quantitative\"           }         },         \"mark\": {           \"type\": \"line\"         }       }     ]   } }</p>"},{"location":"case-studies/regression-table/#references","title":"References","text":"<ul> <li>Fournier, P., Soroka, S., &amp; Nir, L. (2020). Negativity Biases and     Political Ideology: A Comparative Test across 17 Countries. American     Political Science Review, 114(3), 775\u2013791.     http://dx.doi.org/10.1017/S0003055420000131</li> </ul>"},{"location":"case-studies/standardizing/","title":"Standardizing variables","text":"<p>It is easy to standardize the value of many varibles at once, or create new variables standardized. Consider these variables:</p> <pre><code>import tidypolars4sci as tp\nfrom tidypolars4sci.data import starwars as df\n\n# let us select 3 variables and the first 10 rows only for the example\ndf = df.select('name', 'height', 'mass').slice(list(range(10)))\ndf.print()\n</code></pre> <pre><code>shape: (10, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name                 height     mass \u2502\n\u2502 str                     i64      f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker          172    77.00 \u2502\n\u2502 C-3PO                   167    75.00 \u2502\n\u2502 R2-D2                    96    32.00 \u2502\n\u2502 Darth Vader             202   136.00 \u2502\n\u2502 Leia Organa             150    49.00 \u2502\n\u2502 Owen Lars               178   120.00 \u2502\n\u2502 Beru Whitesun Lars      165    75.00 \u2502\n\u2502 R5-D4                    97    32.00 \u2502\n\u2502 Biggs Darklighter       183    84.00 \u2502\n\u2502 Obi-Wan Kenobi          182    77.00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>To standardize one specific varible:</p> <pre><code>df.mutate(mass_std = tp.scale(\"mass\")).print()\n</code></pre> <pre><code>shape: (10, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name                 height     mass   mass_std \u2502\n\u2502 str                     i64      f64        f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker          172    77.00       0.04 \u2502\n\u2502 C-3PO                   167    75.00      -0.02 \u2502\n\u2502 R2-D2                    96    32.00      -1.30 \u2502\n\u2502 Darth Vader             202   136.00       1.79 \u2502\n\u2502 Leia Organa             150    49.00      -0.79 \u2502\n\u2502 Owen Lars               178   120.00       1.32 \u2502\n\u2502 Beru Whitesun Lars      165    75.00      -0.02 \u2502\n\u2502 R5-D4                    97    32.00      -1.30 \u2502\n\u2502 Biggs Darklighter       183    84.00       0.25 \u2502\n\u2502 Obi-Wan Kenobi          182    77.00       0.04 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>To standardize <code>height</code> and <code>mass</code>, we could do:</p> <pre><code>vars = ['height', 'mass']\ntab = df.mutate(**{f\"{var}_std\": tp.scale(var) for var in vars})\ntab.print()\n</code></pre> <pre><code>shape: (10, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name                 height     mass   height_std   mass_std \u2502\n\u2502 str                     i64      f64          f64        f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker          172    77.00         0.36       0.04 \u2502\n\u2502 C-3PO                   167    75.00         0.22      -0.02 \u2502\n\u2502 R2-D2                    96    32.00        -1.77      -1.30 \u2502\n\u2502 Darth Vader             202   136.00         1.20       1.79 \u2502\n\u2502 Leia Organa             150    49.00        -0.26      -0.79 \u2502\n\u2502 Owen Lars               178   120.00         0.53       1.32 \u2502\n\u2502 Beru Whitesun Lars      165    75.00         0.16      -0.02 \u2502\n\u2502 R5-D4                    97    32.00        -1.74      -1.30 \u2502\n\u2502 Biggs Darklighter       183    84.00         0.67       0.25 \u2502\n\u2502 Obi-Wan Kenobi          182    77.00         0.64       0.04 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Or we could use <code>tp.across()</code></p> <pre><code>tab = df.mutate(tp.across(tp.matches(\"heig|mass\"),  tp.scale, names_suffix='_std'))\ntab.print()\n</code></pre> <pre><code>shape: (10, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name                 height     mass   height_std   mass_std \u2502\n\u2502 str                     i64      f64          f64        f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker          172    77.00         0.36       0.04 \u2502\n\u2502 C-3PO                   167    75.00         0.22      -0.02 \u2502\n\u2502 R2-D2                    96    32.00        -1.77      -1.30 \u2502\n\u2502 Darth Vader             202   136.00         1.20       1.79 \u2502\n\u2502 Leia Organa             150    49.00        -0.26      -0.79 \u2502\n\u2502 Owen Lars               178   120.00         0.53       1.32 \u2502\n\u2502 Beru Whitesun Lars      165    75.00         0.16      -0.02 \u2502\n\u2502 R5-D4                    97    32.00        -1.74      -1.30 \u2502\n\u2502 Biggs Darklighter       183    84.00         0.67       0.25 \u2502\n\u2502 Obi-Wan Kenobi          182    77.00         0.64       0.04 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"performance/filter/","title":"Filter","text":""},{"location":"performance/filter/#code","title":"Code","text":"<p>Preparing the data sets and setting the data size and the number of repetitions:</p> <pre><code>from docs.src.config import *\nfrom docs.src.performance import *\nimport time\n\nm = 100              # repetitions\nnum_rows = 2_000_000 # number of rows\n\ndf_tp = tp.tibble({'a':np.random.choice(['apple','banana','carrot',\n                                    'date','eggplant'], num_rows), \n                 'b':np.random.rand(num_rows),\n                 'c':np.random.rand(num_rows),\n                 'd':np.random.rand(num_rows)})\ndf_pandas = df_tp.to_pandas().copy()\ndf_polars = df_tp.to_polars()\n</code></pre> <pre><code># collect processing time\nprocessing_time = {'pandas': [],\n                   'polars': [],\n                   'tidypolars4sci': [],\n                   }\n\n# pandas \n# ------\nfor _ in range(m):\n    start_time = time.time()\n    df_pandas.query(\"a=='apple' | a=='banana'\")\n    processing_time['pandas'] += [time.time() - start_time]\n\n# polars \n# ------\nfor _ in range(m):\n    start_time = time.time()\n    df_polars.filter((pl.col('a')=='apple') | (pl.col('a')=='banana'))\n    processing_time['polars'] += [time.time() - start_time]\n\n# tidypolars4si\n# -------------\nfor _ in range(m):\n    start_time = time.time()\n    df_tp.filter((tp.col('a')=='apple') | (tp.col('a')=='banana'))\n    processing_time['tidypolars4sci'] += [time.time() - start_time]\n</code></pre>"},{"location":"performance/filter/#results","title":"Results","text":"<pre><code>shape: (3, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Module           Mean     SD    Min    Max   How much slower than polars? \u2502\n\u2502 str               f64    f64    f64    f64   str                          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 polars           0.01   0.00   0.01   0.01   1.0x (baseline)              \u2502\n\u2502 tidypolars4sci   0.01   0.00   0.01   0.02   0.9x                         \u2502\n\u2502 pandas           0.09   0.00   0.09   0.12   7.4x                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"performance/overview/","title":"Performance","text":"<p>The performance of tidypolars is compatible with Polars for many operations. You can explore case-by-case comparisons by navigating the menu.</p>"},{"location":"performance/pivot-wide/","title":"Pivot wide","text":""},{"location":"performance/pivot-wide/#code","title":"Code","text":"<p>Let us use the data set <code>mtcars</code> to create a table in wide format using <code>pivot_wide</code>. Here are the variables:</p> <pre><code>from docs.src.config import *\nfrom docs.src.performance import *\n# \nimport tidypolars4sci as tp\nfrom tidypolars4sci.data import mtcars\nimport time\n\nmtcars.glimpse()\n</code></pre> <pre><code>Columns matching pattern '.':\n Var Type     Uniq Miss (%) Head                                                       \nname &lt;object&gt;   32    0 0% ['Mazda RX4' 'Mazda RX4 Wag' 'Datsun 710' 'Hornet 4 Drive'\n...\n mpg &lt;float64&gt;  25    0 0% [21.  21.  22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16....\n cyl &lt;int64&gt;     3    0 0% [6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 ...\ndisp &lt;float64&gt;  27    0 0% [160.  160.  108.  258.  360.  225.  360.  146.7 140.8 167....\n  hp &lt;int64&gt;    22    0 0% [110 110  93 110 175 105 245  62  95 123 123 180 180 180 20...\ndrat &lt;float64&gt;  22    0 0% [3.9  3.9  3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 3.92 3.0...\n  wt &lt;float64&gt;  29    0 0% [2.62  2.875 2.32  3.215 3.44  3.46  3.57  3.19  3.15  3.44...\nqsec &lt;float64&gt;  30    0 0% [16.46 17.02 18.61 19.44 17.02 20.22 15.84 20.   22.9  18.3...\n  vs &lt;int64&gt;     2    0 0% [0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 ...\n  am &lt;int64&gt;     2    0 0% [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 ...\ngear &lt;int64&gt;     3    0 0% [4 4 4 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 3 4 5 5 5 ...\ncarb &lt;int64&gt;     6    0 0% [4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 ...\n\n[Rows: 32; Columns 12]\n</code></pre> <p>A simple pivot wide operation:</p> <pre><code>tab = (mtcars\n       .select('name', 'am')\n       .pivot_wider(values_from='name', names_from='am')\n       )\nprint(tab)\n</code></pre> <pre><code>shape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1        0      \u2502\n\u2502 str      str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Mazda\u2026   Horne\u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Preparing the data and collecting processing time:</p> <pre><code>df_tp = mtcars\ndf_pd = mtcars.to_pandas()\ndf_pl = mtcars.to_polars()\n\n\ndef pivot_wide_with_pandas(df):\n    tab=(df\n         .filter(['name', \"am\"])\n         .pivot_table(index=None, values=\"name\", columns=\"am\",\n                      aggfunc=lambda col: \"; \".join(sorted(col))\n                      )\n         )\n\ndef pivot_wide_with_polars(df):\n    tab = (df\n           .select([\"name\", \"am\"])\n           .with_columns(idx=0)\n           .pivot(index='idx', on=\"am\", values=\"name\",\n                  aggregate_function=pl.element().sort().str.concat(\"; \")\n                  )\n           )\n\ndef pivot_wide_with_tidypolars4sci(df):\n    tab = (df\n           .select(\"name\", 'am')\n           .pivot_wider(values_from=\"name\", names_from='am',\n                        values_fn=pl.element().sort().str.concat(\"; \"))\n           )\n\n\nn = mtcars.nrow # sample size\nm = 1_000       # repetitions\n\n# collect processing time\nprocessing_time = {'pandas': [],\n                   'polars': [],\n                   'tidypolars4sci': [],\n                   }\n# \nfor i in range(m):\n    # pandas\n    start_time = time.time()\n    pivot_wide_with_pandas(df_pd)\n    processing_time['pandas'] += [time.time() - start_time]\n\n    # polars\n    start_time = time.time()\n    pivot_wide_with_polars(df_pl)\n    processing_time['polars'] += [time.time() - start_time]\n\n    start_time = time.time()\n    pivot_wide_with_tidypolars4sci(mtcars)\n    processing_time['tidypolars4sci'] += [time.time() - start_time]\n</code></pre>"},{"location":"performance/pivot-wide/#results","title":"Results","text":"<pre><code>shape: (3, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Module              Mean        SD       Min       Max   How much slower than polars? \u2502\n\u2502 str                  f64       f64       f64       f64   str                          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 polars           0.00041   0.00018   0.00019   0.00464   1.0x (baseline)              \u2502\n\u2502 tidypolars4sci   0.00080   0.00028   0.00046   0.00521   1.9x                         \u2502\n\u2502 pandas           0.00192   0.00053   0.00143   0.00703   4.6x                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Here is the summary of the performance:</p> <p></p>"},{"location":"performance/summarise/","title":"Summarise","text":""},{"location":"performance/summarise/#code","title":"Code","text":"<pre><code>from docs.src.config import *\nfrom docs.src.performance import *\n# \nimport tidypolars4sci as tp\nimport time\nfrom numpy.random import uniform as runif\nfrom numpy.random import normal as rnorm\n\nm = 100\nn = 2_000_000\n\ndf = pl.DataFrame({\n    \"a\": runif(300, 500, n),\n    \"b\": runif(0, 100, n),\n    \"c\": rnorm(0, 1, n),\n    \"d\": runif(100, 200, n),\n    \"e\": rnorm(10, 5, n)\n})\n</code></pre> <p>Preparing the data and collecting processing time:</p> <pre><code>df_tp = tp.from_polars(df)\ndf_pd = df.to_pandas()\ndf_pl = df\n\n\ndf_tp.summarise(tp.matches(\".\"), np.mean)\n\ndef on_pandas(df):\n    df.agg(['mean', 'std']).reset_index()\n\ndef on_polars(df):\n    mean = df_pl.select([pl.col(col).mean().alias(f\"{col}_mean\") for col in df.columns])\n    std = df_pl.select([pl.col(col).std().alias(f\"{col}_std\") for col in df.columns])\n\ndef on_tidypolars4sci(df):\n    df.summarise(**{f\"{col}_mean\": tp.col(col).mean() for col in df.names},\n                 **{f\"{col}_std\": tp.col(col).std() for col in df.names},\n                 )\n\nn = df.nrow    # sample size\nm = 1_000      # repetitions\n\n# collect processing time\nprocessing_time = {'pandas': [],\n                   'polars': [],\n                   'tidypolars4sci': [],\n                   }\n# \nfor i in range(m):\n    # pandas\n    start_time = time.time()\n    on_pandas(df_pd)\n    processing_time['pandas'] += [time.time() - start_time]\n\n    # polars\n    start_time = time.time()\n    on_polars(df_pl)\n    processing_time['polars'] += [time.time() - start_time]\n\n    start_time = time.time()\n    on_tidypolars4sci(mtcars)\n    processing_time['tidypolars4sci'] += [time.time() - start_time]\n</code></pre>"},{"location":"performance/summarise/#results","title":"Results","text":"<pre><code>shape: (3, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Module              Mean        SD       Min       Max   How much slower than polars? \u2502\n\u2502 str                  f64       f64       f64       f64   str                          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 polars           0.00047   0.00015   0.00023   0.00143   1.0x (baseline)              \u2502\n\u2502 tidypolars4sci   0.00084   0.00024   0.00047   0.00266   1.8x                         \u2502\n\u2502 pandas           0.00223   0.00050   0.00152   0.00563   4.8x                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Here is the summary of the performance:</p> <p></p>"},{"location":"usage/installation/","title":"<font color=\"#2a9d8f\">Installation</font>","text":"<p>You can install tidypolars4sci with <code>pip</code>:</p> <pre><code>$ pip install tidypolars4sci\n</code></pre> <p>Or through <code>conda</code>:</p> <pre><code>$ conda install -c conda-forge tidypolars4sci\n</code></pre>"},{"location":"usage/usage/","title":"Basic usage","text":"<p>tidypolars methods are designed to work like tidyverse functions. This creates a dataframe:</p> <pre><code>import tidypolars4sci as tp\n\ndf = tp.tibble({\"x\" : range(6),\n                \"y\" : range(6, 12),\n                \"w\" : range(6, 12),\n                \"z\" : ['a', 'a', 'b', 'c', 'd', 'e']}) # (1)!\n</code></pre> <ol> <li>Creates a tibble (the data frame of tidypolars)</li> </ol> <p>Here is the dataframe created:</p> <pre><code>shape: (6, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   x     y     w   z   \u2502\n\u2502 i64   i64   i64   str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   0     6     6   a   \u2502\n\u2502   1     7     7   a   \u2502\n\u2502   2     8     8   b   \u2502\n\u2502   3     9     9   c   \u2502\n\u2502   4    10    10   d   \u2502\n\u2502   5    11    11   e   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Data manipulation mirrors tidyverse function names:</p> <pre><code>df = (df\n      .select('x', 'y', 'z') # (1)!\n      .filter(tp.col('x') &lt; 4, tp.col('y') &gt;=7) # (2)!\n      .arrange(tp.desc('z'), 'x') # (3)!\n      .mutate(double_x = tp.col('x') * 2, # (4)!\n              x_plus_y = tp.col('x') + tp.col('y'), # (5)!\n              z_num = tp.case_when(tp.col(\"z\")=='a', 1, \n                                   tp.col(\"z\")=='b', 2,\n                                   True, 0), # (6)!\n              )\n\n      )\n</code></pre> <ol> <li>Select columns <code>x</code>, <code>y</code>, and <code>z</code>.</li> <li>Select (filter) rows with <code>x &lt; 4</code> and <code>y &gt; 7</code>.</li> <li>Sort (arrange) the data by <code>z</code> (decreasing values) and then by <code>x</code>     (increasing values).</li> <li>Create a variable <code>double_x</code>.</li> <li>Create a variable <code>x_plus_y</code>.</li> <li>Create a variable <code>z_num</code> that is <code>1</code> when <code>z = 'a'</code>, <code>2</code> when     <code>z = 'b'</code>, and <code>0</code> otherwise.</li> </ol> <pre><code>shape: (3, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   x     y   z     double_x   x_plus_y   z_num \u2502\n\u2502 i64   i64   str        i64        i64     i32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   3     9   c            6         12       0 \u2502\n\u2502   2     8   b            4         10       2 \u2502\n\u2502   1     7   a            2          8       1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/usage/#converting-tofrom-pandas-data-frames","title":"Converting to/from pandas data frames","text":"<p>If one needs to use a package that requires pandas or polars dataframes, you can convert from a tidypolars <code>tibble</code> to either of those <code>DataFrame</code> formats.</p> <pre><code># convert to pandas\ndf = df.to_pandas()\n# or convert to polars\ndf = df.to_polars()\n</code></pre> <p>To convert from a pandas or polars <code>DataFrame</code> to a tidypolars's <code>tibble</code>:</p> <pre><code># convert from pandas\ndf = tp.from_pandas(df)\n# or covert from polars\ndf = tp.from_polars(df)\n</code></pre>"},{"location":"usage/data-manipulation/mutate/","title":"Mutate","text":""},{"location":"usage/data-manipulation/mutate/#basic-examples","title":"Basic examples","text":"<p>To create new variables based on the transformation of existing ones:</p> <pre><code>import tidypolars4sci as tp\nfrom tidypolars4sci.data import starwars\n\ndf = (starwars\n      .head(5) # (1)!\n      .select('name', 'mass')\n      # create two new variables:\n      .mutate(mass2 = tp.col('mass') * 2,\n              mass2_squared = tp.col('mass2') * tp.col('mass2'),\n              )\n      )\n</code></pre> <ol> <li>Select the first 5 rows for the example</li> </ol> <pre><code>shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name               mass    mass2   mass2_squared \u2502\n\u2502 str                 f64      f64             f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker    77.00   154.00       23,716.00 \u2502\n\u2502 C-3PO             75.00   150.00       22,500.00 \u2502\n\u2502 R2-D2             32.00    64.00        4,096.00 \u2502\n\u2502 Darth Vader      136.00   272.00       73,984.00 \u2502\n\u2502 Leia Organa       49.00    98.00        9,604.00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/data-manipulation/mutate/#using-default-functions","title":"Using default functions","text":"<p>TidyPolars provides many default functions that can be applied directly to columns. Here is an example:</p> <pre><code>df = (starwars\n      .head(5)\n      .select('name', 'mass')\n      .mutate(mass_avg = tp.col('mass').mean(),\n              mass_min = tp.col('mass').min()\n              )\n      )\ndf.print()\n</code></pre> <pre><code>shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name               mass   mass_avg   mass_min \u2502\n\u2502 str                 f64        f64        f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker    77.00      73.80      32.00 \u2502\n\u2502 C-3PO             75.00      73.80      32.00 \u2502\n\u2502 R2-D2             32.00      73.80      32.00 \u2502\n\u2502 Darth Vader      136.00      73.80      32.00 \u2502\n\u2502 Leia Organa       49.00      73.80      32.00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The module provides many other default functions to apply to columns. Check the API reference for more. Here are some other examples.</p> <pre><code>import tidypolars4sci as tp\nfrom tidypolars4sci.data import mtcars as df\n\n\n(df\n .group_by(\"am\")\n .summarize(disp_avg = tp.col(\"disp\").mean(),\n            disp_std = tp.col(\"disp\").std(),\n            disp_med = tp.col(\"disp\").median(),\n            disp_min = tp.col(\"disp\").min(),\n            disp_max = tp.col(\"disp\").max(),\n            )\n).print()\n</code></pre> <pre><code>shape: (2, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  am   disp_avg   disp_std   disp_med   disp_min   disp_max \u2502\n\u2502 i64        f64        f64        f64        f64        f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   1     143.53      87.20     120.30      71.10     351.00 \u2502\n\u2502   0     290.38     110.17     275.80     120.10     472.00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/data-manipulation/mutate/#using-custom-functions","title":"Using custom functions","text":"<p>The function <code>map()</code> allows one to apply user-defined custom functions in parallel to each row. The result can be stored in a new column of the data frame using <code>mutate()</code>. Here is an example of how to apply custom functions to one or more columns:</p> <ul> <li>Note: the <code>*</code> in <code>*cols</code> is used to expand the columns. One could     also use <code>cols[0], cols[1]</code> instead.</li> </ul> <pre><code>import numpy as np\n\ndf = tp.tibble({'a':[1,10,100], 'b':[2, -20, 100]})\n\ndef min_of_two(col1, col2):\n    return np.min([col1, col2])\n\ndf\ndf = (df\n      .mutate(min_ab = tp.map(['a', 'b'], lambda cols: min_of_two(*cols)),\n              max_ab = tp.map(['a', 'b'], lambda cols: np.max([*cols])),\n              )\n      )\ndf.print()\n</code></pre> <pre><code>shape: (3, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   a     b   min_ab   max_ab \u2502\n\u2502 i64   i64      i64      i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   1     2        1        2 \u2502\n\u2502  10   -20      -20       10 \u2502\n\u2502 100   100      100      100 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/data-manipulation/mutate/#change-type-of-many-variables-at-once","title":"Changing many variables","text":"<p>There are different ways to change many variables at one. For instance, consider this data:</p> <pre><code># select some rows and varibles\ndf = (starwars\n      .head(5) \n      .select(\"name\", \"homeworld\", \"species\")\n      )\ndf.print()\n</code></pre> <pre><code>shape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name             homeworld   species \u2502\n\u2502 str              str         str     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker   Tatooine    Human   \u2502\n\u2502 C-3PO            Tatooine    Droid   \u2502\n\u2502 R2-D2            Naboo       Droid   \u2502\n\u2502 Darth Vader      Tatooine    Human   \u2502\n\u2502 Leia Organa      Alderaan    Human   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>To change the type to factor of all variables whose name match <code>hom</code> or <code>sp</code> we can use:</p> <pre><code># change to factor (i.e., categorical) those whose name matches hom|sp\ndf = df.mutate(tp.across(tp.matches(\"hom|sp\"),  tp.as_factor, names_suffix=\"_cat\"))\ndf.print()\n</code></pre> <pre><code>shape: (5, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name             homeworld   species   homeworld_cat   species_cat \u2502\n\u2502 str              str         str       cat             cat         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker   Tatooine    Human     Tatooine        Human       \u2502\n\u2502 C-3PO            Tatooine    Droid     Tatooine        Droid       \u2502\n\u2502 R2-D2            Naboo       Droid     Naboo           Droid       \u2502\n\u2502 Darth Vader      Tatooine    Human     Tatooine        Human       \u2502\n\u2502 Leia Organa      Alderaan    Human     Alderaan        Human       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Another possible way is to use a dictionary comprehension. See more examples here.</p>"},{"location":"usage/data-manipulation/mutate/#using-dynamic-variable-names","title":"Dynamic variable names","text":"<p>We can use dynamic names to create the new variable:</p> <pre><code>new_var = \"mass2_squared\"\ndf = (starwars\n      .head(5)\n      .select('name', 'mass')\n      # create a new variable using a dynamic name:\n      .mutate(**{new_var : tp.col('mass') **2 })\n      )\ndf.print()\n</code></pre> <pre><code>shape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name               mass   mass2_squared \u2502\n\u2502 str                 f64             f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Luke Skywalker    77.00        5,929.00 \u2502\n\u2502 C-3PO             75.00        5,625.00 \u2502\n\u2502 R2-D2             32.00        1,024.00 \u2502\n\u2502 Darth Vader      136.00       18,496.00 \u2502\n\u2502 Leia Organa       49.00        2,401.00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/data-manipulation/read-write/","title":"Read/Write Files","text":""},{"location":"usage/data-manipulation/read-write/#read","title":"Read","text":"<p>Reading files from disk is handled with the function <code>read_data()</code>. The function accepts various formats, including <code>csv, xlsx, txt, dta, Rdata, rds, sav</code> and others. The function accepts relative paths.</p> Loading data<pre><code>import tidypolars4sci as tp\n\nfn = \"../../src/data/example.csv\"\ndf = tp.read_data(fn=fn)\n</code></pre> <pre><code>Loading data 'example.csv'... done!\n</code></pre> <pre><code>df.head().print()\n</code></pre> <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   a     b \u2502\n\u2502 i64   i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   1     4 \u2502\n\u2502   2     5 \u2502\n\u2502   3     6 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>When files type that contain labels of variables and values are loaded, the function returns a tuple with the data (tibble) and the lables (dictionary).</p>"},{"location":"usage/statistics/freq/","title":"Frequency Tables","text":"<p>The method <code>.freq()</code> produces tables with relative frequency, joint relative frequencies, and conditional relative frequencies. The joint and conditional cases can combine multiple variables. The number of cases (N), standard deviation (Std.Dev.), and lower (low) and upper (high) 95% confidence intervals bounds based on normal approximation are provided.</p> <pre><code>import tidypolars4sci as tp\nfrom tidypolars4sci.data import mtcars as df\n\n# Notes:\n# - .arrange() below is just sorting the rows to facilitate visualization.\n# - .print() is used just to display the full table.\n\n# Relative frequencies: P(cyl)\ndf.freq('cyl').print()\n</code></pre> <pre><code>shape: (3, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 cyl     N    Freq   Std.Dev.     low    high \u2502\n\u2502 i64   i64     f64        f64     f64     f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   4    11   34.38      14.32    6.31   62.44 \u2502\n\u2502   6     7   21.88      15.62   -8.75   52.50 \u2502\n\u2502   8    14   43.75      13.26   17.76   69.74 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Joint relative frequencies: P(cyl, am)\ndf.freq(['cyl', 'am']).print()\n</code></pre> <pre><code>shape: (6, 7)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 cyl    am     N    Freq   Std.Dev.      low    high \u2502\n\u2502 i64   i64   i64     f64        f64      f64     f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   4     0     3    9.38      16.83   -23.61   42.36 \u2502\n\u2502   4     1     8   25.00      15.31    -5.01   55.01 \u2502\n\u2502   6     0     4   12.50      16.54   -19.91   44.91 \u2502\n\u2502   6     1     3    9.38      16.83   -23.61   42.36 \u2502\n\u2502   8     0    12   37.50      13.98    10.11   64.89 \u2502\n\u2502   8     1     2    6.25      17.12   -27.30   39.80 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Conditional relative frequencies given one variable: P(cyl | am)\ndf.freq('cyl', 'am').arrange('am').print()\n</code></pre> <pre><code>shape: (6, 7)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  am   cyl     N    Freq   Std.Dev.      low    high \u2502\n\u2502 i64   i64   i64     f64        f64      f64     f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   0     4     3   15.79      21.05   -25.47   57.05 \u2502\n\u2502   0     6     4   21.05      20.38   -18.90   61.01 \u2502\n\u2502   0     8    12   63.16      13.93    35.86   90.45 \u2502\n\u2502   1     4     8   61.54      17.20    27.83   95.25 \u2502\n\u2502   1     6     3   23.08      24.33   -24.60   70.75 \u2502\n\u2502   1     8     2   15.38      25.51   -34.62   65.39 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Conditional relative frequencies given two variables: P(cyl | am, carb)\ndf.freq('cyl', ['am', 'carb']).arrange('am', 'carb').print()\n</code></pre> <pre><code>shape: (13, 8)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  am   carb   cyl     N     Freq   Std.Dev.      low     high \u2502\n\u2502 i64    i64   i64   i64      f64        f64      f64      f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   0      1     4     1    33.33      47.14   -59.06   125.73 \u2502\n\u2502   0      1     6     2    66.67      33.33     1.33   132.00 \u2502\n\u2502   0      2     4     2    33.33      33.33   -32.00    98.67 \u2502\n\u2502   0      2     8     4    66.67      23.57    20.47   112.86 \u2502\n\u2502   0      3     8     3   100.00       0.00   100.00   100.00 \u2502\n\u2502   0      4     6     2    28.57      31.94   -34.04    91.18 \u2502\n\u2502   0      4     8     5    71.43      20.20    31.83   111.03 \u2502\n\u2502   1      1     4     4   100.00       0.00   100.00   100.00 \u2502\n\u2502   1      2     4     4   100.00       0.00   100.00   100.00 \u2502\n\u2502   1      4     6     2    66.67      33.33     1.33   132.00 \u2502\n\u2502   1      4     8     1    33.33      47.14   -59.06   125.73 \u2502\n\u2502   1      6     6     1   100.00       0.00   100.00   100.00 \u2502\n\u2502   1      8     8     1   100.00       0.00   100.00   100.00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Joint conditional relative frequencies given two variables: P(cyl, vs | am, carb)\ndf.freq(['cyl', 'vs'], ['am', 'carb']).arrange('am', 'carb').print()\n</code></pre> <pre><code>shape: (14, 9)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  am   carb   cyl    vs     N     Freq   Std.Dev.      low     high \u2502\n\u2502 i64    i64   i64   i64   i64      f64        f64      f64      f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   0      1     4     1     1    33.33      47.14   -59.06   125.73 \u2502\n\u2502   0      1     6     1     2    66.67      33.33     1.33   132.00 \u2502\n\u2502   0      2     4     1     2    33.33      33.33   -32.00    98.67 \u2502\n\u2502   0      2     8     0     4    66.67      23.57    20.47   112.86 \u2502\n\u2502   0      3     8     0     3   100.00       0.00   100.00   100.00 \u2502\n\u2502   0      4     6     1     2    28.57      31.94   -34.04    91.18 \u2502\n\u2502   0      4     8     0     5    71.43      20.20    31.83   111.03 \u2502\n\u2502   1      1     4     1     4   100.00       0.00   100.00   100.00 \u2502\n\u2502   1      2     4     0     1    25.00      43.30   -59.87   109.87 \u2502\n\u2502   1      2     4     1     3    75.00      25.00    26.00   124.00 \u2502\n\u2502   1      4     6     0     2    66.67      33.33     1.33   132.00 \u2502\n\u2502   1      4     8     0     1    33.33      47.14   -59.06   125.73 \u2502\n\u2502   1      6     6     0     1   100.00       0.00   100.00   100.00 \u2502\n\u2502   1      8     8     0     1   100.00       0.00   100.00   100.00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"}]}